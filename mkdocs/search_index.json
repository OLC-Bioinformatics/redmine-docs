{
    "docs": [
        {
            "location": "/", 
            "text": "OLC Redmine Automator\n\n\nTo facilitate the sharing of the CFIA's genomic data and tools to analyze this data, we make use of the Redmine\nplatform. Our instance of Redmine can be found \nhere\n (note that you must be on\nthe CFIA network in order to access Redmine).\n\n\nIf you have not yet gotten started with Redmine or want to know how the Redmine automator works and what it can do,\ntake a look at our \nGetting Started\n page for instructions on how to start using Redmine and a\nbrief overview of what Redmine can do.\n\n\nFor any issues or general help with Redmine, see the \nTroubleshooting\n page.", 
            "title": "Home"
        }, 
        {
            "location": "/#olc-redmine-automator", 
            "text": "To facilitate the sharing of the CFIA's genomic data and tools to analyze this data, we make use of the Redmine\nplatform. Our instance of Redmine can be found  here  (note that you must be on\nthe CFIA network in order to access Redmine).  If you have not yet gotten started with Redmine or want to know how the Redmine automator works and what it can do,\ntake a look at our  Getting Started  page for instructions on how to start using Redmine and a\nbrief overview of what Redmine can do.  For any issues or general help with Redmine, see the  Troubleshooting  page.", 
            "title": "OLC Redmine Automator"
        }, 
        {
            "location": "/getting_started/", 
            "text": "What is Redmine, and what can I use it for?\n\n\nRedmine is a system for project management and issue tracking that OLC has configured to automate a number of\nbioinformatics tasks. With Redmine, you can \nretrieve genomic data\n\n(either raw reads or draft assemblies) that is stored at OLC to perform your own analysis locally, \nlook for\nantibiotic resistance genes\n or \nfind plasmids\n in assemblies,\n\ncreate phylogenetic trees\n, compare \nstrains against RefSeq\n, and more.\n\n\nIf a tool you need is not currently available, we are generally able to add tools on request.\n\n\nAccessing Redmine\n\n\nTo access Redmine, go to \nhttps://redmine.biodiversity.agr.gc.ca\n (note that you\nmust be on the CFIA/Agriculture Canada network). Once there, login with your corporate username and password. If this is\nyour first time using Redmine, you will need to be added to the CFIA Genomics project. To get access, send an email\nto \nandrew.low@canada.ca\n, with \nadam.koziol@canada.ca\n CC'd and say you need access to the OLC Genomics project. Once you have been added to the project,\nhead to \nthe project page\n. This is where you will\nbe able to create requests.\n\n\nChanging Email Settings\n\n\nBy default, Redmine likes to send you emails about literally every issue that anybody reports, which can lead to\nreceiving far more emails than anybody has ever wanted to receive. To change this, click on the \nMy Account\n button (found\nin the top right corner when logged in to Redmine) and change the dropdown for email notifications from \nFor any event\non all my projects\n to something else - I recommend \nOnly for things I watch or I'm involved in\n. Once that's done, hit\nthe \nSave\n button on the bottom left of the screen to make sure Redmine remembers your email preferences.\n\n\nCreating Issues\n\n\nEverything in Redmine is done by creating \nIssues\n - these are requests for an analysis to be done.\n\n\nTo create a new issue, click on the \nNew Issue\n button, as shown in the below screenshot.\n\n\n`Click to see screenshot`\n\n\n![Screenshot](img/Redmine_Overview.png)\n\n\n\n\n\nThe page for new issues can be seen in the next screenshot. To have your analyses done, specific keywords are put in the\n\nSubject\n header, with any necessary details put in the \nDescription\n section. Details on what exactly needs to be put\ninto each section are under the \nData\n and \nAnalysis\n tabs for specific tools. Once an issue has been filled out, click\non the \nCreate\n button. Once that's done you can sit back and relax - you'll receive emails when your request has been\nsubmitted to our compute cluster (which should happen within a minute or two from the time you submitted your issue),\nand another once your job has completed (which, depending on the request, can be anywhere from a few minutes to a few\nhours).\n\n\n`Click to see screenshot`\n\n\n![Screenshot](img/New_Issue.png)", 
            "title": "Getting started"
        }, 
        {
            "location": "/getting_started/#what-is-redmine-and-what-can-i-use-it-for", 
            "text": "Redmine is a system for project management and issue tracking that OLC has configured to automate a number of\nbioinformatics tasks. With Redmine, you can  retrieve genomic data \n(either raw reads or draft assemblies) that is stored at OLC to perform your own analysis locally,  look for\nantibiotic resistance genes  or  find plasmids  in assemblies, create phylogenetic trees , compare  strains against RefSeq , and more.  If a tool you need is not currently available, we are generally able to add tools on request.  Accessing Redmine  To access Redmine, go to  https://redmine.biodiversity.agr.gc.ca  (note that you\nmust be on the CFIA/Agriculture Canada network). Once there, login with your corporate username and password. If this is\nyour first time using Redmine, you will need to be added to the CFIA Genomics project. To get access, send an email\nto  andrew.low@canada.ca , with  adam.koziol@canada.ca  CC'd and say you need access to the OLC Genomics project. Once you have been added to the project,\nhead to  the project page . This is where you will\nbe able to create requests.  Changing Email Settings  By default, Redmine likes to send you emails about literally every issue that anybody reports, which can lead to\nreceiving far more emails than anybody has ever wanted to receive. To change this, click on the  My Account  button (found\nin the top right corner when logged in to Redmine) and change the dropdown for email notifications from  For any event\non all my projects  to something else - I recommend  Only for things I watch or I'm involved in . Once that's done, hit\nthe  Save  button on the bottom left of the screen to make sure Redmine remembers your email preferences.  Creating Issues  Everything in Redmine is done by creating  Issues  - these are requests for an analysis to be done.  To create a new issue, click on the  New Issue  button, as shown in the below screenshot.  `Click to see screenshot` \n\n![Screenshot](img/Redmine_Overview.png)  The page for new issues can be seen in the next screenshot. To have your analyses done, specific keywords are put in the Subject  header, with any necessary details put in the  Description  section. Details on what exactly needs to be put\ninto each section are under the  Data  and  Analysis  tabs for specific tools. Once an issue has been filled out, click\non the  Create  button. Once that's done you can sit back and relax - you'll receive emails when your request has been\nsubmitted to our compute cluster (which should happen within a minute or two from the time you submitted your issue),\nand another once your job has completed (which, depending on the request, can be anywhere from a few minutes to a few\nhours).  `Click to see screenshot` \n\n![Screenshot](img/New_Issue.png)", 
            "title": "What is Redmine, and what can I use it for?"
        }, 
        {
            "location": "/troubleshooting/", 
            "text": "Troubleshooting\n\n\nError Messages\n\n\nIf you get error messages that aren't covered by the descriptions of the tools available, please let us know by sending\nus an email.\n\n\nWhy are things taking so long?\n\n\nOur compute cluster does run into situations where all available resources are being used. If that's the case, your job\nwill wait in queue until compute resources are freed up. This should be a fairly rare occurrence, but it does happen.\n\n\nContact Info\n\n\nIf you're having issues or want a new tool implemented, email us! For quickest response times, email Andrew with Adam CC'd.\n\n\nAndrew Low: \nandrew.low@canada.ca\n\n\nAdam Koziol: \nadam.koziol@canada.ca", 
            "title": "Troubleshooting"
        }, 
        {
            "location": "/troubleshooting/#troubleshooting", 
            "text": "Error Messages  If you get error messages that aren't covered by the descriptions of the tools available, please let us know by sending\nus an email.  Why are things taking so long?  Our compute cluster does run into situations where all available resources are being used. If that's the case, your job\nwill wait in queue until compute resources are freed up. This should be a fairly rare occurrence, but it does happen.  Contact Info  If you're having issues or want a new tool implemented, email us! For quickest response times, email Andrew with Adam CC'd.  Andrew Low:  andrew.low@canada.ca  Adam Koziol:  adam.koziol@canada.ca", 
            "title": "Troubleshooting"
        }, 
        {
            "location": "/tutorials/create_environment/", 
            "text": "Creating a mkdocs conda environment\n\n\nCreate a fresh conda environment\n\n\nconda create -n mkdocs\n\n\nActivate the environment\n\n\nconda activate mkdocs\n\n\nInstall mkdocs\n\n\nconda install mkdocs\n\n\nInstall the bootswatch package, so that the flatly theme works\n\n\npip install mkdocs-bootswatch", 
            "title": "Create environment"
        }, 
        {
            "location": "/tutorials/create_environment/#creating-a-mkdocs-conda-environment", 
            "text": "Create a fresh conda environment  conda create -n mkdocs  Activate the environment  conda activate mkdocs  Install mkdocs  conda install mkdocs  Install the bootswatch package, so that the flatly theme works  pip install mkdocs-bootswatch", 
            "title": "Creating a mkdocs conda environment"
        }, 
        {
            "location": "/tutorials/create_pages/", 
            "text": "Create a new page\n\n\nEnsure that the repository is up-to-date:\n\n\n\n\n\n\nif you don't have a local copy of the repositoty, clone a fresh version using \ngit clone https://github.com/OLC-Bioinformatics/redmine-docs.git\n\n\n\n\n\n\nor update an existing copy with \ngit pull origin master\n from within the repository\n\n\n\n\n\n\nOpen \nredmine-docs/mkdocs.yml\n in the redmine-docs repository with your favourite text editor\n\n\nDecide where you wish to place the new page \n\n\n\n\n\n\nif you want a new analysis, update the file with the desired name and location of the analysis\n\n\n\n\ne.g. if you want to add SISTR, include the following line \n- 'SISTR': 'analysis/SISTR.md'\n (make sure you following the spacing conventions, and that the list is still alphabetical) to the 'Analysis' category\n\n\n\n\n\n\n\n\nCreate an empty markdown file in the location specified in mkdocs.yml - the files are in the \ndocs\n folder, so, in the above example, you would need to create \ndocs/analysis/SISTR.md\n in the redmine-docs repository (I usually use \ntouch\n to accomplish this: \ntouch docs/analysis/SISTR.md\n if I'm in the root of the repository)", 
            "title": "Create pages"
        }, 
        {
            "location": "/tutorials/create_pages/#create-a-new-page", 
            "text": "Ensure that the repository is up-to-date:    if you don't have a local copy of the repositoty, clone a fresh version using  git clone https://github.com/OLC-Bioinformatics/redmine-docs.git    or update an existing copy with  git pull origin master  from within the repository    Open  redmine-docs/mkdocs.yml  in the redmine-docs repository with your favourite text editor  Decide where you wish to place the new page     if you want a new analysis, update the file with the desired name and location of the analysis   e.g. if you want to add SISTR, include the following line  - 'SISTR': 'analysis/SISTR.md'  (make sure you following the spacing conventions, and that the list is still alphabetical) to the 'Analysis' category     Create an empty markdown file in the location specified in mkdocs.yml - the files are in the  docs  folder, so, in the above example, you would need to create  docs/analysis/SISTR.md  in the redmine-docs repository (I usually use  touch  to accomplish this:  touch docs/analysis/SISTR.md  if I'm in the root of the repository)", 
            "title": "Create a new page"
        }, 
        {
            "location": "/tutorials/edit_pages/", 
            "text": "Edit pages\n\n\nThis is the way I edit pages. Feel free to use any method with which you are comfortable\n\n\n\n\nGet the mkdocs preview started\n\n\n\n\nmkdocs serve\n\n\n\n\n\n\nNavigate to the served pages in your browser e.g. \nhttp://127.0.0.1:8000/redmine-docs/\n\n\n\n\n\n\nEnsure that the page you are going to edit is present in the Nav bar e.g. 'Analysis' -\n 'SISTR'\n\n\n\n\nYou should see an empty page\n\n\n\n\n\n\n\n\nOpen the markdown file with your favourite editor\n\n\n\n\n\n\nUpdate the documentation using markdown language - I usually use one of the other files in the folder as a template to ensure that I'm following the same basic format each time\n\n\n\n\nEvery time you save your document, the served page will refresh", 
            "title": "Edit pages"
        }, 
        {
            "location": "/tutorials/edit_pages/#edit-pages", 
            "text": "This is the way I edit pages. Feel free to use any method with which you are comfortable   Get the mkdocs preview started   mkdocs serve    Navigate to the served pages in your browser e.g.  http://127.0.0.1:8000/redmine-docs/    Ensure that the page you are going to edit is present in the Nav bar e.g. 'Analysis' -  'SISTR'   You should see an empty page     Open the markdown file with your favourite editor    Update the documentation using markdown language - I usually use one of the other files in the folder as a template to ensure that I'm following the same basic format each time   Every time you save your document, the served page will refresh", 
            "title": "Edit pages"
        }, 
        {
            "location": "/tutorials/publish_changes/", 
            "text": "Publish Changes\n\n\nOnce you are satisfied with your new page, you need to commit your changes to the main and gh-pages branches of the repository \n\n\n\n\n\n\n(OPTIONAL)\n run \ngit status\n to see confirm what needs to be added to the commit\n\n\n\n\nmkdocs.yml\n should be present under the 'Changes not staged for commit' section\n\n\nyour new file (e.g. \ndocs/analysis/SISTR.md\n) should be present under the 'Untracked files' section\n\n\n\n\n\n\n\n\nadd your new file to the repository\n\n\n\n\ngit add mkdocs.yml docs/analysis/SISTR.md\n\n\n\n\n\n\n\n\ncommit your changes with a useful message\n\n\n\n\ngit commit -m \"Added SISTR analysis\n\n\n\n\n\n\n\n\npush your commits\n\n\n\n\ngit push origin master\n\n\n\n\n\n\n\n\nuse mkdocs to rebuild your site, and push the changes - https://olc-bioinformatics.github.io/redmine-docs/ should reflect the changes within a few minutes\n\n\n\n\nmkdocs gh-deploy", 
            "title": "Publish changes"
        }, 
        {
            "location": "/tutorials/publish_changes/#publish-changes", 
            "text": "Once you are satisfied with your new page, you need to commit your changes to the main and gh-pages branches of the repository     (OPTIONAL)  run  git status  to see confirm what needs to be added to the commit   mkdocs.yml  should be present under the 'Changes not staged for commit' section  your new file (e.g.  docs/analysis/SISTR.md ) should be present under the 'Untracked files' section     add your new file to the repository   git add mkdocs.yml docs/analysis/SISTR.md     commit your changes with a useful message   git commit -m \"Added SISTR analysis     push your commits   git push origin master     use mkdocs to rebuild your site, and push the changes - https://olc-bioinformatics.github.io/redmine-docs/ should reflect the changes within a few minutes   mkdocs gh-deploy", 
            "title": "Publish Changes"
        }, 
        {
            "location": "/internal_only/merge/", 
            "text": "Merge\n\n\nWhat does it do?\n\n\nMerge will take data from multiple MiSeq runs of the same strain and combine the FASTQ files in order \nto produce a better assembly. \n\n\nHow do I use it?\n\n\nSubject\n\n\nIn the \nSubject\n field, put \nMerge\n. Spelling counts, but case sensitivity doesn't.\n\n\nDescription\n\n\nNo text necessary in the description. You will, however, need to attach an excel file (.xlsx extension)\nwith the following headers: \n\n\n\n\nLocation: Should be 'MER'\n\n\nSEQID: Put the name of the merged SEQID (YYYY-MER-####)\n\n\nOLNID: Can be blank\n\n\nLabID: Can be blank\n\n\nLabIDIsolate: Can be blank\n\n\nOtherName: The SeqIDs you want to merge, separated by semi-colons.\n\n\nGenus: Genus of the isolate. Can be left blank.\n\n\nSpecies: Can be blank \n\n\nSubspecies: Can be blank\n\n\nSerotype: Can be blank\n\n\n\n\nAn example file can be found with the example issue below.\n\n\nExample\n\n\nFor an example Merge, see \nissue 14285\n.\n\n\nInterpreting Results\n\n\nYou'll get back the reports and assemblies, as you would for a \nWGS Assembly\n issue.\n\n\nHow long does it take?\n\n\nMerge will take quite a while, depending on how many samples you have. Probably roughly half an hour per sample.\n\n\nWhat can go wrong?\n\n\n1) Requested SEQIDs are not available. If we can't find some of the SEQIDs that you request, you will get a warning\nmessage informing you of it.", 
            "title": "Merge"
        }, 
        {
            "location": "/internal_only/merge/#merge", 
            "text": "What does it do?  Merge will take data from multiple MiSeq runs of the same strain and combine the FASTQ files in order \nto produce a better assembly.   How do I use it?  Subject  In the  Subject  field, put  Merge . Spelling counts, but case sensitivity doesn't.  Description  No text necessary in the description. You will, however, need to attach an excel file (.xlsx extension)\nwith the following headers:    Location: Should be 'MER'  SEQID: Put the name of the merged SEQID (YYYY-MER-####)  OLNID: Can be blank  LabID: Can be blank  LabIDIsolate: Can be blank  OtherName: The SeqIDs you want to merge, separated by semi-colons.  Genus: Genus of the isolate. Can be left blank.  Species: Can be blank   Subspecies: Can be blank  Serotype: Can be blank   An example file can be found with the example issue below.  Example  For an example Merge, see  issue 14285 .  Interpreting Results  You'll get back the reports and assemblies, as you would for a  WGS Assembly  issue.  How long does it take?  Merge will take quite a while, depending on how many samples you have. Probably roughly half an hour per sample.  What can go wrong?  1) Requested SEQIDs are not available. If we can't find some of the SEQIDs that you request, you will get a warning\nmessage informing you of it.", 
            "title": "Merge"
        }, 
        {
            "location": "/analysis/amrsummary/", 
            "text": "AMRsummary\n\n\nWhat does it do?\n\n\nAMRsummary performs ResFinder and MOB-suite analyses on FASTA files, and creates a report combining and summarising the outputs.\n\n\nResFinder is a program developed by the Danish Center for Genomic Epidemiology for detection of antibiotic resistance\nin draft genome assemblies. It is very important to note that the Redmine version will only look for acquired antibiotic\nresistance genes (generally plasmid-borne) and not chromosomally encoded AMR genes that are caused by point mutations.\n\n\nMobSuite is a set of tools developed by the Public Health Agency of Canada for detecting plasmids in draft genome\nassemblies. This tool runs the \nmob_recon\n part of the suite, which first detects plasmids in the assemblies, and then\nperforms typing on the plasmids. More details on MobSuite, including fairly extensive details on the output files\nproduced, can be found at the \nMobSuite GitHub repository\n).\n\n\nHow do I use it?\n\n\nSubject\n\n\nIn the \nSubject\n field, put \namr summary\n. Spelling counts, but case sensitivity doesn't.\n\n\nDescription\n\n\nAll you need to put in the description is a list of SEQIDs you want to process, one per line.\n\n\nExample\n\n\nFor an example AMRsummary, see \nissue 14100\n.\n\n\nInterpreting Results\n\n\nAMRSummary will upload three separate reports once it is complete\n\n\n\n\nresfinder_blastn.xlsx\n shows every AMR gene found in each sample. Just because a gene/resistance is listed here does not necessarily mean the strain carries that resistance - it's important\nto look at the \nPercentIdentity\n and \nPercentCovered\n columns. You can be pretty sure that anything with 100 for both\nis actually there, but anything else requires further analysis to be sure.\n\n\nmob_recon_summary.csv\n shows any contigs that are predicted to be plasmids - note that all contigs calculated to be chromosomal are ignored. \nLocation\n is the name of the predicted plasmid,\nwhile \nContig\n is the name contig predicted to contain plasmid sequence. One plasmid can be composed of several contigs if it could not be circularised.\n\n\namr_summary.csv\n combines the two previous reports. The contigs of all predicted AMR genes from the \nresfinder_assembled\n report are used to search the \nmob_recon_summary\n report.\nThe plasmid predictions, and well as all the incompatibility types for that plasmid are extracted, and used in the report. \nLocation\n will specify either \nchromosome\n or\nthe name of the predicted plasmid.\n\n\n\n\nHow long does it take?\n\n\nResFinder is very fast, while MOB-suite is relatively slow - it should take a few minutes to analyze each SEQID requested.\n\n\nWhat can go wrong?\n\n\n\n\nRequested SEQIDs are not available. If we can't find some of the SEQIDs that you request, you will get a warning\nmessage informing you of it.", 
            "title": "Amrsummary"
        }, 
        {
            "location": "/analysis/amrsummary/#amrsummary", 
            "text": "What does it do?  AMRsummary performs ResFinder and MOB-suite analyses on FASTA files, and creates a report combining and summarising the outputs.  ResFinder is a program developed by the Danish Center for Genomic Epidemiology for detection of antibiotic resistance\nin draft genome assemblies. It is very important to note that the Redmine version will only look for acquired antibiotic\nresistance genes (generally plasmid-borne) and not chromosomally encoded AMR genes that are caused by point mutations.  MobSuite is a set of tools developed by the Public Health Agency of Canada for detecting plasmids in draft genome\nassemblies. This tool runs the  mob_recon  part of the suite, which first detects plasmids in the assemblies, and then\nperforms typing on the plasmids. More details on MobSuite, including fairly extensive details on the output files\nproduced, can be found at the  MobSuite GitHub repository ).  How do I use it?  Subject  In the  Subject  field, put  amr summary . Spelling counts, but case sensitivity doesn't.  Description  All you need to put in the description is a list of SEQIDs you want to process, one per line.  Example  For an example AMRsummary, see  issue 14100 .  Interpreting Results  AMRSummary will upload three separate reports once it is complete   resfinder_blastn.xlsx  shows every AMR gene found in each sample. Just because a gene/resistance is listed here does not necessarily mean the strain carries that resistance - it's important\nto look at the  PercentIdentity  and  PercentCovered  columns. You can be pretty sure that anything with 100 for both\nis actually there, but anything else requires further analysis to be sure.  mob_recon_summary.csv  shows any contigs that are predicted to be plasmids - note that all contigs calculated to be chromosomal are ignored.  Location  is the name of the predicted plasmid,\nwhile  Contig  is the name contig predicted to contain plasmid sequence. One plasmid can be composed of several contigs if it could not be circularised.  amr_summary.csv  combines the two previous reports. The contigs of all predicted AMR genes from the  resfinder_assembled  report are used to search the  mob_recon_summary  report.\nThe plasmid predictions, and well as all the incompatibility types for that plasmid are extracted, and used in the report.  Location  will specify either  chromosome  or\nthe name of the predicted plasmid.   How long does it take?  ResFinder is very fast, while MOB-suite is relatively slow - it should take a few minutes to analyze each SEQID requested.  What can go wrong?   Requested SEQIDs are not available. If we can't find some of the SEQIDs that you request, you will get a warning\nmessage informing you of it.", 
            "title": "AMRsummary"
        }, 
        {
            "location": "/analysis/autoclark/", 
            "text": "AutoCLARK\n\n\nWhat does it do?\n\n\nThis process runs CLARK, a metagenomics tool, to determine what species are present in a sample. This is useful if you\nare unsure what species your sample is, or to check to see if any cross-species contamination occurred (or, obviously,\nif you have a shotgun metagenomics sample). Lots of detail on CLARK is provided at the \nCLARK website\n.\n\n\nHow do I use it?\n\n\nSubject\n\n\nIn the \nSubject\n field, put \nAutoCLARK\n. Spelling counts, but case sensitivity doesn't.\n\n\nDescription\n\n\nIn the \nDescription\n field first specify if you want CLARK to look at raw reads or draft assemblies for species\ndetermination. For reads, the first line of your description should be \nfastq\n, and for assemblies it should be \nfasta\n.\nSubsequent lines should be the SEQIDs you want CLARK to be looking at.\n\n\nExample\n\n\nFor an example AutoCLARK, see \nissue 12819\n.\n\n\nInterpreting Results\n\n\nOnce CLARK is complete, a file called \nabundance.xlsx\n will be uploaded to Redmine. This file shows the species present\nfor each strain in the request. These results should be interpreted with caution - species that show up with low\nproportions (less than 1-2 percent) are often not actually there and are just artifacts of the analysis.\n\n\nHow long does it take?\n\n\nCLARK will usually take 10 to 15 minutes to run, though it may take substantially longer if you requested that a large\nnumber of SEQIDs be analyzed.\n\n\nWhat can go wrong?\n\n\n1) Requested SEQIDs are not available. If we can't find some of the SEQIDs that you request, you will get a warning\nmessage informing you of it.", 
            "title": "Autoclark"
        }, 
        {
            "location": "/analysis/autoclark/#autoclark", 
            "text": "What does it do?  This process runs CLARK, a metagenomics tool, to determine what species are present in a sample. This is useful if you\nare unsure what species your sample is, or to check to see if any cross-species contamination occurred (or, obviously,\nif you have a shotgun metagenomics sample). Lots of detail on CLARK is provided at the  CLARK website .  How do I use it?  Subject  In the  Subject  field, put  AutoCLARK . Spelling counts, but case sensitivity doesn't.  Description  In the  Description  field first specify if you want CLARK to look at raw reads or draft assemblies for species\ndetermination. For reads, the first line of your description should be  fastq , and for assemblies it should be  fasta .\nSubsequent lines should be the SEQIDs you want CLARK to be looking at.  Example  For an example AutoCLARK, see  issue 12819 .  Interpreting Results  Once CLARK is complete, a file called  abundance.xlsx  will be uploaded to Redmine. This file shows the species present\nfor each strain in the request. These results should be interpreted with caution - species that show up with low\nproportions (less than 1-2 percent) are often not actually there and are just artifacts of the analysis.  How long does it take?  CLARK will usually take 10 to 15 minutes to run, though it may take substantially longer if you requested that a large\nnumber of SEQIDs be analyzed.  What can go wrong?  1) Requested SEQIDs are not available. If we can't find some of the SEQIDs that you request, you will get a warning\nmessage informing you of it.", 
            "title": "AutoCLARK"
        }, 
        {
            "location": "/analysis/bcgtree/", 
            "text": "bcgTree\n\n\nWhat does it do?\n\n\nbcgTree is a an automated phylogenetic tree building pipeline that builds trees from bacterial core genomes. The pipeline \"automatically extracts 107 essential single-copy core genes, found in a majority of bacteria\" (these genes were statistically determined, see \nbcgTree publication\n). It then uses hidden Markov models and performs a partitioned maximum-likelihood analysis. If you want to \nlearn more about it, check out the \nbcgTree publication\n. Dont forget to cite Ankenbrand and Keller, 2016!\n\n\nHow do I use it?\n\n\nSubject\n\n\nIn the \nSubject\n field, put \nbcgtree\n. Spelling counts, but case sensitivity doesnt.\n\n\nDescription\n\n\nRequired Components\n\n\nIn the \nDescription\n field, you must include a list of SEQIDs one per line.\n\n\nOptional Components\n\n\nIn order to customise your bcgTree analysis, several settings can be optionally modified.\n\n\n\n\nIf you would like to change the number of bootstraps performed, add the following line to the description before the list of SEQIDs:\n\n\ndefault is \n100\n\n\nmodify as follows:\n\n\nbootstraps=1000\n\n\n\n\n\n\n\n\n\n\nIf you would like to change the minimum number of proteomes in which a gene must occur in order to be kept:\n\n\ndefault is \n2\n\n\nmodify as follows:\n\n\nmin_proteomes=5\n\n\n\n\n\n\n\n\n\n\nIf you would like to change the amino acid substitution model used for the partitions by RAxML:\n\n\ndefault is \nAUTO\n\n\nmodify as follows:\n\n\naa_substitution_model=GTR\n\n\n\n\n\n\nyou can select one of the following amino acid substitution models to use:\n\n\nAUTO, DAYHOFF, DCMUT, JTT, MTREV, WAG,RTREV, CPREV, VT, BLOSUM62, MTMAM, LG,\n  MTART, MTZOA, PMB, HIVB,HIVW, JTTDCMUT, FLU, STMTREV, DUMMY, DUMMY2,\n  LG4M, LG4X, PROT_FILE, GTR_UNLINKED, GTR\n\n\n\n\n\n\n\n\n\n\n\n\nExample\n\n\nFor an example bcgtree issue see \nissue 25083\n. \nNOTE\n: the output files for these issues no longer exist on the ftp server.\n\n\nInterpreting Results\n\n\nThe bcgTree automator will upload links to the ftp for files called \nprokka_output.zip\n and \nbcgtree_output.zip\n once it has completed. \n\n\nThe \nprokka_output.zip\n contains all of the outputs from prokka. Prokka will output a lot of files for each genome you give it - you can find a quick description of\neach file \nhere\n. Of particular interest are the \n.faa\n files, which bcgTree uses for analysis.\n\n\nThe \nbcgtree_output.zip\n file contains all of the outputs from bcgTree. The alignment files, and gene-id files output by bcgtree can be found in subfolders in the zip file. The most interesting outputs from bcgtree are the RAxML files. These files conaint the phylogenetic trees output by bcgTree: \n\n\n\n\nRAxML_bestTree.final\n\n\nRAxML_bipartitionsBranchLabels.final\n\n\nRAxML_bipartitions.final\n\n\nRAxML_bootstrap.final\n\n\n\n\nThese files can be opened using a phylogenetic tree viewer of your choice.\n\n\nThere will also be the \nconfig.txt\n file containing the command(s) passed to bcgTree, as well as a \nbcgtree.log\n file containing all of the executed commands and their output(s) (including the random seed values used by RAxML).\n\n\nHow long does it take?\n\n\nProkka isnt the quickest thing around - expect it to take 2 to 3 minutes for each genome you give it. After prokka is finished the bcgTree pipeline time will depend on the number of sequences and bootstraps requested. \n\n\nWhat can go wrong?\n\n\n\n\nRequested SEQIDs are not available. If we cant find some of the SEQIDs that you request, you will get a warning message informing you of it.\n\n\nThere was an issue with the requested amino acid substitution model: there was a typo, or you requested a currently-unsupported substitution model. An error message detailing the problem will be added to the issue.", 
            "title": "Bcgtree"
        }, 
        {
            "location": "/analysis/bcgtree/#bcgtree", 
            "text": "What does it do?  bcgTree is a an automated phylogenetic tree building pipeline that builds trees from bacterial core genomes. The pipeline \"automatically extracts 107 essential single-copy core genes, found in a majority of bacteria\" (these genes were statistically determined, see  bcgTree publication ). It then uses hidden Markov models and performs a partitioned maximum-likelihood analysis. If you want to \nlearn more about it, check out the  bcgTree publication . Dont forget to cite Ankenbrand and Keller, 2016!  How do I use it?  Subject  In the  Subject  field, put  bcgtree . Spelling counts, but case sensitivity doesnt.  Description  Required Components  In the  Description  field, you must include a list of SEQIDs one per line.  Optional Components  In order to customise your bcgTree analysis, several settings can be optionally modified.   If you would like to change the number of bootstraps performed, add the following line to the description before the list of SEQIDs:  default is  100  modify as follows:  bootstraps=1000      If you would like to change the minimum number of proteomes in which a gene must occur in order to be kept:  default is  2  modify as follows:  min_proteomes=5      If you would like to change the amino acid substitution model used for the partitions by RAxML:  default is  AUTO  modify as follows:  aa_substitution_model=GTR    you can select one of the following amino acid substitution models to use:  AUTO, DAYHOFF, DCMUT, JTT, MTREV, WAG,RTREV, CPREV, VT, BLOSUM62, MTMAM, LG,\n  MTART, MTZOA, PMB, HIVB,HIVW, JTTDCMUT, FLU, STMTREV, DUMMY, DUMMY2,\n  LG4M, LG4X, PROT_FILE, GTR_UNLINKED, GTR       Example  For an example bcgtree issue see  issue 25083 .  NOTE : the output files for these issues no longer exist on the ftp server.  Interpreting Results  The bcgTree automator will upload links to the ftp for files called  prokka_output.zip  and  bcgtree_output.zip  once it has completed.   The  prokka_output.zip  contains all of the outputs from prokka. Prokka will output a lot of files for each genome you give it - you can find a quick description of\neach file  here . Of particular interest are the  .faa  files, which bcgTree uses for analysis.  The  bcgtree_output.zip  file contains all of the outputs from bcgTree. The alignment files, and gene-id files output by bcgtree can be found in subfolders in the zip file. The most interesting outputs from bcgtree are the RAxML files. These files conaint the phylogenetic trees output by bcgTree:    RAxML_bestTree.final  RAxML_bipartitionsBranchLabels.final  RAxML_bipartitions.final  RAxML_bootstrap.final   These files can be opened using a phylogenetic tree viewer of your choice.  There will also be the  config.txt  file containing the command(s) passed to bcgTree, as well as a  bcgtree.log  file containing all of the executed commands and their output(s) (including the random seed values used by RAxML).  How long does it take?  Prokka isnt the quickest thing around - expect it to take 2 to 3 minutes for each genome you give it. After prokka is finished the bcgTree pipeline time will depend on the number of sequences and bootstraps requested.   What can go wrong?   Requested SEQIDs are not available. If we cant find some of the SEQIDs that you request, you will get a warning message informing you of it.  There was an issue with the requested amino acid substitution model: there was a typo, or you requested a currently-unsupported substitution model. An error message detailing the problem will be added to the issue.", 
            "title": "bcgTree"
        }, 
        {
            "location": "/analysis/cardrgi/", 
            "text": "CARD-RGI\n\n\nWhat does it do?\n\n\nCARD-RGI (Comprehensive Antibiotic Resistance Database - Resistance Gene Identifier) is a program developed by the McMaster University to predict resistomes\nin draft genome assemblies. \nCARD website\n\n\nFor more information, see the \nCARD publication\n. If you publish data using this automator, don't forget to cite the authors of the tool \nAlcock et al., 2020\n\n\nHow do I use it?\n\n\nSubject\n\n\nIn the \nSubject\n field, put \nCARDRGI\n. Spelling counts, but case sensitivity doesn't.\n\n\nDescription\n\n\nRequired Components\n\n\nThe first line of the description should be the analysis you would like to run (e.g. \nanalysis=isolate\n). This will depend on the type of sequence data your are investigating.\n\n\n\n\nThe following options are currently supported:\n\n\nisolate\n - used for resistome analysis of bacterial isolate sequence assemblies\n\n\nmetagenome\n - used for resistome analysis of metagenome fastq-files. (This option can also be used to 'force' the tool to complete resistome analysis of isolate fastq-files). Currently, this metagenome redmine automator uses \nKMA\n for alignment of gene targets to the raw-read data. If you would like to try the other options (BWA or bowtie2), you can download the stand-alone tool from the \nCARD github\n.\n\n\n\n\n\n\n\n\nYou must also include a list of SEQIDs one per line.\n\n\nOptional Components\n\n\nBy default, CARD-RGI will run the analysis for isolate assemblies. In order to customise your CARD-RGI analyses, two additional settings can be optionally modified:\n\n\n\n\n\n\nloosehits - the default analysis will only include strict and perfect resistance gene matches. Setting this to true will also include 'loose' hits, which may or may not be contributing to resistance.\n\n\n\n\ndefault is \nFalse\n \n\n\nIf you want to include loose hits, add a line to your description:\n\n\nloosehits=TRUE\n\n\n\n\n\n\n\n\n\n\n\n\npartialgenes - the default analysis will only include full gene matches.\n\n\n\n\ndefault is \nFalse\n \n\n\nIf you want to include partial gene hits, add a line to your description:\n\n\npartialgenes=TRUE\n\n\n\n\n\n\n\n\n\n\n\n\nExample\n\n\nFor an example using CARDRGI, see \nissue 28111\n. The zip file has been attached to this request as an example (the ftp links expire after approx. 2 weeks). Please note that 2017-SEQ-0054 is an isolate sequence, not actually a metagenome.\n\n\nInterpreting Results\n\n\nCARD-RGI will upload a zipped folder called \ncard-rgi_output_redmineID.zip\n to the ftp once it has completed. \n\n\nIsolate Analysis\n\n\nThis folder will contain a \nCARDRGI_output.csv\n csv file which shows every AMR gene found in each\nsample-sequence. Just because a gene/resistance is listed here does not necessarily mean the strain carries that resistance - it's important\nto look at the \nBest_Identities\n column, which contains the percent identity of the gene/target match to the top hit in CARD. You can be pretty sure that anything with 100\nis actually there, but anything else requires further analysis to be sure. \n\n\nAlso, some efflux and point-mutations may confer resistance in specific genera/species but not others, so it is important to consider this before coming to any conclusions even if they are a 100% match. Information about the output table can be found on the \nCARD-RGI github page\n under \nRGI main Tab-Delimited Output Details\n.\n\n\nThe isolate analysis will also output individual results files for each sequence, and a RGI-heatmap file including information about all of the isolate sequences in your analysis.\n\n\nMetagenome Analysis\n\n\nThe zip folder will contain individual output files for each sequence analysed. It will also include \nCARDRGI_gene_mapping_output.csv\n and \nCARDRGI_allele_mapping_output.csv\n files. These contain the CARD-results of all resistance genes found in the raw fastq data for each sample-sequence. The \nCARDRGI_allele_mapping_output.csv\n allele file will include the data for the top allele hits for each sequence.\n\n\nHow long does it take?\n\n\nCARD-RGI is pretty fast, however the time required for analysis will depend on the analysis type and number of sequences requested. Expect approximately 2-5 minutes per sequence.\n\n\nWhat can go wrong?\n\n\n1) Requested SEQIDs are not available. If we can't find some of the SEQIDs that you request, you will get a warning\nmessage informing you of it.", 
            "title": "Cardrgi"
        }, 
        {
            "location": "/analysis/cardrgi/#card-rgi", 
            "text": "What does it do?  CARD-RGI (Comprehensive Antibiotic Resistance Database - Resistance Gene Identifier) is a program developed by the McMaster University to predict resistomes\nin draft genome assemblies.  CARD website  For more information, see the  CARD publication . If you publish data using this automator, don't forget to cite the authors of the tool  Alcock et al., 2020  How do I use it?  Subject  In the  Subject  field, put  CARDRGI . Spelling counts, but case sensitivity doesn't.  Description  Required Components  The first line of the description should be the analysis you would like to run (e.g.  analysis=isolate ). This will depend on the type of sequence data your are investigating.   The following options are currently supported:  isolate  - used for resistome analysis of bacterial isolate sequence assemblies  metagenome  - used for resistome analysis of metagenome fastq-files. (This option can also be used to 'force' the tool to complete resistome analysis of isolate fastq-files). Currently, this metagenome redmine automator uses  KMA  for alignment of gene targets to the raw-read data. If you would like to try the other options (BWA or bowtie2), you can download the stand-alone tool from the  CARD github .     You must also include a list of SEQIDs one per line.  Optional Components  By default, CARD-RGI will run the analysis for isolate assemblies. In order to customise your CARD-RGI analyses, two additional settings can be optionally modified:    loosehits - the default analysis will only include strict and perfect resistance gene matches. Setting this to true will also include 'loose' hits, which may or may not be contributing to resistance.   default is  False    If you want to include loose hits, add a line to your description:  loosehits=TRUE       partialgenes - the default analysis will only include full gene matches.   default is  False    If you want to include partial gene hits, add a line to your description:  partialgenes=TRUE       Example  For an example using CARDRGI, see  issue 28111 . The zip file has been attached to this request as an example (the ftp links expire after approx. 2 weeks). Please note that 2017-SEQ-0054 is an isolate sequence, not actually a metagenome.  Interpreting Results  CARD-RGI will upload a zipped folder called  card-rgi_output_redmineID.zip  to the ftp once it has completed.   Isolate Analysis  This folder will contain a  CARDRGI_output.csv  csv file which shows every AMR gene found in each\nsample-sequence. Just because a gene/resistance is listed here does not necessarily mean the strain carries that resistance - it's important\nto look at the  Best_Identities  column, which contains the percent identity of the gene/target match to the top hit in CARD. You can be pretty sure that anything with 100\nis actually there, but anything else requires further analysis to be sure.   Also, some efflux and point-mutations may confer resistance in specific genera/species but not others, so it is important to consider this before coming to any conclusions even if they are a 100% match. Information about the output table can be found on the  CARD-RGI github page  under  RGI main Tab-Delimited Output Details .  The isolate analysis will also output individual results files for each sequence, and a RGI-heatmap file including information about all of the isolate sequences in your analysis.  Metagenome Analysis  The zip folder will contain individual output files for each sequence analysed. It will also include  CARDRGI_gene_mapping_output.csv  and  CARDRGI_allele_mapping_output.csv  files. These contain the CARD-results of all resistance genes found in the raw fastq data for each sample-sequence. The  CARDRGI_allele_mapping_output.csv  allele file will include the data for the top allele hits for each sequence.  How long does it take?  CARD-RGI is pretty fast, however the time required for analysis will depend on the analysis type and number of sequences requested. Expect approximately 2-5 minutes per sequence.  What can go wrong?  1) Requested SEQIDs are not available. If we can't find some of the SEQIDs that you request, you will get a warning\nmessage informing you of it.", 
            "title": "CARD-RGI"
        }, 
        {
            "location": "/analysis/closerelatives/", 
            "text": "CloseRelatives\n\n\nWhat does it do?\n\n\nCloseRelatives uses mash to try to figure out what genomes in the CFIA collection are closest\nto a query genome. \n\n\nHow do I use it?\n\n\nSubject\n\n\nIn the \nSubject\n field, put \nClose Relatives\n. Spelling counts, but case sensitivity doesn't.\n\n\nDescription\n\n\nThe first line of the description should be the number of closely related strains you want to find, \nand the second line should be the SeqID you want to use as a query. For example, to find the 5 closest\ngenomes to 2014-SEQ-0276, you would enter:\n\n\n10\n2014-SEQ-0276\n\n\n\n\nExample\n\n\nFor an example CloseRelatives issue, see \nissue 14676\n.\n\n\nInterpreting Results\n\n\nThe automator will give you a list of the number of closest strains it found and their mash distances.\nIn the event that you want to look at more strains, it will also upload a file called \nclose_relatives_results.csv\n that\nhas the distance for every genome in the CFIA collection.\n\n\nFor interpretation of the mash distance reported, know that 0 means that two strains are identical (or at least extremely\nclose to identical), and 1 means that two strains have essentially no similarity.\n\n\nHow long does it take?\n\n\nMash is super quick - close relatives should finish in 2 or 3 minutes.\n\n\nWhat can go wrong?\n\n\n\n\nRequested SEQIDs are not available. If we can't find some of the SEQIDs that you request, you will get a warning message informing you of it.\n\n\nNumber of strains desired not requested. If the first line of the description wasn't a number, you'll get an \nerror telling you to enter a number.", 
            "title": "Closerelatives"
        }, 
        {
            "location": "/analysis/closerelatives/#closerelatives", 
            "text": "What does it do?  CloseRelatives uses mash to try to figure out what genomes in the CFIA collection are closest\nto a query genome.   How do I use it?  Subject  In the  Subject  field, put  Close Relatives . Spelling counts, but case sensitivity doesn't.  Description  The first line of the description should be the number of closely related strains you want to find, \nand the second line should be the SeqID you want to use as a query. For example, to find the 5 closest\ngenomes to 2014-SEQ-0276, you would enter:  10\n2014-SEQ-0276  Example  For an example CloseRelatives issue, see  issue 14676 .  Interpreting Results  The automator will give you a list of the number of closest strains it found and their mash distances.\nIn the event that you want to look at more strains, it will also upload a file called  close_relatives_results.csv  that\nhas the distance for every genome in the CFIA collection.  For interpretation of the mash distance reported, know that 0 means that two strains are identical (or at least extremely\nclose to identical), and 1 means that two strains have essentially no similarity.  How long does it take?  Mash is super quick - close relatives should finish in 2 or 3 minutes.  What can go wrong?   Requested SEQIDs are not available. If we can't find some of the SEQIDs that you request, you will get a warning message informing you of it.  Number of strains desired not requested. If the first line of the description wasn't a number, you'll get an \nerror telling you to enter a number.", 
            "title": "CloseRelatives"
        }, 
        {
            "location": "/analysis/confindr/", 
            "text": "ConFindr\n\n\nWhat does it do?\n\n\nConFindr looks for both intra-species and inter-species contamination in raw reads, which can cause misassemblies and\nerroneous downstream analysis. More details on ConFindr can be found \non GitHub\n.\n\n\nHow do I use it?\n\n\nSubject\n\n\nIn the \nSubject\n field, put \nConFindr\n. Spelling counts, but case sensitivity doesn't.\n\n\nDescription\n\n\nAll you need to put in the description is a list of SEQIDs you want to detect contamination in, one per line.\n\n\nExample\n\n\nFor an example ConFindr, see \nissue 12881\n.\n\n\nInterpreting Results\n\n\nWhen your request is complete, a file called \nconfindr_output.zip\n will be uploaded. This contains two files: \nconfindr_log.txt\n,\nand \nconfindr_report.csv\n. The report file contains 5 columns:\n\n\n\n\nSample: The name of the sample\n\n\nGenus: What ConFindr thinks the genus of the sample is. If ConFindr finds more than one genus, both will be listed here.\n\n\nNumContamSNVs: How many times ConFindr found something that looked like a contaminating SNV. Anything 3 or over\nis enough to call a sample as contaminated.\n\n\nNumUniqueKmers: How many unique kmers were found for the rMLST genes. If this number is over 45000, a sample is called\nas contaminated.\n\n\nContamStatus: Shown as \nTrue\n if ConFindr thinks a sample is contaminated, and \nFalse\n if the sample is thought to be\nclean.\n\n\n\n\nThe log file can mostly be ignored - if any unexpected errors come up, we may use it for debugging purposes.\n\n\nHow long does it take?\n\n\nConFindr will take between 1 and 2 minutes for each sample.\n\n\nWhat can go wrong?\n\n\n1) Requested SEQIDs are not available. If we can't find some of the SEQIDs that you request, you will get a warning\nmessage informing you of it.", 
            "title": "Confindr"
        }, 
        {
            "location": "/analysis/confindr/#confindr", 
            "text": "What does it do?  ConFindr looks for both intra-species and inter-species contamination in raw reads, which can cause misassemblies and\nerroneous downstream analysis. More details on ConFindr can be found  on GitHub .  How do I use it?  Subject  In the  Subject  field, put  ConFindr . Spelling counts, but case sensitivity doesn't.  Description  All you need to put in the description is a list of SEQIDs you want to detect contamination in, one per line.  Example  For an example ConFindr, see  issue 12881 .  Interpreting Results  When your request is complete, a file called  confindr_output.zip  will be uploaded. This contains two files:  confindr_log.txt ,\nand  confindr_report.csv . The report file contains 5 columns:   Sample: The name of the sample  Genus: What ConFindr thinks the genus of the sample is. If ConFindr finds more than one genus, both will be listed here.  NumContamSNVs: How many times ConFindr found something that looked like a contaminating SNV. Anything 3 or over\nis enough to call a sample as contaminated.  NumUniqueKmers: How many unique kmers were found for the rMLST genes. If this number is over 45000, a sample is called\nas contaminated.  ContamStatus: Shown as  True  if ConFindr thinks a sample is contaminated, and  False  if the sample is thought to be\nclean.   The log file can mostly be ignored - if any unexpected errors come up, we may use it for debugging purposes.  How long does it take?  ConFindr will take between 1 and 2 minutes for each sample.  What can go wrong?  1) Requested SEQIDs are not available. If we can't find some of the SEQIDs that you request, you will get a warning\nmessage informing you of it.", 
            "title": "ConFindr"
        }, 
        {
            "location": "/analysis/cowsnphr/", 
            "text": "COWSNPhR\n\n\nWhat does it do?\n\n\nCOWSNPhR (CFIA OLC Workflow for Single Nucleotide PHylogeny Reporting) is a pipeline developed in conjunction with the \nUSDA APHIS Veterinary Services that determines the presence of high quality Single Nucleotide Variants between a \nreference strain and other closely related strains. Following annotation of the reference strain, using \n\nProkka\n, the pipeline maps the raw reads of the query strains to the reference \ngenome using \nbowtie2\n, finds genetic variants with \n\nDeepVariant\n, extracts variants, creates multiple sequence alignments, and\ncalculates a phylogenetic tree using \nFastTree\n to show the relatedness of \nthese strains. The location of each variant is mapped to the annotation of the reference strain, and all variants are \nentered in a summary table.\n\n\nHow do I use it?\n\n\nSubject\n\n\nIn the \nSubject\n field, put \ncowsnphr\n. Spelling counts, but case sensitivity does not.\n\n\nDescription\n\n\nThe first line of your description needs to be \nreference\n, and the second line the SEQID of the strain you want to act\nas your reference strain. Ideally, you'll want to pick a high-quality assembly for your reference.\n\n\nIf you wish to attach a reference file instead of providing a SEQID, the second line must be \nattached\n\n\nThe third line of your description should be \ncompare\n, and lines after that the SEQIDs for strains to which you want to \ncompare your reference.\n\n\nExample\n\n\nFor example COWSNPhR analyses, see \nissue 15681\n and \n\nissue 15682 (uploaded reference file)\n.\n\n\nInterpreting Results\n\n\nThe zip file uploaded on COWSNPhR completion should contain four folders: \n\n\n\n\nvcf_files\n: compressed global VCF files \n\n\nsummary_tables\n: table summarizing the location, prevalence, and annotation of variants\n\n\nalignments\n: multiple sequence alignment of variants\n\n\ntree_files\n: phylogenetic tree of alignment. If you want to view this tree, you can use a program such as\n\nFigTree\n or a web-based viewer like \nphylo.io\n.\n\n\n\n\nHow long does it take?\n\n\nMost COWSNPhR requests take ~1 hour to complete. If you submit a request for a larger COWSNPhR analysis (\n30 strains), \nit may take substantially longer.\n\n\nWhat can go wrong?\n\n\nA few things can go wrong with this process:\n\n\n1) Requested SEQIDs are not available. If we can't find some of the SEQIDs that you request, you will get a warning\nmessage informing you of it.\n\n\n2) Strains too far apart. COWSNPhR requires that the strains you want to compare to the reference be closely related to\nthe reference. If you ask for an analysis with strains that are not very related, you will get a warning telling you so.\n\n\n3) Other errors. This software is still in active development, so there may be unforeseen issues arising for novel \nreference: query combinations.", 
            "title": "Cowsnphr"
        }, 
        {
            "location": "/analysis/cowsnphr/#cowsnphr", 
            "text": "What does it do?  COWSNPhR (CFIA OLC Workflow for Single Nucleotide PHylogeny Reporting) is a pipeline developed in conjunction with the \nUSDA APHIS Veterinary Services that determines the presence of high quality Single Nucleotide Variants between a \nreference strain and other closely related strains. Following annotation of the reference strain, using  Prokka , the pipeline maps the raw reads of the query strains to the reference \ngenome using  bowtie2 , finds genetic variants with  DeepVariant , extracts variants, creates multiple sequence alignments, and\ncalculates a phylogenetic tree using  FastTree  to show the relatedness of \nthese strains. The location of each variant is mapped to the annotation of the reference strain, and all variants are \nentered in a summary table.  How do I use it?  Subject  In the  Subject  field, put  cowsnphr . Spelling counts, but case sensitivity does not.  Description  The first line of your description needs to be  reference , and the second line the SEQID of the strain you want to act\nas your reference strain. Ideally, you'll want to pick a high-quality assembly for your reference.  If you wish to attach a reference file instead of providing a SEQID, the second line must be  attached  The third line of your description should be  compare , and lines after that the SEQIDs for strains to which you want to \ncompare your reference.  Example  For example COWSNPhR analyses, see  issue 15681  and  issue 15682 (uploaded reference file) .  Interpreting Results  The zip file uploaded on COWSNPhR completion should contain four folders:    vcf_files : compressed global VCF files   summary_tables : table summarizing the location, prevalence, and annotation of variants  alignments : multiple sequence alignment of variants  tree_files : phylogenetic tree of alignment. If you want to view this tree, you can use a program such as FigTree  or a web-based viewer like  phylo.io .   How long does it take?  Most COWSNPhR requests take ~1 hour to complete. If you submit a request for a larger COWSNPhR analysis ( 30 strains), \nit may take substantially longer.  What can go wrong?  A few things can go wrong with this process:  1) Requested SEQIDs are not available. If we can't find some of the SEQIDs that you request, you will get a warning\nmessage informing you of it.  2) Strains too far apart. COWSNPhR requires that the strains you want to compare to the reference be closely related to\nthe reference. If you ask for an analysis with strains that are not very related, you will get a warning telling you so.  3) Other errors. This software is still in active development, so there may be unforeseen issues arising for novel \nreference: query combinations.", 
            "title": "COWSNPhR"
        }, 
        {
            "location": "/analysis/diversitree/", 
            "text": "DiversiTree\n\n\nWhat does it do?\n\n\nDiversiTree is used for creating phylogenetic trees using \nparsnp\n,\nand optionally finding a specified number of strains that represent the most genetic diversity.\n\n\nHow do I use it?\n\n\nSubject\n\n\nIn the \nSubject\n field, put \nDiversiTree\n. Spelling counts, but case sensitivity doesn't.\n\n\nDescription\n\n\nThe first line of the description should be the number of diverse strains you want picked. If all you want here is the\ntree and don't care about the number of strains, you can set this to 1. Subsequent lines should be the SEQIDs you want\nto create the tree from. Note that these strains should all be fairly closely related, or the tree creation may fail (so\ntry to keep things to the same species).\n\n\nBy default, DiversiTree uses a tree creation program called \nparsnp\n. Another option available is \nmashtree\n, which is \ngenerally faster at making trees and can handle more diversity between samples, but may create less accurate\ntrees. If you want to use \nmashtree\n, add a line at the end of your description that says \ntreeprogram=mashtree\n. You can\nlook at \nissue 14724\n for an example request that \nuses \nmashtree\n.\n\n\nExample\n\n\nFor an example DiversiTree, see \nissue 12100\n.\n\n\nInterpreting Results\n\n\nDiversiTree will upload two files to Redmine on completion: \ndiversitree_report.html\n, and \ntree.nwk\n. The \ndiversitree.html\n \ncan be opened in any web browser, and has a picture of the tree with selected strains highlighted, and a list of the\n\nX\n most diverse strains, where \nX\n is the number specified in the first line of the description. The \ntree.nwk\n file\ncontains the phylogenetic tree created in newick format. If you want to view this tree, you can use a program such as\n\nFigTree\n or a web-based viewer like \nphylo.io\n.\n\n\nHow long does it take?\n\n\nThis depends largely on the number of strains you want to use to create the tree. It can often be as quick as a few minutes\nif you have 10 or less strains, or take several hours if you want a larger (100 or so strain) tree.\n\n\nWhat can go wrong?\n\n\nA few things can go wrong with this process:\n\n\n1) Requested SEQIDs are not available. If we can't find some of the SEQIDs that you request, you will get a warning\nmessage informing you of it.\n\n\n2) Strains too far apart. DiversiTree will warn you if it thinks that the strains you want to make a tree from are\nnot closely related enough. If you get this warning, you may want to consider creating a new issue while leaving out\nthe strains it says are too far, or use \nmashtree\n as your tree creation program.", 
            "title": "Diversitree"
        }, 
        {
            "location": "/analysis/diversitree/#diversitree", 
            "text": "What does it do?  DiversiTree is used for creating phylogenetic trees using  parsnp ,\nand optionally finding a specified number of strains that represent the most genetic diversity.  How do I use it?  Subject  In the  Subject  field, put  DiversiTree . Spelling counts, but case sensitivity doesn't.  Description  The first line of the description should be the number of diverse strains you want picked. If all you want here is the\ntree and don't care about the number of strains, you can set this to 1. Subsequent lines should be the SEQIDs you want\nto create the tree from. Note that these strains should all be fairly closely related, or the tree creation may fail (so\ntry to keep things to the same species).  By default, DiversiTree uses a tree creation program called  parsnp . Another option available is  mashtree , which is \ngenerally faster at making trees and can handle more diversity between samples, but may create less accurate\ntrees. If you want to use  mashtree , add a line at the end of your description that says  treeprogram=mashtree . You can\nlook at  issue 14724  for an example request that \nuses  mashtree .  Example  For an example DiversiTree, see  issue 12100 .  Interpreting Results  DiversiTree will upload two files to Redmine on completion:  diversitree_report.html , and  tree.nwk . The  diversitree.html  \ncan be opened in any web browser, and has a picture of the tree with selected strains highlighted, and a list of the X  most diverse strains, where  X  is the number specified in the first line of the description. The  tree.nwk  file\ncontains the phylogenetic tree created in newick format. If you want to view this tree, you can use a program such as FigTree  or a web-based viewer like  phylo.io .  How long does it take?  This depends largely on the number of strains you want to use to create the tree. It can often be as quick as a few minutes\nif you have 10 or less strains, or take several hours if you want a larger (100 or so strain) tree.  What can go wrong?  A few things can go wrong with this process:  1) Requested SEQIDs are not available. If we can't find some of the SEQIDs that you request, you will get a warning\nmessage informing you of it.  2) Strains too far apart. DiversiTree will warn you if it thinks that the strains you want to make a tree from are\nnot closely related enough. If you get this warning, you may want to consider creating a new issue while leaving out\nthe strains it says are too far, or use  mashtree  as your tree creation program.", 
            "title": "DiversiTree"
        }, 
        {
            "location": "/analysis/drep/", 
            "text": "dRep\n\n\nWhat does it do?\n\n\ndRep\n, developed by Matt Olm, is used to compare genomes and determine relatedness in the form of average nucleotide identity (ANI).\nOptionally, it can be used to dreplicate genomes.\n\n\nFor more information, see the \ndRep publication\n. If you publish data using this automator, don't forget to cite the authors of the tool \nOlm et al., 2017\n\n\nHow do I use it?\n\n\nSubject\n\n\nIn the \nSubject\n field, put \ndrep\n. Spelling counts, but case sensitivity doesn't.\n\n\nDescription\n\n\nRequired Components\n\n\nThe first line of the description should be the analysis you would like to run (e.g. \nanalysis=custom\n). \n\n\n\n\nThe following options are currently supported:\n\n\ncustom\n - compare only the SEQIDs listed in the description\n\n\nenterobacterales\n - compare the listed SEQIDs to a set of reference sequences for species from the order Enterobacterales\n\n\nlisteriaceae\n - compare the listed SEQIDs to a set of reference sequences for species from the family Listeriaceae\n\n\n\n\n\n\n\n\nYou must also include a list of SEQIDs one per line.\n\n\nOptional Components\n\n\nBy default, dRep will run the compare command to compare the set of genomes. In order to customise your dRep analyses, several settings can be optionally modified\n\n\n\n\n\n\nMASH ANI cutoff - this value is important, as only sequences clustering within this 'relatedness' threshold will be analysed using the secondary ANI algorithm (which is what determines the ANI values)\n\n\n\n\ndefault is \n0.9\n (90%) \n\n\nIf you want to use custom cutoffs for MASH clustering, add a line to your description:\n\n\nmash_ANI_threshold=0.8\n\n\n\n\n\n\n\n\n\n\n\n\nSecondary clustering cutoff\n\n\n\n\ndefault is \n0.99\n (99%) \n\n\nmodify as follows:\n\n\nS_ANI=0.9\n\n\n\n\n\n\n\n\n\n\n\n\ncoverage threshold (minimum overlap between genomes when doing secondary comparisons)\n\n\n\n\ndefault is \n0.1\n (10%) \n\n\nmodify as follows:\n\n\ncoverage_threshold=0.2\n\n\n\n\n\n\n\n\n\n\n\n\ncluster algorithm \n\n\n\n\ndefault is \naverage\n \n\n\nmodify as follows:\n\n\nclusteralgorithm=ward\n\n\n\n\n\n\navailable algorithms include:\n\n\nmedian\n, \nweighted\n, \nsingle\n, \ncomplete\n, \naverage\n, \nward\n, \ncentroid\n\n\n\n\n\n\n\n\n\n\n\n\ncomparison algorithm \n\n\n\n\ndefault is \nANImf\n \n\n\nmodify as follows:\n\n\ncomparisonalgorithm=fastANI\n\n\n\n\n\n\navailable algorithms include:\n\n\nfastANI\n, \nANImf\n, \nANIn\n, \ngANI\n, \ngoANI\n\n\n\n\n\n\n\n\n\n\n\n\ncommand type (compare genomes for ANI values, or dereplicate, see \ndRep\n).\n\n\n\n\ndefault is \ncompare\n \n\n\nmodify as follows:\n\n\ncommand=dereplicate\n\n\n\n\n\n\n\n\n\n\n\n\nExample\n\n\nInterpreting Results\n\n\ndRep will upload a zip file to the ftp on completion. This will contain folders with data in the form of tables, figures, etc. ANI values will only be output for clusters of sequences that are related at or above the MASH ANI cutoff. dRep does not output a tree file, however you should be able to replicate the output MASH tree by hierarchical clustering of the MASH table in R. (Hierarchical clustering uses the cluster algorithm command described above)\n\n\nHow long does it take?\n\n\nThis depends largely on the number of strains you want to compare and their relatedness. It can often be as quick as a few minutes\nif you have 10 or less strains, or take several hours for more strains. The primary clustering step uses Mash to determine whether sequences are likely related (based on provided cutoff or default 90%). \n\n\nThe secondary analysis which calculates the ANI values is only completed on sets of genomes that have at least 90% Mash ANI (unless this cutoff is modified). These secondary comparisons are slower (more sensitive and accurate for ANI). Therefore, if you have a large number of closely related genomes your job may take longer to complete.\n\n\nWhat can go wrong?\n\n\nA few things can go wrong with this process:\n\n\n1) Requested SEQIDs are not available. If we can't find some of the SEQIDs that you request, you will get a warning\nmessage informing you of it.\n\n\n2) You did not provide an analysis type. Custom analysis only completes dRep compare for the SEQ-IDs listed, whereas enterobacterales will compare your listed sequences to reference sequences from the order Enterobacterales, and listeriaceae will compare your listed sequences to reference sequences from the family Listeriaceae.", 
            "title": "Drep"
        }, 
        {
            "location": "/analysis/drep/#drep", 
            "text": "What does it do?  dRep , developed by Matt Olm, is used to compare genomes and determine relatedness in the form of average nucleotide identity (ANI).\nOptionally, it can be used to dreplicate genomes.  For more information, see the  dRep publication . If you publish data using this automator, don't forget to cite the authors of the tool  Olm et al., 2017  How do I use it?  Subject  In the  Subject  field, put  drep . Spelling counts, but case sensitivity doesn't.  Description  Required Components  The first line of the description should be the analysis you would like to run (e.g.  analysis=custom ).    The following options are currently supported:  custom  - compare only the SEQIDs listed in the description  enterobacterales  - compare the listed SEQIDs to a set of reference sequences for species from the order Enterobacterales  listeriaceae  - compare the listed SEQIDs to a set of reference sequences for species from the family Listeriaceae     You must also include a list of SEQIDs one per line.  Optional Components  By default, dRep will run the compare command to compare the set of genomes. In order to customise your dRep analyses, several settings can be optionally modified    MASH ANI cutoff - this value is important, as only sequences clustering within this 'relatedness' threshold will be analysed using the secondary ANI algorithm (which is what determines the ANI values)   default is  0.9  (90%)   If you want to use custom cutoffs for MASH clustering, add a line to your description:  mash_ANI_threshold=0.8       Secondary clustering cutoff   default is  0.99  (99%)   modify as follows:  S_ANI=0.9       coverage threshold (minimum overlap between genomes when doing secondary comparisons)   default is  0.1  (10%)   modify as follows:  coverage_threshold=0.2       cluster algorithm    default is  average    modify as follows:  clusteralgorithm=ward    available algorithms include:  median ,  weighted ,  single ,  complete ,  average ,  ward ,  centroid       comparison algorithm    default is  ANImf    modify as follows:  comparisonalgorithm=fastANI    available algorithms include:  fastANI ,  ANImf ,  ANIn ,  gANI ,  goANI       command type (compare genomes for ANI values, or dereplicate, see  dRep ).   default is  compare    modify as follows:  command=dereplicate       Example  Interpreting Results  dRep will upload a zip file to the ftp on completion. This will contain folders with data in the form of tables, figures, etc. ANI values will only be output for clusters of sequences that are related at or above the MASH ANI cutoff. dRep does not output a tree file, however you should be able to replicate the output MASH tree by hierarchical clustering of the MASH table in R. (Hierarchical clustering uses the cluster algorithm command described above)  How long does it take?  This depends largely on the number of strains you want to compare and their relatedness. It can often be as quick as a few minutes\nif you have 10 or less strains, or take several hours for more strains. The primary clustering step uses Mash to determine whether sequences are likely related (based on provided cutoff or default 90%).   The secondary analysis which calculates the ANI values is only completed on sets of genomes that have at least 90% Mash ANI (unless this cutoff is modified). These secondary comparisons are slower (more sensitive and accurate for ANI). Therefore, if you have a large number of closely related genomes your job may take longer to complete.  What can go wrong?  A few things can go wrong with this process:  1) Requested SEQIDs are not available. If we can't find some of the SEQIDs that you request, you will get a warning\nmessage informing you of it.  2) You did not provide an analysis type. Custom analysis only completes dRep compare for the SEQ-IDs listed, whereas enterobacterales will compare your listed sequences to reference sequences from the order Enterobacterales, and listeriaceae will compare your listed sequences to reference sequences from the family Listeriaceae.", 
            "title": "dRep"
        }, 
        {
            "location": "/analysis/eCGF/", 
            "text": "eCGF\n\n\nWhat does it do?\n\n\nThe eCGF automator performs \nin silico\n CGF subtyping of \nCampylobacter\n using whole-genome sequence data in FASTA format \n\n\nCheck out the source code: \ngithub\n\n\nHow do I use it?\n\n\nSubject\n\n\nIn the \nSubject\n field, put \neCGF\n. Spelling counts, but case sensitivity does not.\n\n\nDescription\n\n\nAll you need to put in the description is a list of SEQIDs you want to process, one per line.\n\n\nExample\n\n\nFor an example eCGF analysis, see \nissue 16196\n.\n\n\nInterpreting Results\n\n\nECTyper will output a summary report, \nISSUE_NUMBER_summary_report.csv\n that should look something like \nthe following excerpt:\n\n\n\n\n\n\n\n\nGenes\n\n\n11168_cj0008\n\n\n11168_cj0033\n\n\n11168_cj0035\n\n\n...\n\n\nNearest Match\n\n\nNumber of Similarities (/40)\n\n\n...\n\n\n\n\n\n\n\n\n\n\n2018-LET-0106\n\n\n0\n\n\n0\n\n\n1\n\n\n...\n\n\n27_3_4\n\n\n40\n\n\n...\n\n\n\n\n\n\n2018-LET-0012\n\n\n0\n\n\n0\n\n\n1\n\n\n...\n\n\n926_2_1\n\n\n40\n\n\n...\n\n\n\n\n\n\n\n\nHow long does it take?\n\n\neCGF is pretty fast - expect it to take a few seconds per genome you give it.\n\n\nWhat can go wrong?\n\n\n\n\nRequested SEQIDs are not available. If we can't find some of the SEQIDs that you request, \nyou will get a warning message informing you of it.\n\n\n?", 
            "title": "eCGF"
        }, 
        {
            "location": "/analysis/eCGF/#ecgf", 
            "text": "What does it do?  The eCGF automator performs  in silico  CGF subtyping of  Campylobacter  using whole-genome sequence data in FASTA format   Check out the source code:  github  How do I use it?  Subject  In the  Subject  field, put  eCGF . Spelling counts, but case sensitivity does not.  Description  All you need to put in the description is a list of SEQIDs you want to process, one per line.  Example  For an example eCGF analysis, see  issue 16196 .  Interpreting Results  ECTyper will output a summary report,  ISSUE_NUMBER_summary_report.csv  that should look something like \nthe following excerpt:     Genes  11168_cj0008  11168_cj0033  11168_cj0035  ...  Nearest Match  Number of Similarities (/40)  ...      2018-LET-0106  0  0  1  ...  27_3_4  40  ...    2018-LET-0012  0  0  1  ...  926_2_1  40  ...     How long does it take?  eCGF is pretty fast - expect it to take a few seconds per genome you give it.  What can go wrong?   Requested SEQIDs are not available. If we can't find some of the SEQIDs that you request, \nyou will get a warning message informing you of it.  ?", 
            "title": "eCGF"
        }, 
        {
            "location": "/analysis/ectyper/", 
            "text": "ECTyper\n\n\nWhat does it do?\n\n\nThe ECTyper automator performs serotyping on FASTA files. \n\n\nCheck out the source code: \ngithub\n\n\nHow do I use it?\n\n\nSubject\n\n\nIn the \nSubject\n field, put \nec_typer\n. Spelling counts, but case sensitivity does not.\n\n\nDescription\n\n\nAll you need to put in the description is a list of SEQIDs you want to process, one per line.\n\n\nExample\n\n\nFor an example ECTyper analysis, see \nissue 15946\n.\n\n\nInterpreting Results\n\n\nECTyper will output a summary report, \nec_typer_report.tsv\n ,that should look something like \nthe following:\n\n\n\n\n\n\n\n\nName\n\n\nO-type\n\n\nH-type\n\n\nAlleles\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n2014-SEQ-0276\n\n\nO157\n\n\nH7\n\n\nwzx: 1.00\n\n\nwzy: 0.58\n\n\nfliC: 1.00\n\n\n\n\n\n\n2019-SEQ-0137\n\n\nO146\n\n\nH8\n\n\nwzx: 1.00\n\n\nwzy: 0.56\n\n\nfliC: 1.00\n\n\n\n\n\n\n2019-SEQ-0145\n\n\n-\n\n\nH2\n\n\nfliC: 1.00\n\n\n\n\n\n\n\n\n\n\n\n\nHow long does it take?\n\n\nECTyper is pretty fast - expect it to take a minute per genome you give it.\n\n\nWhat can go wrong?\n\n\n\n\nRequested SEQIDs are not available. If we can't find some of the SEQIDs that you request, \nyou will get a warning message informing you of it.", 
            "title": "Ectyper"
        }, 
        {
            "location": "/analysis/ectyper/#ectyper", 
            "text": "What does it do?  The ECTyper automator performs serotyping on FASTA files.   Check out the source code:  github  How do I use it?  Subject  In the  Subject  field, put  ec_typer . Spelling counts, but case sensitivity does not.  Description  All you need to put in the description is a list of SEQIDs you want to process, one per line.  Example  For an example ECTyper analysis, see  issue 15946 .  Interpreting Results  ECTyper will output a summary report,  ec_typer_report.tsv  ,that should look something like \nthe following:     Name  O-type  H-type  Alleles        2014-SEQ-0276  O157  H7  wzx: 1.00  wzy: 0.58  fliC: 1.00    2019-SEQ-0137  O146  H8  wzx: 1.00  wzy: 0.56  fliC: 1.00    2019-SEQ-0145  -  H2  fliC: 1.00       How long does it take?  ECTyper is pretty fast - expect it to take a minute per genome you give it.  What can go wrong?   Requested SEQIDs are not available. If we can't find some of the SEQIDs that you request, \nyou will get a warning message informing you of it.", 
            "title": "ECTyper"
        }, 
        {
            "location": "/analysis/fastqc/", 
            "text": "FastQC/MultiQC\n\n\nWhat does it do?\n\n\nFastQC is a tool for conducting quality control checks on raw sequence data. MultiQC is a tool to aggregate FastQC reports from multiple sequences into a single file/report.\n\n\nFor more information, see the \nFastQC website\n, and \nMultiQC website\n.\n\n\nHow do I use it?\n\n\nSubject\n\n\nIn the \nSubject\n field, put \nfastqc\n. Spelling counts, but case sensitivity doesn't.\n\n\nDescription\n\n\nRequired Components\n\n\nYou must include a list of SEQIDs one per line.\n\n\nExample\n\n\nFor an example FastQC analysis, see \nissue 30311\n. The zip file has been attached to this request as an example (the ftp links expire after approx. 2 weeks).\n\n\nInterpreting Results\n\n\nFastQC/MultiQC will upload the multiqc report and a zipped folder called \nfastqc_redmineID.zip\n to both redmine and the ftp once it has completed. This will contain report files for individual sequences, and the multiqc report. (Files are uploaded to both redmine and the ftp in case a large number of sequences are analysed, and therefore reports are too large to be uploaded directly to redmine).\n\n\nHow long does it take?\n\n\nFastQC is usually pretty fast, \n1 minute per sequence. The time required for analysis will depend on the number of sequences requested.\n\n\nWhat can go wrong?\n\n\n1) Requested SEQIDs are not available. If we can't find some of the SEQIDs that you request, you will get a warning message informing you of it.", 
            "title": "Fastqc"
        }, 
        {
            "location": "/analysis/fastqc/#fastqcmultiqc", 
            "text": "What does it do?  FastQC is a tool for conducting quality control checks on raw sequence data. MultiQC is a tool to aggregate FastQC reports from multiple sequences into a single file/report.  For more information, see the  FastQC website , and  MultiQC website .  How do I use it?  Subject  In the  Subject  field, put  fastqc . Spelling counts, but case sensitivity doesn't.  Description  Required Components  You must include a list of SEQIDs one per line.  Example  For an example FastQC analysis, see  issue 30311 . The zip file has been attached to this request as an example (the ftp links expire after approx. 2 weeks).  Interpreting Results  FastQC/MultiQC will upload the multiqc report and a zipped folder called  fastqc_redmineID.zip  to both redmine and the ftp once it has completed. This will contain report files for individual sequences, and the multiqc report. (Files are uploaded to both redmine and the ftp in case a large number of sequences are analysed, and therefore reports are too large to be uploaded directly to redmine).  How long does it take?  FastQC is usually pretty fast,  1 minute per sequence. The time required for analysis will depend on the number of sequences requested.  What can go wrong?  1) Requested SEQIDs are not available. If we can't find some of the SEQIDs that you request, you will get a warning message informing you of it.", 
            "title": "FastQC/MultiQC"
        }, 
        {
            "location": "/analysis/geneseekr/", 
            "text": "GeneSeekr\n\n\nWhat does it do?\n\n\nThe GeneSeekr is a suite of analyses that detect gene targets in FASTA-formatted files.\n\n\nHow do I use it?\n\n\nSubject\n\n\nIn the \nSubject\n field, put \ngeneseekr\n. Spelling counts, but case sensitivity doesn't.\n\n\nDescription\n\n\nRequired Components\n\n\nIn the \nDescription\n field, you must provide the requested analysis type as follows:\n\n\nanalysis=requested_analysis\n\n\nThe GeneSeekr pipeline supports the following analyses (again, spelling counts, but case sensitivity doesn't):\n\n\n\n\ngdcs\n - determines the presence of genomically-dispersed conserved sequences in the following genera: \nEscherichia, Listeria, Salmonella, Vibrio\n. \nNOTE\n: you must provide an additional line: \norganism=ORGANISM\n\n\ngenesippr\n - custom suite of genes derived from the following genera: \nBacillus, Campylobacter, Escherichia, Listeria, Salmonella, Staphylococcus, Vibrio\n\n\nmlst\n - determines multi-locus sequence type for the following genera: \nBacillus, Campylobacter, Escherichia, Listeria, Salmonella, Staphylococcus, Vibrio\n. \nNOTE\n: you must provide an additional line: \norganism=ORGANISM\n\n\ncgmlst\n - determines core genome multi-locus sequence type for the following genera: \nEscherichia, Yersinia\n. \nNOTE\n: you must provide an additional line: \norganism=ORGANISM\n\n\nresfinder\n - identifies acquired antimicrobial resistance genes\n\n\nrmlst\n - determines ribosomal multi-locus sequence type\n\n\nserosippr\n - calculates the serotype for \nEscherichia\n\n\nsixteens\n - determines closest 16S match\n\n\nvirulence\n - finds virulence genes\n\n\ncustom\n (\nyou must attach a FASTA-formatted file of target(s) to the issue\n)\n\n\n\nBacterial Integrative and Conjugative Elements (ICEs) \nICEberg databases\n from the \nICEfinder publication\n:\n\n\nall_ices\n - used for all ICE gene detection\n\n\naice\n - used for actinomycete (AICEs) type ICE gene detection\n\n\ncime\n - used for cis-mobilizable elements (CIMEs) ICE gene detection\n\n\nime\n - used for Integrative and Mobilizable Elements (IME) type ICE gene detection\n\n\nt4ss\n - used for Type IV Secretion System (T4SS) type ICE gene detection\n\n\n\n\n\n\n\n\nYou must also include a list of SEQIDs one per line.\n\n\nOptional Components\n\n\nIn order to customise your GeneSeekr analyses, several settings can be optionally modified\n\n\n\n\nBLAST program. \nNOTE:\n GeneSeekr does not check to see if your query or database are the appropriate molecule for the requested program. Additionally, none of the standard analyses currently have protein databases.\n\n\ndefault is \nblastn\n\n\nYou can select one of the following BLAST programs to use:\n\n\nblastn - nt query: nt db\n\n\nblastp - protein query: protein db\n\n\nblastx - translated nt query: protein db\n\n\ntblastn - protein query: translated nt db\n\n\ntblastx - translated nt query: translated nt db\n\n\n\n\n\n\nmodify as follows:\n\n\nblast=tblastx\n\n\n\n\n\n\n\n\n\n\nMinimum cutoff for matches to be included in report.\n\n\ndefault is \n70\n\n\nmodify as follows:\n\n\ncutoff=80\n\n\n\n\n\n\n\n\n\n\nE-value cutoff\n\n\ndefault is \n1E-05\n\n\nmodify as follows:\n\n\nevalue=1E-10\n\n\n\n\n\n\n\n\n\n\nInclude alignments in reports\n\n\ndefault is \nFalse\n\n\nmodify as follows:\n\n\nalign=True\n\n\n\n\n\n\n\n\n\n\nReport unique hits only - does not report multiple hits at the same location in a contig. Instead, only the best hit is reported, and the rest are discarded\n\n\ndefault is \nFalse\n\n\nmodify as follows:\n\n\nunique=True\n\n\n\n\n\n\n\n\n\n\nInclude FASTA file output of strain-specific target sequence matches \n\n\ndefault is \nFalse\n\n\nmodify as follows:\n\n\nfasta=True\n       \n\n\n\n\n\n\n\n\n\n\n\n\nExample\n\n\nFor example GeneSeekr issues, see \nissue 14470 (ResFindr)\n, \nissue 14471 (custom)\n, or \nissue 27867 (cgMLST)\n.\n\n\nInterpreting Results\n\n\nThe GeneSeekr automator will upload a file called \ngeneseekr_output.zip\n once it has completed. This file will contain all the reports generated for the requested analysis.\n\n\nHow long does it take?\n\n\nIt depends on the analysis requested. The GeneSeekr pipeline should take about a minute to analyze each SEQID requested.\n\n\nWhat can go wrong?\n\n\n\n\nRequested SEQIDs are not available. If we can't find some of the SEQIDs that you request, you will get a warning message informing you of it.\n\n\nThere was an issue with the requested analysis: either one was not supplied, the was a typo, or you requested a currently-unsupported analysis. An error message detailing the problem will be added to the issue.\n\n\nThe \ncustom\n analysis requires an attached FASTA-formatted file of gene targets. If the file was not attached, or there was an issue reading the file, an error message detailing the problem will be add to the issue.", 
            "title": "Geneseekr"
        }, 
        {
            "location": "/analysis/geneseekr/#geneseekr", 
            "text": "What does it do?  The GeneSeekr is a suite of analyses that detect gene targets in FASTA-formatted files.  How do I use it?  Subject  In the  Subject  field, put  geneseekr . Spelling counts, but case sensitivity doesn't.  Description  Required Components  In the  Description  field, you must provide the requested analysis type as follows:  analysis=requested_analysis  The GeneSeekr pipeline supports the following analyses (again, spelling counts, but case sensitivity doesn't):   gdcs  - determines the presence of genomically-dispersed conserved sequences in the following genera:  Escherichia, Listeria, Salmonella, Vibrio .  NOTE : you must provide an additional line:  organism=ORGANISM  genesippr  - custom suite of genes derived from the following genera:  Bacillus, Campylobacter, Escherichia, Listeria, Salmonella, Staphylococcus, Vibrio  mlst  - determines multi-locus sequence type for the following genera:  Bacillus, Campylobacter, Escherichia, Listeria, Salmonella, Staphylococcus, Vibrio .  NOTE : you must provide an additional line:  organism=ORGANISM  cgmlst  - determines core genome multi-locus sequence type for the following genera:  Escherichia, Yersinia .  NOTE : you must provide an additional line:  organism=ORGANISM  resfinder  - identifies acquired antimicrobial resistance genes  rmlst  - determines ribosomal multi-locus sequence type  serosippr  - calculates the serotype for  Escherichia  sixteens  - determines closest 16S match  virulence  - finds virulence genes  custom  ( you must attach a FASTA-formatted file of target(s) to the issue )  Bacterial Integrative and Conjugative Elements (ICEs)  ICEberg databases  from the  ICEfinder publication :  all_ices  - used for all ICE gene detection  aice  - used for actinomycete (AICEs) type ICE gene detection  cime  - used for cis-mobilizable elements (CIMEs) ICE gene detection  ime  - used for Integrative and Mobilizable Elements (IME) type ICE gene detection  t4ss  - used for Type IV Secretion System (T4SS) type ICE gene detection     You must also include a list of SEQIDs one per line.  Optional Components  In order to customise your GeneSeekr analyses, several settings can be optionally modified   BLAST program.  NOTE:  GeneSeekr does not check to see if your query or database are the appropriate molecule for the requested program. Additionally, none of the standard analyses currently have protein databases.  default is  blastn  You can select one of the following BLAST programs to use:  blastn - nt query: nt db  blastp - protein query: protein db  blastx - translated nt query: protein db  tblastn - protein query: translated nt db  tblastx - translated nt query: translated nt db    modify as follows:  blast=tblastx      Minimum cutoff for matches to be included in report.  default is  70  modify as follows:  cutoff=80      E-value cutoff  default is  1E-05  modify as follows:  evalue=1E-10      Include alignments in reports  default is  False  modify as follows:  align=True      Report unique hits only - does not report multiple hits at the same location in a contig. Instead, only the best hit is reported, and the rest are discarded  default is  False  modify as follows:  unique=True      Include FASTA file output of strain-specific target sequence matches   default is  False  modify as follows:  fasta=True               Example  For example GeneSeekr issues, see  issue 14470 (ResFindr) ,  issue 14471 (custom) , or  issue 27867 (cgMLST) .  Interpreting Results  The GeneSeekr automator will upload a file called  geneseekr_output.zip  once it has completed. This file will contain all the reports generated for the requested analysis.  How long does it take?  It depends on the analysis requested. The GeneSeekr pipeline should take about a minute to analyze each SEQID requested.  What can go wrong?   Requested SEQIDs are not available. If we can't find some of the SEQIDs that you request, you will get a warning message informing you of it.  There was an issue with the requested analysis: either one was not supplied, the was a typo, or you requested a currently-unsupported analysis. An error message detailing the problem will be added to the issue.  The  custom  analysis requires an attached FASTA-formatted file of gene targets. If the file was not attached, or there was an issue reading the file, an error message detailing the problem will be add to the issue.", 
            "title": "GeneSeekr"
        }, 
        {
            "location": "/analysis/intimintyper/", 
            "text": "IntiminTyper\n\n\nWhat does it do?\n\n\nIntiminTyper uses \nphylotyper\n developed at the Public Health Agency of Canada to assign subtypes to intimin (\neae\n) \ngenes in \nEscherichia coli\n.\n\n\nHow do I use it?\n\n\nSubject\n\n\nIn the \nSubject\n field, put \nintimin_typer\n. Spelling counts, but case sensitivity doesn't.\n\n\nDescription\n\n\nAll you need to put in the description is a list of SEQIDs you want to subtype intimin genes in, one per line.\nNothing bad will happen if you put in SEQIDs that aren't from \nE. coli\n, but you won't get any results for those\nSeqIDs.\n\n\nExample\n\n\nFor an example IntiminTyper, see \nissue 16512\n.\n\n\nInterpreting Results\n\n\nIntiminTyper will upload a file called \nintimin_predictions.tsv\n - this file will tell what subtype the intimin gene in \neach of your samples is, noting if it's an exact match to a known allele or a guess based on what the allele is similar \nto. When IntiminTyper guesses you'll also receive a probability showing how certain it is with its guess.\n\n\nHow long does it take?\n\n\nIntiminTyper should take about 30 seconds for analysis of each sample.\n\n\nWhat can go wrong?\n\n\n1) Requested SEQIDs are not available: If we can't find some of the SEQIDs that you request, they won't show up in your\nfinal report.", 
            "title": "Intimintyper"
        }, 
        {
            "location": "/analysis/intimintyper/#intimintyper", 
            "text": "What does it do?  IntiminTyper uses  phylotyper  developed at the Public Health Agency of Canada to assign subtypes to intimin ( eae ) \ngenes in  Escherichia coli .  How do I use it?  Subject  In the  Subject  field, put  intimin_typer . Spelling counts, but case sensitivity doesn't.  Description  All you need to put in the description is a list of SEQIDs you want to subtype intimin genes in, one per line.\nNothing bad will happen if you put in SEQIDs that aren't from  E. coli , but you won't get any results for those\nSeqIDs.  Example  For an example IntiminTyper, see  issue 16512 .  Interpreting Results  IntiminTyper will upload a file called  intimin_predictions.tsv  - this file will tell what subtype the intimin gene in \neach of your samples is, noting if it's an exact match to a known allele or a guess based on what the allele is similar \nto. When IntiminTyper guesses you'll also receive a probability showing how certain it is with its guess.  How long does it take?  IntiminTyper should take about 30 seconds for analysis of each sample.  What can go wrong?  1) Requested SEQIDs are not available: If we can't find some of the SEQIDs that you request, they won't show up in your\nfinal report.", 
            "title": "IntiminTyper"
        }, 
        {
            "location": "/analysis/kma/", 
            "text": "KMA - Gene Detection\n\n\nWhat does it do?\n\n\nKMA (k-mer alignment) is a program developed by the Center for Genomic Epidemiology (CGE) to align gene targets to sequence assemblies or raw-reads. This redmine automator tool currently allows analysis for antimicrobial, biocide, and metal resistance, or a custom set of user targets in sequence data.\n\n\nFor more information, see the \nKMA publication\n, and/or the \nCGE website\n.\n\n\nIf you publish data using this automator, don't forget to cite the authors of the tool \nClausen et al., 2018\n\n\nHow do I use it?\n\n\nSubject\n\n\nIn the \nSubject\n field, put \nkma\n. Spelling counts, but case sensitivity doesn't.\n\n\nDescription\n\n\nRequired Components\n\n\nThe first line of the description should be the analysis you would like to run (e.g. \nanalysis=amr\n). This will depend on the type of sequence data your are investigating.\n\n\n\n\nThe following options are currently supported:\n\n\namr\n - used for antimicrobial resistance gene detection\n\n\nbiocide\n - used for biocide resistance gene detection\n\n\nmetal\n - used for metal resistance gene detection\n\n\nbacmet\n - used for metal resistance gene detection using the \nBacMet database\n, which was converted to nucleotide format by James Robertson (reference to follow)\n\n\ncustom\n - gene detection using a custom target database uploaded by the user. The attached file \nMUST\n be named \ntargets.fasta\n. The output csv file will use your fasta-file gene headers as names.\n\n\n\n\n\n\n\nBacterial Integrative and Conjugative Elements (ICEs) \nICEberg databases\n from the \nICEfinder publication\n:\n\nCAUTION: the ICEfinder webtool seems to work differently than KMA, and may detect ICEs where KMA does not\n\n\nall_ices\n - used for all ICE gene detection\n\n\naice\n - used for actinomycete (AICEs) type ICE gene detection\n\n\ncime\n - used for cis-mobilizable elements (CIMEs) ICE gene detection\n\n\nime\n - used for Integrative and Mobilizable Elements (IME) type ICE gene detection\n\n\nt4ss\n - used for Type IV Secretion System (T4SS) type ICE gene detection\n\n\n\n\n\n\n\n\nYou must also include a list of SEQIDs one per line.\n\n\nOptional Components\n\n\nBy default, KMA will run the analysis for isolate assemblies. In order to customise your CARD-RGI analyses, additional settings can be optionally modified:\n\n\n\n\n\n\nseqtype\n - the default analysis will use genome assemblies.\n\n\n\n\ndefault is \nfasta\n \n\n\nIf you want to analyse raw-read data, add the following line:\n\n\nseqtype=fastq\n\n\nseqtype=minionfastq\n\n\n\n\n\n\nNote: seqtype for minion raw-reads is slightly different, as KMA uses different commands for paired-end (illumina) and single-end (nanopore) data\n\n\n\n\n\n\n\n\nnanopore\n - the default analysis will be for short-read Illumina data. \nThis function is for assemblies\n\n\n\n\ndefault is \nFalse\n \n\n\nIf you want to analyse long-read Nanopore data, add a line to your description:\n\n\nnanopore=TRUE\n\n\n\n\n\n\n\n\n\n\n\n\nmin_ID\n - Use this option to specify the minimum template identity (i.e. relatedness to gene(s) in your database), in percent, needed in order to report a template as a hit.\n\n\n\n\ndefault is \nFalse\n \n\n\nIf you want to analyse long-read Nanopore data, add a line to your description (example is for matches greater than 90%):\n\n\nmin_ID=90\n\n\n\n\n\n\n\n\n\n\n\n\nreadcount\n - the default analysis will only output a csv file containing information on matching target gene(s) presence including template identity, coverage, depth, etc. This flag will output read-mapping data for your targets. \nThis function is best used with raw-reads - Assembly analysis will likely only report 1 read mapping to each gene-target\n\n\n\n\ndefault is \nFalse\n \n\n\nIf you want the analysis to output a file including information on the number of reads in your sequence mapping to each database-target, add a line to your description:\n\n\nreadcount=TRUE\n\n\n\n\n\n\n\n\n\n\n\n\nalign\n - Create consensus alignment files \n.fsa and \n.aln.\n\n\n\n\ndefault is \nFalse\n\n\nIf you want the analysis to create additional alignment files, add a line to your description:\n\n\nalign=TRUE\n\n\n\n\n\n\n\n\n\n\n\n\nvcf\n - Produce vcf-files, including any positions different from the template. This will use \"-vcf 2\" which applies the filter used for basecalling. \nThis function will make KMA run longer\n\n\n\n\ndefault is \nFalse\n\n\nIf you want the analysis to output a vcf file for each sequence, add a line to your description:\n\n\nvcf=TRUE\n\n\n\n\n\n\n\n\n\n\n\n\nhmm\n - Use a HMM (Hidden Markov Model) to identify high scoring subsequences within the query.\n\n\n\n\ndefault is \nFalse\n\n\nIf you want the analysis to use HMM, add a line to your description:\n\n\nhmm=TRUE\n\n\n\n\n\n\n\n\n\n\n\n\nExample\n\n\nFor an example KMA analysis, see \nissue 28117\n. The zip file has been attached to this request as an example (the ftp links expire after approx. 2 weeks).\n\n\nInterpreting Results\n\n\nKMA will upload a zipped folder called \nkma_output_redmineID.zip\n to the ftp once it has completed. This will contain a  kma_output.csv file with the target-hits/results for all of the sequences requested in the analysis. Just because a gene/resistance is listed here does not necessarily mean the strain carries that resistance - it's important\nto look at the \nTemplate_Identity\n and \nTemplate_Coverage\n columns. You can be pretty sure that anything with 100 for both\nis actually there, but anything else requires further analysis to be sure.\n\n\nDatabases Provided with the Automator\n\n\nThe databases for AMR, biocide, and metal resistance were derived from the NCBI \nAMRFinderPlus database\n, version 3.11 downloaded on 2023-10-27. This database was then manually curated and split into separate AMR, biocide, and metal resistance databases. The following genes were added to the biocide resistance database, as they were of interest for some research projects:\n\n\n-sugE_sugE_quaternary_ammonium_compound_efflux_NC_011514.1:c6661-6344\n-sugE_sugE_quaternary_ammonium_compound_efflux_NC_003197.2:4581504-4581833\n-sugE_sugE_quaternary_ammonium_compound_efflux_NC_017731.1:2886005-2886319\n-sugE_sugE_quaternary_ammonium_compound_efflux_NC_020418.1:c2409693-2409373\n-sugE_sugE_quaternary_ammonium_compound_efflux_NC_016830.1:5098537-5098851\n-sugE(p)_sugESalmonella_quaternary_ammonium_compound_efflux_NC_010259.1:c4461-4144\n-sugE(c)_sugESalmonella_quaternary_ammonium_compound_efflux_NC_003198.1:4557993-4558310\n-sugE(p)_sugEEcoli_quaternary_ammonium_compound_efflux_NC_019069.1:c60194-59877\n-sugE(p)_sugEEcoli_quaternary_ammonium_compound_efflux_KC285365.1\n-sugE(c)_sugEEcoli_quaternary_ammonium_compound_efflux_LT903847.1:c240852-240535\n-bcrA_bcrABC_Listeria_benzalkonium_chloride_efflux_JX023276.1:106-645\n-bcrB_bcrABC_Listeria_benzalkonium_chloride_efflux_JX023276.1:657-974\n-bcrC_bcrABC_Listeria_benzalkonium_chloride_efflux_JX023276.1:992-1336\n-qacH_qacH_Listeria_quaternary_ammonium_compound_efflux_HG329628.1:983-1354\n-emrE_emrE_Listeria_Listeria_quaternary_ammonium_compound_resistance_NC_013768.1:1817073-1817396\n-qacA_qacA_Listeria_quaternary_ammonium_compound_efflux_KC980922.1\n-qacC_qacC_Listeria_quaternary_ammonium_compound_efflux_RJZ34303\n-qacED1_qacED1_Acinetobacter_quaternary_ammonium_compound_efflux_KM972592.1\n-mdfA_multidrug_efflux_pump_NC_00913.3:883673-884905\n\n\n\nA verotoxin gene database has also been provided, which has been curated by our lab. Please contact Catherine Carrillo for more information.\n\n\nHow long does it take?\n\n\nKMA is very fast, however the time required for analysis will depend on the analysis type and number of sequences requested.\n\n\nWhat can go wrong?\n\n\n1) Requested SEQIDs are not available. If we can't find some of the SEQIDs that you request, you will get a warning message informing you of it.\n\n\n2) A custom analysis was requested but \ntargets.fasta\n file was not attached. You will get a warning message informing you of it.\n\n\nVersion (as of 2023-12-20)\n\n\nKMA version = 1.4.9\n\n\nNCBI AMRFinderPlus database (used for amr, biocide, and metal detection) = 3.11", 
            "title": "Kma"
        }, 
        {
            "location": "/analysis/kma/#kma-gene-detection", 
            "text": "What does it do?  KMA (k-mer alignment) is a program developed by the Center for Genomic Epidemiology (CGE) to align gene targets to sequence assemblies or raw-reads. This redmine automator tool currently allows analysis for antimicrobial, biocide, and metal resistance, or a custom set of user targets in sequence data.  For more information, see the  KMA publication , and/or the  CGE website .  If you publish data using this automator, don't forget to cite the authors of the tool  Clausen et al., 2018  How do I use it?  Subject  In the  Subject  field, put  kma . Spelling counts, but case sensitivity doesn't.  Description  Required Components  The first line of the description should be the analysis you would like to run (e.g.  analysis=amr ). This will depend on the type of sequence data your are investigating.   The following options are currently supported:  amr  - used for antimicrobial resistance gene detection  biocide  - used for biocide resistance gene detection  metal  - used for metal resistance gene detection  bacmet  - used for metal resistance gene detection using the  BacMet database , which was converted to nucleotide format by James Robertson (reference to follow)  custom  - gene detection using a custom target database uploaded by the user. The attached file  MUST  be named  targets.fasta . The output csv file will use your fasta-file gene headers as names.    Bacterial Integrative and Conjugative Elements (ICEs)  ICEberg databases  from the  ICEfinder publication : CAUTION: the ICEfinder webtool seems to work differently than KMA, and may detect ICEs where KMA does not  all_ices  - used for all ICE gene detection  aice  - used for actinomycete (AICEs) type ICE gene detection  cime  - used for cis-mobilizable elements (CIMEs) ICE gene detection  ime  - used for Integrative and Mobilizable Elements (IME) type ICE gene detection  t4ss  - used for Type IV Secretion System (T4SS) type ICE gene detection     You must also include a list of SEQIDs one per line.  Optional Components  By default, KMA will run the analysis for isolate assemblies. In order to customise your CARD-RGI analyses, additional settings can be optionally modified:    seqtype  - the default analysis will use genome assemblies.   default is  fasta    If you want to analyse raw-read data, add the following line:  seqtype=fastq  seqtype=minionfastq    Note: seqtype for minion raw-reads is slightly different, as KMA uses different commands for paired-end (illumina) and single-end (nanopore) data     nanopore  - the default analysis will be for short-read Illumina data.  This function is for assemblies   default is  False    If you want to analyse long-read Nanopore data, add a line to your description:  nanopore=TRUE       min_ID  - Use this option to specify the minimum template identity (i.e. relatedness to gene(s) in your database), in percent, needed in order to report a template as a hit.   default is  False    If you want to analyse long-read Nanopore data, add a line to your description (example is for matches greater than 90%):  min_ID=90       readcount  - the default analysis will only output a csv file containing information on matching target gene(s) presence including template identity, coverage, depth, etc. This flag will output read-mapping data for your targets.  This function is best used with raw-reads - Assembly analysis will likely only report 1 read mapping to each gene-target   default is  False    If you want the analysis to output a file including information on the number of reads in your sequence mapping to each database-target, add a line to your description:  readcount=TRUE       align  - Create consensus alignment files  .fsa and  .aln.   default is  False  If you want the analysis to create additional alignment files, add a line to your description:  align=TRUE       vcf  - Produce vcf-files, including any positions different from the template. This will use \"-vcf 2\" which applies the filter used for basecalling.  This function will make KMA run longer   default is  False  If you want the analysis to output a vcf file for each sequence, add a line to your description:  vcf=TRUE       hmm  - Use a HMM (Hidden Markov Model) to identify high scoring subsequences within the query.   default is  False  If you want the analysis to use HMM, add a line to your description:  hmm=TRUE       Example  For an example KMA analysis, see  issue 28117 . The zip file has been attached to this request as an example (the ftp links expire after approx. 2 weeks).  Interpreting Results  KMA will upload a zipped folder called  kma_output_redmineID.zip  to the ftp once it has completed. This will contain a  kma_output.csv file with the target-hits/results for all of the sequences requested in the analysis. Just because a gene/resistance is listed here does not necessarily mean the strain carries that resistance - it's important\nto look at the  Template_Identity  and  Template_Coverage  columns. You can be pretty sure that anything with 100 for both\nis actually there, but anything else requires further analysis to be sure.  Databases Provided with the Automator  The databases for AMR, biocide, and metal resistance were derived from the NCBI  AMRFinderPlus database , version 3.11 downloaded on 2023-10-27. This database was then manually curated and split into separate AMR, biocide, and metal resistance databases. The following genes were added to the biocide resistance database, as they were of interest for some research projects:  -sugE_sugE_quaternary_ammonium_compound_efflux_NC_011514.1:c6661-6344\n-sugE_sugE_quaternary_ammonium_compound_efflux_NC_003197.2:4581504-4581833\n-sugE_sugE_quaternary_ammonium_compound_efflux_NC_017731.1:2886005-2886319\n-sugE_sugE_quaternary_ammonium_compound_efflux_NC_020418.1:c2409693-2409373\n-sugE_sugE_quaternary_ammonium_compound_efflux_NC_016830.1:5098537-5098851\n-sugE(p)_sugESalmonella_quaternary_ammonium_compound_efflux_NC_010259.1:c4461-4144\n-sugE(c)_sugESalmonella_quaternary_ammonium_compound_efflux_NC_003198.1:4557993-4558310\n-sugE(p)_sugEEcoli_quaternary_ammonium_compound_efflux_NC_019069.1:c60194-59877\n-sugE(p)_sugEEcoli_quaternary_ammonium_compound_efflux_KC285365.1\n-sugE(c)_sugEEcoli_quaternary_ammonium_compound_efflux_LT903847.1:c240852-240535\n-bcrA_bcrABC_Listeria_benzalkonium_chloride_efflux_JX023276.1:106-645\n-bcrB_bcrABC_Listeria_benzalkonium_chloride_efflux_JX023276.1:657-974\n-bcrC_bcrABC_Listeria_benzalkonium_chloride_efflux_JX023276.1:992-1336\n-qacH_qacH_Listeria_quaternary_ammonium_compound_efflux_HG329628.1:983-1354\n-emrE_emrE_Listeria_Listeria_quaternary_ammonium_compound_resistance_NC_013768.1:1817073-1817396\n-qacA_qacA_Listeria_quaternary_ammonium_compound_efflux_KC980922.1\n-qacC_qacC_Listeria_quaternary_ammonium_compound_efflux_RJZ34303\n-qacED1_qacED1_Acinetobacter_quaternary_ammonium_compound_efflux_KM972592.1\n-mdfA_multidrug_efflux_pump_NC_00913.3:883673-884905  A verotoxin gene database has also been provided, which has been curated by our lab. Please contact Catherine Carrillo for more information.  How long does it take?  KMA is very fast, however the time required for analysis will depend on the analysis type and number of sequences requested.  What can go wrong?  1) Requested SEQIDs are not available. If we can't find some of the SEQIDs that you request, you will get a warning message informing you of it.  2) A custom analysis was requested but  targets.fasta  file was not attached. You will get a warning message informing you of it.  Version (as of 2023-12-20)  KMA version = 1.4.9  NCBI AMRFinderPlus database (used for amr, biocide, and metal detection) = 3.11", 
            "title": "KMA - Gene Detection"
        }, 
        {
            "location": "/analysis/kraken2/", 
            "text": "Kraken2\n\n\nWhat does it do?\n\n\nKraken2 is a program for taxonomic sequence classification.\n\n\nFor more information, see the \nKraken2 github\n, and/or the protocol paper describing use of \nKraken2\n.\n\n\nIf you publish data using this automator, don't forget to cite the authors of the tool \nWood and Salzberg, 2014\n and the Kraken2 paper \nWood et al., 2019\n\n\nHow do I use it?\n\n\nSubject\n\n\nIn the \nSubject\n field, put \nkraken2\n. Spelling counts, but case sensitivity doesn't.\n\n\nDescription\n\n\nRequired Components\n\n\nYou must include a list of SEQIDs one per line.\n\n\nOptional Components\n\n\nIn order to customise your analyses, additional settings can be optionally modified:\n\n\n\n\n\n\nseqtype\n - By default, the Kraken2 will assume you are running an analysis on paired-end raw sequence data.\n\n\n\n\ndefault is \npaired\n \n\n\nIf you want to analyse long-read nanopore or assembly data, add the following line:\n\n\nseqtype=nanopore\n\n\nseqtype=assembly\n\n\n\n\n\n\n\n\n\n\n\n\ndatabase\n - the default analysis will utilize the Kraken2 standard database (9/26/2022) from \nKraken2 index zone\n.\n\n\n\n\ndefault is \nkraken2\n \n\n\nIf you want to analyse using a different database, the following options are currently supported:\n\n\ndatabase=greengenes\n\n\ndatabase=plusPF\n\n\ndatabase=rdp\n\n\ndatabase=silva\n\n\n\n\n\n\n\n\n-\nThe kraken2 and plusPF databases are meant for metagenomes, all others are 16S based databases\n\n\n\n\n\n\nExample\n\n\nFor an example kraken2 analysis, see \nissue 29355\n. The zip file has been attached to this request as an example (the ftp links expire after approx. 2 weeks).\n\n\nInterpreting Results\n\n\nKraken2 will upload a zipped folder called \nkraken2_output_redmineID.zip\n to the ftp once it has completed. This will contain report files for kraken2 and bracken analyses.\n\n\nHow long does it take?\n\n\nKraken2 is much faster than the original kraken, however the time required for analysis will depend on the analysis type and number of sequences requested. If too many sequences are requested at once, the automator may run out of memory and fail. Please try to keep it to 10 metagenomes maximum.\n\n\nWhat can go wrong?\n\n\n1) Requested SEQIDs are not available. If we can't find some of the SEQIDs that you request, you will get a warning message informing you of it.", 
            "title": "Kraken2"
        }, 
        {
            "location": "/analysis/kraken2/#kraken2", 
            "text": "What does it do?  Kraken2 is a program for taxonomic sequence classification.  For more information, see the  Kraken2 github , and/or the protocol paper describing use of  Kraken2 .  If you publish data using this automator, don't forget to cite the authors of the tool  Wood and Salzberg, 2014  and the Kraken2 paper  Wood et al., 2019  How do I use it?  Subject  In the  Subject  field, put  kraken2 . Spelling counts, but case sensitivity doesn't.  Description  Required Components  You must include a list of SEQIDs one per line.  Optional Components  In order to customise your analyses, additional settings can be optionally modified:    seqtype  - By default, the Kraken2 will assume you are running an analysis on paired-end raw sequence data.   default is  paired    If you want to analyse long-read nanopore or assembly data, add the following line:  seqtype=nanopore  seqtype=assembly       database  - the default analysis will utilize the Kraken2 standard database (9/26/2022) from  Kraken2 index zone .   default is  kraken2    If you want to analyse using a different database, the following options are currently supported:  database=greengenes  database=plusPF  database=rdp  database=silva     - The kraken2 and plusPF databases are meant for metagenomes, all others are 16S based databases    Example  For an example kraken2 analysis, see  issue 29355 . The zip file has been attached to this request as an example (the ftp links expire after approx. 2 weeks).  Interpreting Results  Kraken2 will upload a zipped folder called  kraken2_output_redmineID.zip  to the ftp once it has completed. This will contain report files for kraken2 and bracken analyses.  How long does it take?  Kraken2 is much faster than the original kraken, however the time required for analysis will depend on the analysis type and number of sequences requested. If too many sequences are requested at once, the automator may run out of memory and fail. Please try to keep it to 10 metagenomes maximum.  What can go wrong?  1) Requested SEQIDs are not available. If we can't find some of the SEQIDs that you request, you will get a warning message informing you of it.", 
            "title": "Kraken2"
        }, 
        {
            "location": "/analysis/mashtree/", 
            "text": "MashTree\n\n\nWhat does it do?\n\n\nMashTree will take a list of SEQIDs, and then create a\nphylogenetic tree using Mash distances. See \nmashtree github\n and the \nmashtree docs\n for more information. (The mashtree docs explains how mash is used to create the phylogeny).\n\n\nIf you use mashtree, please remember to cite \nKatz et al., 2019\n, \nOndov et al., 2016\n and \nOndov et al., 2019\n\n\nHow do I use it?\n\n\nSubject\n\n\nIn the \nSubject\n field, put \nmashtree\n. Spelling counts, but case sensitivity doesn't.\n\n\nDescription\n\n\nRequired Components\n\n\nThe first line of the description should be the analysis you would like to run (e.g. \nanalysis=custom\n). \n\n\n\n\nThe following options are currently supported:\n\n\ncustom\n - compare only the SEQIDs listed in the description\n\n\nenterobacterales\n - compare the listed SEQIDs to a set of reference sequences for species from the order Enterobacterales\n\n\nlisteriaceae\n - compare the listed SEQIDs to a set of reference sequences for species from the family Listeriaceae\n\n\n\n\n\n\n\n\nYou must also include a list of SEQIDs one per line.\n\n\nOptional Components\n\n\n\n\n\n\ngenomesize: \n\n\n\n\ndefault is \n5000000\n \n\n\nIf you want to use a genome size estimate, add a line to your description:\n\n\ngenomesize=3000000\n\n\n\n\n\n\n\n\n\n\n\n\nmindepth - if mindepth is zero, then it will be chosen in a smart but slower method to discard lower-abundance kmers.\n\n\n\n\ndefault is \n5\n \n\n\nIf you want to use a minimum depth, add a line to your description:\n\n\nmindepth=10\n\n\n\n\n\n\n\n\n\n\n\n\nkmerlength - \nMash kmer size\n \"larger k-mers will provide more specificity while smaller k-mers will provide more sensitivity. (Larger genomes will also require larger k-mers to avoid k-mers that are shared by chance).\"\n\n\n\n\ndefault is \n21\n \n\n\nIf you want to change the k-mer size, add a line to your description:\n\n\nkmerlength=30\n\n\n\n\n\n\n\n\n\n\n\n\nsketch-size - \nMash sketch size\n \"corresponds to the number of (non-redundant) min-hashes that are kept. Larger sketches will better represent the sequence, but at the cost of larger sketch files and longer comparison times.\"\n\n\n\n\ndefault is \n10000\n \n\n\nIf you want to change the mash sketch-size, add a line to your description:\n\n\nsketch-size=1000\n\n\n\n\n\n\n\n\n\n\n\n\nExample\n\n\nFor an example MashTree, see \nissue 26206\n.\n\n\nInterpreting Results\n\n\nUpon completion, you'll be given a treefile.\n\n\nHow long does it take?\n\n\nThis depends largely on the number of strains you want to use to create the tree. It can often be as quick as a few minutes. \n\n\nWhat can go wrong?\n\n\nA few things can go wrong with this process:\n\n\n1) Requested SEQIDs are not available. If we can't find some of the SEQIDs that you request, you will get a warning\nmessage informing you of it.", 
            "title": "Mashtree"
        }, 
        {
            "location": "/analysis/mashtree/#mashtree", 
            "text": "What does it do?  MashTree will take a list of SEQIDs, and then create a\nphylogenetic tree using Mash distances. See  mashtree github  and the  mashtree docs  for more information. (The mashtree docs explains how mash is used to create the phylogeny).  If you use mashtree, please remember to cite  Katz et al., 2019 ,  Ondov et al., 2016  and  Ondov et al., 2019  How do I use it?  Subject  In the  Subject  field, put  mashtree . Spelling counts, but case sensitivity doesn't.  Description  Required Components  The first line of the description should be the analysis you would like to run (e.g.  analysis=custom ).    The following options are currently supported:  custom  - compare only the SEQIDs listed in the description  enterobacterales  - compare the listed SEQIDs to a set of reference sequences for species from the order Enterobacterales  listeriaceae  - compare the listed SEQIDs to a set of reference sequences for species from the family Listeriaceae     You must also include a list of SEQIDs one per line.  Optional Components    genomesize:    default is  5000000    If you want to use a genome size estimate, add a line to your description:  genomesize=3000000       mindepth - if mindepth is zero, then it will be chosen in a smart but slower method to discard lower-abundance kmers.   default is  5    If you want to use a minimum depth, add a line to your description:  mindepth=10       kmerlength -  Mash kmer size  \"larger k-mers will provide more specificity while smaller k-mers will provide more sensitivity. (Larger genomes will also require larger k-mers to avoid k-mers that are shared by chance).\"   default is  21    If you want to change the k-mer size, add a line to your description:  kmerlength=30       sketch-size -  Mash sketch size  \"corresponds to the number of (non-redundant) min-hashes that are kept. Larger sketches will better represent the sequence, but at the cost of larger sketch files and longer comparison times.\"   default is  10000    If you want to change the mash sketch-size, add a line to your description:  sketch-size=1000       Example  For an example MashTree, see  issue 26206 .  Interpreting Results  Upon completion, you'll be given a treefile.  How long does it take?  This depends largely on the number of strains you want to use to create the tree. It can often be as quick as a few minutes.   What can go wrong?  A few things can go wrong with this process:  1) Requested SEQIDs are not available. If we can't find some of the SEQIDs that you request, you will get a warning\nmessage informing you of it.", 
            "title": "MashTree"
        }, 
        {
            "location": "/analysis/metaphlan/", 
            "text": "MetaPhlAn4\n\n\nWhat does it do?\n\n\nMetaPhlAn is a tool for profiling the composition of microbial communities from metagenomic shotgun sequence data.\n\n\nFor more information, see the \nMetaPhlAn 4.0 website\n, and/or the tutorial describing use of \nMetaPhlAn\n.\n\n\nIf you publish data using this automator, don't forget to cite the authors of the tool \nBlanco-M\u00edguez et al., 2023\n.\n\n\nHow do I use it?\n\n\nSubject\n\n\nIn the \nSubject\n field, put \nmetaphlan\n. Spelling counts, but case sensitivity doesn't.\n\n\nDescription\n\n\nRequired Components\n\n\nYou must include a list of SEQIDs one per line.\n\n\nOptional Components\n\n\nIn order to customise your analyses, additional settings can be optionally modified:\n\n\n\n\nanalysis\n - By default, MetaPhlAn4 automator will run analysis for relative abundance with read stats.\n\n\ndefault is \nrel_ab_w_read_stats\n - profiling a metagenomes in terms of relative abundances and estimate the number of reads coming from each clade\n\n\nIf you want a different analysis, add the following line:\n\n\nanalysis=rel_ab\n - profiling a metagenome in terms of relative abundances\n\n\nanalysis=reads_map\n  -  mapping from reads to clades (only reads hitting a marker)\n\n\nanalysis=clade_profiles\n - normalized marker counts for clades with at least a non-null marker\n\n\nanalysis=marker_ab_table\n - normalized marker counts\n\n\nanalysis=marker_counts\n - non-normalized marker counts [use with extreme caution]\n\n\nanalysis=marker_pres_table\n - list of markers present in the sample\n\n\n\n\n\n\n\n\n\n\n\n\nExample\n\n\nFor an example MetaPhlAn4 analysis, see \nissue 30290\n. The zip file has been attached to this request as an example (the ftp links expire after approx. 2 weeks).\n\n\nInterpreting Results\n\n\nMetaPhlAn4 will upload a zipped folder called \nmetaphlan4_output_redmineID.zip\n to the ftp once it has completed. This will contain report files for MetaPhlAn4 and bracken analyses.\n\n\nHow long does it take?\n\n\nThe time required for analysis will depend on the analysis type and number of sequences requested. \n\n\nWhat can go wrong?\n\n\n1) Requested SEQIDs are not available. If we can't find some of the SEQIDs that you request, you will get a warning message informing you of it.\n\n\nVersion\n\n\nMetaPhlAn version 4.0", 
            "title": "Metaphlan"
        }, 
        {
            "location": "/analysis/metaphlan/#metaphlan4", 
            "text": "What does it do?  MetaPhlAn is a tool for profiling the composition of microbial communities from metagenomic shotgun sequence data.  For more information, see the  MetaPhlAn 4.0 website , and/or the tutorial describing use of  MetaPhlAn .  If you publish data using this automator, don't forget to cite the authors of the tool  Blanco-M\u00edguez et al., 2023 .  How do I use it?  Subject  In the  Subject  field, put  metaphlan . Spelling counts, but case sensitivity doesn't.  Description  Required Components  You must include a list of SEQIDs one per line.  Optional Components  In order to customise your analyses, additional settings can be optionally modified:   analysis  - By default, MetaPhlAn4 automator will run analysis for relative abundance with read stats.  default is  rel_ab_w_read_stats  - profiling a metagenomes in terms of relative abundances and estimate the number of reads coming from each clade  If you want a different analysis, add the following line:  analysis=rel_ab  - profiling a metagenome in terms of relative abundances  analysis=reads_map   -  mapping from reads to clades (only reads hitting a marker)  analysis=clade_profiles  - normalized marker counts for clades with at least a non-null marker  analysis=marker_ab_table  - normalized marker counts  analysis=marker_counts  - non-normalized marker counts [use with extreme caution]  analysis=marker_pres_table  - list of markers present in the sample       Example  For an example MetaPhlAn4 analysis, see  issue 30290 . The zip file has been attached to this request as an example (the ftp links expire after approx. 2 weeks).  Interpreting Results  MetaPhlAn4 will upload a zipped folder called  metaphlan4_output_redmineID.zip  to the ftp once it has completed. This will contain report files for MetaPhlAn4 and bracken analyses.  How long does it take?  The time required for analysis will depend on the analysis type and number of sequences requested.   What can go wrong?  1) Requested SEQIDs are not available. If we can't find some of the SEQIDs that you request, you will get a warning message informing you of it.  Version  MetaPhlAn version 4.0", 
            "title": "MetaPhlAn4"
        }, 
        {
            "location": "/analysis/mobsuite/", 
            "text": "MobSuite\n\n\nWhat does it do?\n\n\nMobSuite is a set of tools developed by the Public Health Agency of Canada for detecting plasmids in draft genome\nassemblies. This tool runs the \nmob_recon\n part of the suite, which first detects plasmids in the assemblies, and then\nperforms typing on the plasmids. More details on MobSuite, including fairly extensive details on the output files\nproduced, can be found at the \nMobSuite GitHub repository\n.\n\n\nHow do I use it?\n\n\nSubject\n\n\nIn the \nSubject\n field, put \nMobSuite\n. Spelling counts, but case sensitivity doesn't.\n\n\nDescription\n\n\nAll you need to put in the description is a list of SEQIDs you want to look for plasmids in, one per line.\n\n\nExample\n\n\nFor an example MobSuite, see \nissue 12823\n.\n\n\nInterpreting Results\n\n\nMobSuite outputs quite a few files. The zip file uploaded will have one folder for each SEQID requested.\nWithin each folder, you will find a number of MobSuite output files. Of particular interest is the \ncontig_report.txt\n file,\nwhich assigns each contig in your assembly as chromosomal or plasmid, and has typing info on plasmid-derived contigs.\nFull descriptions of all files can be found at the \nMobSuite GitHub repository\n.\n\n\nHow long does it take?\n\n\nMobSuite works fairly quickly - it should take roughly one minute to analyze each SEQID that you have requested.\n\n\nWhat can go wrong?\n\n\nA few things can go wrong with this process:\n\n\n1) Requested SEQIDs are not available. If we can't find some of the SEQIDs that you request, you will get a warning\nmessage informing you of it.\n\n\n2) FTP timeout. Sometimes, particularly for larger requests, the upload of results to the FTP will run into problems and time out,\nin which case you will likely get an error message similar to this: \n[Errno 104] Connection reset by peer\n. If this occurs,\nyou can either try again later, or, if you had a large request, try splitting it into a few smaller requests. If the\nproblem persists, send us an email and we'll try to get it figured out.", 
            "title": "Mobsuite"
        }, 
        {
            "location": "/analysis/mobsuite/#mobsuite", 
            "text": "What does it do?  MobSuite is a set of tools developed by the Public Health Agency of Canada for detecting plasmids in draft genome\nassemblies. This tool runs the  mob_recon  part of the suite, which first detects plasmids in the assemblies, and then\nperforms typing on the plasmids. More details on MobSuite, including fairly extensive details on the output files\nproduced, can be found at the  MobSuite GitHub repository .  How do I use it?  Subject  In the  Subject  field, put  MobSuite . Spelling counts, but case sensitivity doesn't.  Description  All you need to put in the description is a list of SEQIDs you want to look for plasmids in, one per line.  Example  For an example MobSuite, see  issue 12823 .  Interpreting Results  MobSuite outputs quite a few files. The zip file uploaded will have one folder for each SEQID requested.\nWithin each folder, you will find a number of MobSuite output files. Of particular interest is the  contig_report.txt  file,\nwhich assigns each contig in your assembly as chromosomal or plasmid, and has typing info on plasmid-derived contigs.\nFull descriptions of all files can be found at the  MobSuite GitHub repository .  How long does it take?  MobSuite works fairly quickly - it should take roughly one minute to analyze each SEQID that you have requested.  What can go wrong?  A few things can go wrong with this process:  1) Requested SEQIDs are not available. If we can't find some of the SEQIDs that you request, you will get a warning\nmessage informing you of it.  2) FTP timeout. Sometimes, particularly for larger requests, the upload of results to the FTP will run into problems and time out,\nin which case you will likely get an error message similar to this:  [Errno 104] Connection reset by peer . If this occurs,\nyou can either try again later, or, if you had a large request, try splitting it into a few smaller requests. If the\nproblem persists, send us an email and we'll try to get it figured out.", 
            "title": "MobSuite"
        }, 
        {
            "location": "/analysis/neartree/", 
            "text": "NearTree\n\n\nWhat does it do?\n\n\nNearTree will take a query SEQID, and then find the \nX\n closest strains to it out of a list specified by creating a\nphylogenetic tree and looking for the tips that are closest to your query strain.\n\n\nHow do I use it?\n\n\nSubject\n\n\nIn the \nSubject\n field, put \nNearTree\n. Spelling counts, but case sensitivity doesn't.\n\n\nDescription\n\n\nThe first line of the description should be the number of closest strains you want to your query strain.\nThe second line must say \nquery\n, and the third line should be the query SEQID you want to find close relatives for.\nThe fourth line must say \nreference\n, and every line after that should be a SEQID you want to compare your query to.\n\n\nExample\n\n\nFor an example NearTree, see \nissue 12940\n.\n\n\nInterpreting Results\n\n\nUpon completion, you'll be given a list of the SEQIDs that are closest to the query specified. The most closely related\nwill be listed first, with each SEQID listed after that becoming slightly more distant.\n\n\nHow long does it take?\n\n\nThis depends largely on the number of strains you want to use to create the tree. It can often be as quick as a few minutes\nif you have 10 or less strains, or take several hours if you want a larger (100 or so strain) tree.\n\n\nWhat can go wrong?\n\n\nA few things can go wrong with this process:\n\n\n1) Requested SEQIDs are not available. If we can't find some of the SEQIDs that you request, you will get a warning\nmessage informing you of it.\n\n\n2) Strains too far apart. NearTree will warn you if it thinks that the strains you want to make a tree from are\nnot closely related enough. If you get this warning, you may want to consider creating a new issue while leaving out\nthe strains it says are too far.", 
            "title": "Neartree"
        }, 
        {
            "location": "/analysis/neartree/#neartree", 
            "text": "What does it do?  NearTree will take a query SEQID, and then find the  X  closest strains to it out of a list specified by creating a\nphylogenetic tree and looking for the tips that are closest to your query strain.  How do I use it?  Subject  In the  Subject  field, put  NearTree . Spelling counts, but case sensitivity doesn't.  Description  The first line of the description should be the number of closest strains you want to your query strain.\nThe second line must say  query , and the third line should be the query SEQID you want to find close relatives for.\nThe fourth line must say  reference , and every line after that should be a SEQID you want to compare your query to.  Example  For an example NearTree, see  issue 12940 .  Interpreting Results  Upon completion, you'll be given a list of the SEQIDs that are closest to the query specified. The most closely related\nwill be listed first, with each SEQID listed after that becoming slightly more distant.  How long does it take?  This depends largely on the number of strains you want to use to create the tree. It can often be as quick as a few minutes\nif you have 10 or less strains, or take several hours if you want a larger (100 or so strain) tree.  What can go wrong?  A few things can go wrong with this process:  1) Requested SEQIDs are not available. If we can't find some of the SEQIDs that you request, you will get a warning\nmessage informing you of it.  2) Strains too far apart. NearTree will warn you if it thinks that the strains you want to make a tree from are\nnot closely related enough. If you get this warning, you may want to consider creating a new issue while leaving out\nthe strains it says are too far.", 
            "title": "NearTree"
        }, 
        {
            "location": "/analysis/plasmidborneidentity/", 
            "text": "Plasmid-Borne Identity\n\n\n\n\nWhat does it do?\n\n\nPlasmid-Borne Identity performs GeneSeekr and MOB-suite analyses on FASTA files, and creates a report combining and \nsummarising the outputs.\n\n\nMobSuite is a set of tools developed by the Public Health Agency of Canada for detecting plasmids in draft genome\nassemblies. This tool runs the \nmob_recon\n part of the suite, which first detects plasmids in the assemblies, and then\nperforms typing on the plasmids. More details on MobSuite, including fairly extensive details on the output files\nproduced, can be found at the \nMobSuite GitHub repository\n).\n\n\nHow do I use it?\n\n\nSubject\n\n\nIn the \nSubject\n field, put \nplasmid_borne_identity\n. Spelling counts, but case sensitivity doesn't.\n\n\nDescription\n\n\nAll you need to put in the description is a list of SEQIDs you want to process, one per line.\n\n\nAttachments\n\n\nYou are required to attach a FASTA-formatted file containing the gene(s) you wish analysed \n\n\nOptional arguments\n\n\n\n\nBLAST program. \nNOTE:\n GeneSeekr (and therefore PlasmidBorne Identity) does not check to see if your query or \ndatabase are the appropriate molecule for the requested program. \n\n\ndefault is \nblastn\n\n\nYou can select one of the following BLAST programs to use:\n\n\nblastn - nt query: nt db\n\n\nblastp - protein query: protein db\n\n\nblastx - translated nt query: protein db\n\n\ntblastn - protein query: translated nt db\n\n\ntblastx - translated nt query: translated nt db\n\n\n\n\n\n\nmodify as follows:\n\n\nblast=tblastx\n\n\n\n\n\n\n\n\n\n\nMinimum cutoff for matches to be included in report.\n\n\ndefault is \n70\n\n\nmodify as follows:\n\n\ncutoff=80\n\n\n\n\n\n\n\n\n\n\nE-value cutoff\n\n\ndefault is \n1E-05\n\n\nmodify as follows:\n\n\nevalue=1E-10\n or\n\n\nevalue=0.01\n\n\n\n\n\n\n\n\n\n\n\n\nExample\n\n\nFor an example Plasmid-Borne Identity analysis, see \nissue 15644\n.\n\n\nInterpreting Results\n\n\nPlasmid-Borne Identity will upload five separate reports once it is complete\n\n\ngeneseekr_{BLAST_PROGRAM}.xlsx\n strain name and percent identity match for all query genes\n\n\ngeneseekr_{BLAST_PROGRAM}_detailed.csv\n strain name, and BLAST summary information, including percent match, alignment length, \nsubject length, e-value, number of positives, number of mismatches, and number of gaps for every gene\n\n\ngeneseekr_{BLAST_PROGRAM}.csv\n  same as \ngeneseekr_{BLAST_PROGRAM}.csv\n  same as, but in .csv format\n\n\nmob_recon_summary.csv\n shows any contigs that are predicted to be plasmids - note that all contigs calculated to be \nchromosomal are ignored. \nLocation\n is the name of the predicted plasmid, while \nContig\n is the name contig \npredicted to contain plasmid sequence. One plasmid can be composed of several contigs if it could not be circularised.\n\n\nplasmid_borne_summary.csv\n combines information from \ngeneseekr_{BLAST_PROGRAM}.csv\n  and \nmob_recon_summary.csv\n. \nThe contigs of all predicted AMR genes from the \ngeneseekr_{BLAST_PROGRAM}_detailed.csv\n report are used to search \nthe \nmob_recon_summary\n report. The plasmid predictions, and well as all the incompatibility types for that plasmid \nare extracted, and used in the report. \nLocation\n will specify either \nchromosome\n or the name of the predicted plasmid.\n\n\nHow long does it take?\n\n\nGeneSeekr is very fast, while MOB-suite is relatively slow - it should take a few minutes to analyze each SEQID requested.\n\n\nWhat can go wrong?\n\n\n\n\nRequested SEQIDs are not available. If we can't find some of the SEQIDs that you request, you will get a warning\nmessage informing you of it.\n\n\nIssue with required FASTA-formatted targets file, including not attaching the file, or the FASTA formatting being incorrect\n\n\nSpecifying the incorrect BLAST analysis program for the provided sequences e.g. blastp with a nucleotide query and db", 
            "title": "Plasmidborneidentity"
        }, 
        {
            "location": "/analysis/plasmidborneidentity/#plasmid-borne-identity", 
            "text": "What does it do?  Plasmid-Borne Identity performs GeneSeekr and MOB-suite analyses on FASTA files, and creates a report combining and \nsummarising the outputs.  MobSuite is a set of tools developed by the Public Health Agency of Canada for detecting plasmids in draft genome\nassemblies. This tool runs the  mob_recon  part of the suite, which first detects plasmids in the assemblies, and then\nperforms typing on the plasmids. More details on MobSuite, including fairly extensive details on the output files\nproduced, can be found at the  MobSuite GitHub repository ).  How do I use it?  Subject  In the  Subject  field, put  plasmid_borne_identity . Spelling counts, but case sensitivity doesn't.  Description  All you need to put in the description is a list of SEQIDs you want to process, one per line.  Attachments  You are required to attach a FASTA-formatted file containing the gene(s) you wish analysed   Optional arguments   BLAST program.  NOTE:  GeneSeekr (and therefore PlasmidBorne Identity) does not check to see if your query or \ndatabase are the appropriate molecule for the requested program.   default is  blastn  You can select one of the following BLAST programs to use:  blastn - nt query: nt db  blastp - protein query: protein db  blastx - translated nt query: protein db  tblastn - protein query: translated nt db  tblastx - translated nt query: translated nt db    modify as follows:  blast=tblastx      Minimum cutoff for matches to be included in report.  default is  70  modify as follows:  cutoff=80      E-value cutoff  default is  1E-05  modify as follows:  evalue=1E-10  or  evalue=0.01       Example  For an example Plasmid-Borne Identity analysis, see  issue 15644 .  Interpreting Results  Plasmid-Borne Identity will upload five separate reports once it is complete  geneseekr_{BLAST_PROGRAM}.xlsx  strain name and percent identity match for all query genes  geneseekr_{BLAST_PROGRAM}_detailed.csv  strain name, and BLAST summary information, including percent match, alignment length, \nsubject length, e-value, number of positives, number of mismatches, and number of gaps for every gene  geneseekr_{BLAST_PROGRAM}.csv   same as  geneseekr_{BLAST_PROGRAM}.csv   same as, but in .csv format  mob_recon_summary.csv  shows any contigs that are predicted to be plasmids - note that all contigs calculated to be \nchromosomal are ignored.  Location  is the name of the predicted plasmid, while  Contig  is the name contig \npredicted to contain plasmid sequence. One plasmid can be composed of several contigs if it could not be circularised.  plasmid_borne_summary.csv  combines information from  geneseekr_{BLAST_PROGRAM}.csv   and  mob_recon_summary.csv . \nThe contigs of all predicted AMR genes from the  geneseekr_{BLAST_PROGRAM}_detailed.csv  report are used to search \nthe  mob_recon_summary  report. The plasmid predictions, and well as all the incompatibility types for that plasmid \nare extracted, and used in the report.  Location  will specify either  chromosome  or the name of the predicted plasmid.  How long does it take?  GeneSeekr is very fast, while MOB-suite is relatively slow - it should take a few minutes to analyze each SEQID requested.  What can go wrong?   Requested SEQIDs are not available. If we can't find some of the SEQIDs that you request, you will get a warning\nmessage informing you of it.  Issue with required FASTA-formatted targets file, including not attaching the file, or the FASTA formatting being incorrect  Specifying the incorrect BLAST analysis program for the provided sequences e.g. blastp with a nucleotide query and db", 
            "title": "Plasmid-Borne Identity"
        }, 
        {
            "location": "/analysis/pointfinder/", 
            "text": "PointFinder\n\n\nWhat does it do?\n\n\nPointFinder is a program complementary to ResFinder developed by the Danish Center for Genomic Epidemiology\nfor detection of antibiotic resistance in draft genome assemblies. Unlike ResFinder, PointFinder looks for point\nmutations that are known to confer antibiotic resistance.\n\n\nHow do I use it?\n\n\nSubject\n\n\nIn the \nSubject\n field, put \nPointFinder\n. Spelling counts, but case sensitivity doesn't.\n\n\nDescription\n\n\nAll you need to put in the description is a list of SEQIDs you want to detect AMR in, one per line.\nNote that PointFinder is limited to detecting mutations in a few genera:\n\n\n\n\nCampylobacter\n\n\nEscherichia\n\n\nMycobacterium\n\n\nNeisseria\n\n\nSalmonella\n\n\n\n\nOur PointFinder automator will automatically determine the genus of your requested SEQIDs, and will not attempt to\nanalyze any SEQIDs that are not from one of these genera.\n\n\nExample\n\n\nFor an example PointFinder, see \nissue 12933\n.\n\n\nInterpreting Results\n\n\nPointFinder will upload a zip file called \npointfinder_output.zip\n. Within this folder, you will find 3 files per\nSEQID:\n\n\nNote: Any SEQIDs that had no resistance detected will not have any files uploaded\n\n\n\n\nSEQID_blastn_PointFinder_prediction.txt: Has each antibiotic for with known mutations for the genus of interest.\nAnything with a 0 had no detected mutations, anything other had predicted point mutation(s) for that antibiotic.\n\n\nSEQID_blastn_PointFinder_results.txt: A file listing the genes that had mutations, what they were, and what resistance those\nmutations confer.\n\n\nSEQID_blastn_PointFinder_table.txt: Much the same as the _results.txt file, but also lists known AMR genes that\ndid not have point mutations.\n\n\n\n\nHow long does it take?\n\n\nPointFinder should take 30 seconds to 1 minutes for analysis of each sample.\n\n\nWhat can go wrong?\n\n\n1) Requested SEQIDs are not available: If we can't find some of the SEQIDs that you request, you will get a warning\nmessage informing you of it.\n\n\n2) Can't run on requested genera: If the SEQIDs you request are not one of the genera that PointFinder works on,\nyou will get a message saying so. PointFinder will still run on any SEQIDs specified that are from the correct genera.", 
            "title": "Pointfinder"
        }, 
        {
            "location": "/analysis/pointfinder/#pointfinder", 
            "text": "What does it do?  PointFinder is a program complementary to ResFinder developed by the Danish Center for Genomic Epidemiology\nfor detection of antibiotic resistance in draft genome assemblies. Unlike ResFinder, PointFinder looks for point\nmutations that are known to confer antibiotic resistance.  How do I use it?  Subject  In the  Subject  field, put  PointFinder . Spelling counts, but case sensitivity doesn't.  Description  All you need to put in the description is a list of SEQIDs you want to detect AMR in, one per line.\nNote that PointFinder is limited to detecting mutations in a few genera:   Campylobacter  Escherichia  Mycobacterium  Neisseria  Salmonella   Our PointFinder automator will automatically determine the genus of your requested SEQIDs, and will not attempt to\nanalyze any SEQIDs that are not from one of these genera.  Example  For an example PointFinder, see  issue 12933 .  Interpreting Results  PointFinder will upload a zip file called  pointfinder_output.zip . Within this folder, you will find 3 files per\nSEQID:  Note: Any SEQIDs that had no resistance detected will not have any files uploaded   SEQID_blastn_PointFinder_prediction.txt: Has each antibiotic for with known mutations for the genus of interest.\nAnything with a 0 had no detected mutations, anything other had predicted point mutation(s) for that antibiotic.  SEQID_blastn_PointFinder_results.txt: A file listing the genes that had mutations, what they were, and what resistance those\nmutations confer.  SEQID_blastn_PointFinder_table.txt: Much the same as the _results.txt file, but also lists known AMR genes that\ndid not have point mutations.   How long does it take?  PointFinder should take 30 seconds to 1 minutes for analysis of each sample.  What can go wrong?  1) Requested SEQIDs are not available: If we can't find some of the SEQIDs that you request, you will get a warning\nmessage informing you of it.  2) Can't run on requested genera: If the SEQIDs you request are not one of the genera that PointFinder works on,\nyou will get a message saying so. PointFinder will still run on any SEQIDs specified that are from the correct genera.", 
            "title": "PointFinder"
        }, 
        {
            "location": "/analysis/primerfinder/", 
            "text": "PrimerFinder\n\n\nWhat does it do?\n\n\nThe PrimerFinder performs \nin silico\n PCR analyses on FASTA and FASTQ formatted files.\n\n\nThere are two different modules:\n\n\n \n\n\nPrimerFinder Legacy\n computes primer binding and amplicon statistics on FASTA formatted files using the now retired ePCR \nsuite of tools from NCBI. \n\n\nPrimerFinder Supremacy\n is able to process FASTA- and FASTQ-formatted files. If using FASTQ files, \n\nBBMap\n is employed to bait out reads containing primer sequences. A second \nround of baiting is performed using the previously-baited reads. Contigs are assembled by \n\nSPAdes\n with only the baited reads. \n\n\nFor both FASTA-formatted files and contigs assembled from FASTQ-formatted files, primers are \nBLASTed against contigs, and outputs are parsed to determine primer binding, and amplicon statistics\n\n\nHow do I use it?\n\n\nSubject\n\n\nIn the \nSubject\n field, put \nprimer_finder\n. Spelling counts, but case sensitivity does not.\n\n\nDescription\n\n\nIn the \nDescription\n field, you must provide:\n\n\nRequired Components\n\n\n\n\n\n\nprogram=requested_program\n\n\n\n\nacceptable programs are \nlegacy\n and \nsupremacy\n\n\n\n\n\n\n\n\nanalysis=requested_analysis\n\n\n\n\n\n\nacceptable analyses are \ncustom\n and \nvtyper\n\n\n\n\n\n\ncustom\n analyses require a FASTA-formatted file of primers you wish to use (see Attachments section for \nadditional details)\n\n\n\n\n\n\nvtyper\n analyses will use the primer set from the vtyper tool\n\n\n\n\n\n\n\n\n\n\n\n\n\n\na list of SEQIDs (one per line)\n\n\n\n\n\n\nOptional Components\n\n\nIn order to customise your PrimerFinder analyses, several settings can be optionally modified\n\n\n\n\nNumber of mismatches allowed.\n\n\ndefault is \n2\n\n\noptions are \n0\n, \n1\n, \n2\n, \n3\n. Anything else will return an error\n\n\nmodify as follows:\n\n\nmismatches=1\n\n\n\n\n\n\n\n\n\n\nFormat of sequence files to use (note that PrimerFinder legacy will still use FASTA-formatted files even if you try \nto specify FASTQ)\n\n\ndefault is \nfasta\n\n\noptions are: \nfasta\n and \nfastq\n\n\nmodify as follows:\n\n\nformat=fastq\n\n\n\n\n\n\n\n\n\n\nK-mer size to use for SPAdes assembly\n\n\ndefault is \n55,77,99,127\n\n\neither provide and integer, e.g. \n33\n, or a comma-separated list, e.g. \n21,33,55\n\n\nmodify as follows:\n\n\nkmersize=33\n \nOR\n\n\nkmersize=21,33,55\n\n\n\n\n\n\n\n\n\n\nExport amplicons in PrimerFinder Legacy (amplicons are created by default by PrimerFinder Supremacy)\n\n\ndefault is \nFalse\n\n\nmodify as follows:\n\n\nexportamplicons\n\n\n\n\n\n\n\n\n\n\n\n\nAttachments\n\n\nFor \ncustom\n analyses, you are required to attach a FASTA-formatted file containing the primer set(s) you wish analysed. \nThe file must have the following format:\n\n\ngene1-F\nseq\n\ngene1-R\nseq\n\ngene2-F1\nseq\n\ngene2-R1\nseq\n\ngene2-F2\nseq\n\ngene2-R2\nseq\n.....\n\n\n\nYou are allowed to use IUPAC degenerate bases in this file. \n\nPlease don't add too many degenerate bases, as the number of primers combinations can increase quickly.\n\n\n# Dictionary of degenerate IUPAC codes\niupac = {\n    'R': ['A', 'G'],\n    'Y': ['C', 'T'],\n    'S': ['C', 'G'],\n    'W': ['A', 'T'],\n    'K': ['G', 'T'],\n    'M': ['A', 'C'],\n    'B': ['C', 'G', 'T'],\n    'D': ['A', 'G', 'T'],\n    'H': ['A', 'C', 'T'],\n    'V': ['A', 'C', 'G'],\n    'N': ['A', 'C', 'G', 'T'],\n    '-': ['-']\n}\n\n\n\nExamples\n\n\nExample PrimerFinder analyses:\n\n\nPrimerFinder Legacy, custom analyses \nissue 16084\n\n\nPrimerFinder Legacy, vtyper analyses \nissue 16085\n\n\nPrimerFinder Supremacy, custom analyses, FASTA format \nissue 16086\n\n\nPrimerFinder Supremacy, custom analyses, FASTQ format \nissue 16087\n\n\nInterpreting Results\n\n\nPrimerFinder Legacy\n\n\nPrimerFinder Legacy will upload \nePCR_report.csv\n, which contains the strain name, gene name as parsed from the primer \nfile, location of the calculated amplicon, the size of the amplicon, the name of the contig on which the amplicon was \nfound, the total number of mismatches between the primer set and the target sequence, and the primers used to create the amplicon.\n\n\nHere's an example created using the example primer file from the \nAttachments\n section of Redmine \nissue 16084\n\n\n\n\n\n\n\n\nSample\n\n\nGene\n\n\nGenomeLocation\n\n\nAmpliconSize\n\n\nContig\n\n\nTotalMismatches\n\n\nPrimerSet\n\n\n\n\n\n\n\n\n\n\n2014-SEQ-1390\n\n\ngene1\n\n\n30506-30699\n\n\n194\n\n\ncontig_1\n\n\n0\n\n\ngene1_0_0\n\n\n\n\n\n\n2014-SEQ-1390\n\n\ngene2\n\n\n476139-476423\n\n\n285\n\n\ncontig_32\n\n\n1\n\n\ngene2_1_1\n\n\n\n\n\n\n\n\nNote that the way the primer set is numbered is based on the number of primer sets with the same gene name: \ngene1\n had \none primer set, \ngene1-F\n and \ngene1-R\n, and these are represented as \ngene1_0_0\n. There were two\nprimer sets for \ngene2\n, and in this example \ngene2-F2\n and \ngene2-R2\n annealed (with one mismatch)\n\n\nIf requested, amplicon sequences for each match will be created. Using the same example as above \n2014-SEQ-1390_amplicons.fa\n will contain:\n\n\n2014-SEQ-1390_contig_1_476139_476423_gene1_0_0\namplicon..... \n\n2014-SEQ-1390_contig_32_27409_27668_gene2_1_1\namplicon.....\n\n\n\nPrimerFinder Supremacy\n\n\nPrimerFinder Supremacy will generate \nePCR_report.csv\nwithin the \nconsolidated_report\n folder. This report contains the \nfollowing fields: strain name, gene name parsed from the primer file, location of the amplicon, size of the amplicon, \nname of contig on which the amplicon was found, the forward and reverse primers used to create the amplicon, the number of mismatches for the forward and reverse primers.\n\n\nHere's an example created using the example primer file from the \nAttachments\n section of Redmine \nissue 16084\n\n\n\n\n\n\n\n\nSample\n\n\nGene\n\n\nGenomeLocation\n\n\nAmpliconSize\n\n\nContig\n\n\nForwardPrimers\n\n\nReversePrimers\n\n\nForwardMismatches\n\n\nReverseMismatches\n\n\n\n\n\n\n\n\n\n\n2014-SEQ-1390\n\n\ngene1\n\n\n30506-30699\n\n\n194\n\n\ncontig_1\n\n\ngene1-F_0\n\n\ngene1-R_0\n\n\n0\n\n\n0\n\n\n\n\n\n\n2014-SEQ-1390\n\n\ngene2\n\n\n476139-476423\n\n\n285\n\n\ncontig_32\n\n\ngene2-F2_0\n\n\ngene2-R2_0\n\n\n1\n\n\n0\n\n\n\n\n\n\n\n\nNote that the primer names have \n_0\n appended to the end. In the case of IUPAC bases being present in the primer sequence, this number will be incremented for each primer created to satisfy all possible \ncombinations. \n\n\nAmplicon sequences are always included. Using the same example as above, \n2014-SEQ-1390_amplicons.fa\n will contain:\n\n\n2014-SEQ-1390_contig_1_gene1-F_0_gene1-R_0\namplicon\n\n2014-SEQ-1390_contig_32_gene2-F2_0_gene2-R2_0\namplicon\n\n\n\nRaw BLAST results are also uploaded. In the example above, \n2014-SEQ-1390_rawresults.csv\n will contain:\n\n\n\n\n\n\n\n\nqseqid\n\n\nsseqid\n\n\npositive\n\n\nmismatch\n\n\ngaps\n\n\nevalue\n\n\nbitscore\n\n\nslen\n\n\nlength\n\n\nqstart\n\n\nqend\n\n\nqseq\n\n\nsstart\n\n\nsend\n\n\nsseq\n\n\n\n\n\n\n\n\n\n\ncontig_1\n\n\ngene1-R_0\n\n\n25\n\n\n0\n\n\n0\n\n\n3.07E-07\n\n\n50.1\n\n\n25\n\n\n25\n\n\n476399\n\n\n476423\n\n\nTACGGTTCCTTTGACGGTGCGATGA\n\n\n25\n\n\n1\n\n\nTACGGTTCCTTTGACGGTGCGATGA\n\n\n\n\n\n\ncontig_1\n\n\ngene1-F_0\n\n\n25\n\n\n0\n\n\n0\n\n\n3.07E-07\n\n\n50.1\n\n\n25\n\n\n25\n\n\n476139\n\n\n476163\n\n\nGTGAAATTATCGCCACGTTCGGGCA\n\n\n1\n\n\n25\n\n\nGTGAAATTATCGCCACGTTCGGGCA\n\n\n\n\n\n\ncontig_32\n\n\ngene2-F2_0\n\n\n20\n\n\n1\n\n\n0\n\n\n4.41E-06\n\n\n42.1\n\n\n21\n\n\n21\n\n\n27648\n\n\n27668\n\n\nCGCCTTATTATACGACCAAAG\n\n\n21\n\n\n1\n\n\nCGCCTTATTTTACGACCAAAG\n\n\n\n\n\n\ncontig_32\n\n\ngene2-R2_0\n\n\n20\n\n\n0\n\n\n0\n\n\n1.74E-05\n\n\n40.1\n\n\n20\n\n\n20\n\n\n27409\n\n\n27428\n\n\nTGCCCAAAGCAGAGAGATTC\n\n\n1\n\n\n20\n\n\nTGCCCAAAGCAGAGAGATTC\n\n\n\n\n\n\n\n\nHow long does it take?\n\n\nPrimerFinder Legacy and PrimerFinder Supremacy on FASTA mode are very fast (seconds per sample), while PrimerFinder \nSupremacy FASTQ mode is relatively slow (a few minutes per sample)\n\n\nWhat can go wrong?\n\n\n\n\nRequested SEQIDs are not available. \n\n\nNot including the \nprogram=requested_program\n component, or requesting an unsupported program\n\n\nNot including the \nanalysis=requested_analysis\n component, or requesting an unsupported analysis\n\n\nSpecifying an unsupported number of \nmismatches\n\n\nIncorrectly formatted \nkmersize\n\n\nAttaching an incorrectly formatted primer file, or not including a primer file for \ncustom\n analyses\n\n\n?\n\n\n\n\nIf anything goes wrong, an error message explaining the error should be returned.", 
            "title": "Primerfinder"
        }, 
        {
            "location": "/analysis/primerfinder/#primerfinder", 
            "text": "What does it do?  The PrimerFinder performs  in silico  PCR analyses on FASTA and FASTQ formatted files.  There are two different modules:     PrimerFinder Legacy  computes primer binding and amplicon statistics on FASTA formatted files using the now retired ePCR \nsuite of tools from NCBI.   PrimerFinder Supremacy  is able to process FASTA- and FASTQ-formatted files. If using FASTQ files,  BBMap  is employed to bait out reads containing primer sequences. A second \nround of baiting is performed using the previously-baited reads. Contigs are assembled by  SPAdes  with only the baited reads.   For both FASTA-formatted files and contigs assembled from FASTQ-formatted files, primers are \nBLASTed against contigs, and outputs are parsed to determine primer binding, and amplicon statistics  How do I use it?  Subject  In the  Subject  field, put  primer_finder . Spelling counts, but case sensitivity does not.  Description  In the  Description  field, you must provide:  Required Components    program=requested_program   acceptable programs are  legacy  and  supremacy     analysis=requested_analysis    acceptable analyses are  custom  and  vtyper    custom  analyses require a FASTA-formatted file of primers you wish to use (see Attachments section for \nadditional details)    vtyper  analyses will use the primer set from the vtyper tool        a list of SEQIDs (one per line)    Optional Components  In order to customise your PrimerFinder analyses, several settings can be optionally modified   Number of mismatches allowed.  default is  2  options are  0 ,  1 ,  2 ,  3 . Anything else will return an error  modify as follows:  mismatches=1      Format of sequence files to use (note that PrimerFinder legacy will still use FASTA-formatted files even if you try \nto specify FASTQ)  default is  fasta  options are:  fasta  and  fastq  modify as follows:  format=fastq      K-mer size to use for SPAdes assembly  default is  55,77,99,127  either provide and integer, e.g.  33 , or a comma-separated list, e.g.  21,33,55  modify as follows:  kmersize=33   OR  kmersize=21,33,55      Export amplicons in PrimerFinder Legacy (amplicons are created by default by PrimerFinder Supremacy)  default is  False  modify as follows:  exportamplicons       Attachments  For  custom  analyses, you are required to attach a FASTA-formatted file containing the primer set(s) you wish analysed. \nThe file must have the following format:  gene1-F\nseq gene1-R\nseq gene2-F1\nseq gene2-R1\nseq gene2-F2\nseq gene2-R2\nseq\n.....  You are allowed to use IUPAC degenerate bases in this file.  Please don't add too many degenerate bases, as the number of primers combinations can increase quickly.  # Dictionary of degenerate IUPAC codes\niupac = {\n    'R': ['A', 'G'],\n    'Y': ['C', 'T'],\n    'S': ['C', 'G'],\n    'W': ['A', 'T'],\n    'K': ['G', 'T'],\n    'M': ['A', 'C'],\n    'B': ['C', 'G', 'T'],\n    'D': ['A', 'G', 'T'],\n    'H': ['A', 'C', 'T'],\n    'V': ['A', 'C', 'G'],\n    'N': ['A', 'C', 'G', 'T'],\n    '-': ['-']\n}  Examples  Example PrimerFinder analyses:  PrimerFinder Legacy, custom analyses  issue 16084  PrimerFinder Legacy, vtyper analyses  issue 16085  PrimerFinder Supremacy, custom analyses, FASTA format  issue 16086  PrimerFinder Supremacy, custom analyses, FASTQ format  issue 16087  Interpreting Results  PrimerFinder Legacy  PrimerFinder Legacy will upload  ePCR_report.csv , which contains the strain name, gene name as parsed from the primer \nfile, location of the calculated amplicon, the size of the amplicon, the name of the contig on which the amplicon was \nfound, the total number of mismatches between the primer set and the target sequence, and the primers used to create the amplicon.  Here's an example created using the example primer file from the  Attachments  section of Redmine  issue 16084     Sample  Gene  GenomeLocation  AmpliconSize  Contig  TotalMismatches  PrimerSet      2014-SEQ-1390  gene1  30506-30699  194  contig_1  0  gene1_0_0    2014-SEQ-1390  gene2  476139-476423  285  contig_32  1  gene2_1_1     Note that the way the primer set is numbered is based on the number of primer sets with the same gene name:  gene1  had \none primer set,  gene1-F  and  gene1-R , and these are represented as  gene1_0_0 . There were two\nprimer sets for  gene2 , and in this example  gene2-F2  and  gene2-R2  annealed (with one mismatch)  If requested, amplicon sequences for each match will be created. Using the same example as above  2014-SEQ-1390_amplicons.fa  will contain:  2014-SEQ-1390_contig_1_476139_476423_gene1_0_0\namplicon.....  2014-SEQ-1390_contig_32_27409_27668_gene2_1_1\namplicon.....  PrimerFinder Supremacy  PrimerFinder Supremacy will generate  ePCR_report.csv within the  consolidated_report  folder. This report contains the \nfollowing fields: strain name, gene name parsed from the primer file, location of the amplicon, size of the amplicon, \nname of contig on which the amplicon was found, the forward and reverse primers used to create the amplicon, the number of mismatches for the forward and reverse primers.  Here's an example created using the example primer file from the  Attachments  section of Redmine  issue 16084     Sample  Gene  GenomeLocation  AmpliconSize  Contig  ForwardPrimers  ReversePrimers  ForwardMismatches  ReverseMismatches      2014-SEQ-1390  gene1  30506-30699  194  contig_1  gene1-F_0  gene1-R_0  0  0    2014-SEQ-1390  gene2  476139-476423  285  contig_32  gene2-F2_0  gene2-R2_0  1  0     Note that the primer names have  _0  appended to the end. In the case of IUPAC bases being present in the primer sequence, this number will be incremented for each primer created to satisfy all possible \ncombinations.   Amplicon sequences are always included. Using the same example as above,  2014-SEQ-1390_amplicons.fa  will contain:  2014-SEQ-1390_contig_1_gene1-F_0_gene1-R_0\namplicon 2014-SEQ-1390_contig_32_gene2-F2_0_gene2-R2_0\namplicon  Raw BLAST results are also uploaded. In the example above,  2014-SEQ-1390_rawresults.csv  will contain:     qseqid  sseqid  positive  mismatch  gaps  evalue  bitscore  slen  length  qstart  qend  qseq  sstart  send  sseq      contig_1  gene1-R_0  25  0  0  3.07E-07  50.1  25  25  476399  476423  TACGGTTCCTTTGACGGTGCGATGA  25  1  TACGGTTCCTTTGACGGTGCGATGA    contig_1  gene1-F_0  25  0  0  3.07E-07  50.1  25  25  476139  476163  GTGAAATTATCGCCACGTTCGGGCA  1  25  GTGAAATTATCGCCACGTTCGGGCA    contig_32  gene2-F2_0  20  1  0  4.41E-06  42.1  21  21  27648  27668  CGCCTTATTATACGACCAAAG  21  1  CGCCTTATTTTACGACCAAAG    contig_32  gene2-R2_0  20  0  0  1.74E-05  40.1  20  20  27409  27428  TGCCCAAAGCAGAGAGATTC  1  20  TGCCCAAAGCAGAGAGATTC     How long does it take?  PrimerFinder Legacy and PrimerFinder Supremacy on FASTA mode are very fast (seconds per sample), while PrimerFinder \nSupremacy FASTQ mode is relatively slow (a few minutes per sample)  What can go wrong?   Requested SEQIDs are not available.   Not including the  program=requested_program  component, or requesting an unsupported program  Not including the  analysis=requested_analysis  component, or requesting an unsupported analysis  Specifying an unsupported number of  mismatches  Incorrectly formatted  kmersize  Attaching an incorrectly formatted primer file, or not including a primer file for  custom  analyses  ?   If anything goes wrong, an error message explaining the error should be returned.", 
            "title": "PrimerFinder"
        }, 
        {
            "location": "/analysis/prokka/", 
            "text": "Prokka\n\n\nWhat does it do?\n\n\nProkka annotates genomes, letting you know what genes and other features are present. If you want to \nlearn more about it, check out the \nprokka publication.\n\n\nHow do I use it?\n\n\nSubject\n\n\nIn the \nSubject\n field, put \nProkka\n. Spelling counts, but case sensitivity doesn't.\n\n\nDescription\n\n\nAll you need to put in the description is a list of SEQIDs you want to process, one per line.\n\n\nExample\n\n\nFor an example Prokka, see \nissue 15195\n.\n\n\nInterpreting Results\n\n\nProkka will output a lot of files for each genome you give it - you can find a quick description of\neach file \nhere\n. Of particular interest are the \n.gff\n and \n.gbk\n files.\n\n\nHow long does it take?\n\n\nProkka isn't the quickest thing around - expect it to take 2 to 3 minutes for each genome you give it.\n\n\nWhat can go wrong?\n\n\n\n\nRequested SEQIDs are not available. If we can't find some of the SEQIDs that you request, you will get a warning\nmessage informing you of it.\n\n\nFTP Upload issues. Since the files prokka produces are fairly big, the need to be uploaded to an FTP site. We'll sometimes\nhave connection issues that stop uploads from happening properly. If this is the case, you'll get a message telling you to \ntry again later. FTP connection issues usually only persist for a few hours at a time.", 
            "title": "Prokka"
        }, 
        {
            "location": "/analysis/prokka/#prokka", 
            "text": "What does it do?  Prokka annotates genomes, letting you know what genes and other features are present. If you want to \nlearn more about it, check out the  prokka publication.  How do I use it?  Subject  In the  Subject  field, put  Prokka . Spelling counts, but case sensitivity doesn't.  Description  All you need to put in the description is a list of SEQIDs you want to process, one per line.  Example  For an example Prokka, see  issue 15195 .  Interpreting Results  Prokka will output a lot of files for each genome you give it - you can find a quick description of\neach file  here . Of particular interest are the  .gff  and  .gbk  files.  How long does it take?  Prokka isn't the quickest thing around - expect it to take 2 to 3 minutes for each genome you give it.  What can go wrong?   Requested SEQIDs are not available. If we can't find some of the SEQIDs that you request, you will get a warning\nmessage informing you of it.  FTP Upload issues. Since the files prokka produces are fairly big, the need to be uploaded to an FTP site. We'll sometimes\nhave connection issues that stop uploads from happening properly. If this is the case, you'll get a message telling you to \ntry again later. FTP connection issues usually only persist for a few hours at a time.", 
            "title": "Prokka"
        }, 
        {
            "location": "/analysis/psortb/", 
            "text": "PSORTb\n\n\nWhat does it do?\n\n\nPSORTb is a program developed by the Brinkman lab at Simon Fraser University - it attempts to figure out what\nthe subcellular location of proteins might be. If you wnat to know more, you can check out the \n\nPSORTb publication\n or the \n\nPSORTb documentation\n. \n\n\nHow do I use it?\n\n\nSubject\n\n\nIn the \nSubject\n field, put \nPSORTb\n. Spelling counts, but case sensitivity doesn't.\n\n\nDescription\n\n\nAll you need to put in the description is a list of SEQIDs you want to find protein localizations for, one per line.\n\n\nExample\n\n\nFor an example PSORTb, see \nissue 16061\n.\n\n\nInterpreting Results\n\n\nPSORTb will upload a zip file - this will contain FASTA-formatted proteins as predicted and annotated by prokka, and \na text file for each SEQID that has the predicted subcellular localization for each protein.\n\n\nHow long does it take?\n\n\nPSORTb is pretty slow - expect it to take at least 20 to 30 minutes per SEQID requested.\n\n\nWhat can go wrong?\n\n\n1) Requested SEQIDs are not available: If we can't find some of the SEQIDs that you request, you will get a warning\nmessage informing you of it.\n\n\n2) PSORTb needs to know whether a strain is gram positive or gram negative - you'll see that each of the text files\nyou get have either \ngrampos\n or \ngramneg\n in them, depending on whether or not we predicted that isolate to be gram \npositive or gram negative. We're fairly sure that our classification is fairly robust, but there might be exceptions.\nIf you put an isolate through and it's wrongly classified, email \nandrew.low@canada.ca\n and we'll get it sorted out!", 
            "title": "Psortb"
        }, 
        {
            "location": "/analysis/psortb/#psortb", 
            "text": "What does it do?  PSORTb is a program developed by the Brinkman lab at Simon Fraser University - it attempts to figure out what\nthe subcellular location of proteins might be. If you wnat to know more, you can check out the  PSORTb publication  or the  PSORTb documentation .   How do I use it?  Subject  In the  Subject  field, put  PSORTb . Spelling counts, but case sensitivity doesn't.  Description  All you need to put in the description is a list of SEQIDs you want to find protein localizations for, one per line.  Example  For an example PSORTb, see  issue 16061 .  Interpreting Results  PSORTb will upload a zip file - this will contain FASTA-formatted proteins as predicted and annotated by prokka, and \na text file for each SEQID that has the predicted subcellular localization for each protein.  How long does it take?  PSORTb is pretty slow - expect it to take at least 20 to 30 minutes per SEQID requested.  What can go wrong?  1) Requested SEQIDs are not available: If we can't find some of the SEQIDs that you request, you will get a warning\nmessage informing you of it.  2) PSORTb needs to know whether a strain is gram positive or gram negative - you'll see that each of the text files\nyou get have either  grampos  or  gramneg  in them, depending on whether or not we predicted that isolate to be gram \npositive or gram negative. We're fairly sure that our classification is fairly robust, but there might be exceptions.\nIf you put an isolate through and it's wrongly classified, email  andrew.low@canada.ca  and we'll get it sorted out!", 
            "title": "PSORTb"
        }, 
        {
            "location": "/analysis/pyseer/", 
            "text": "GWAS-pyseer\n\n\nWhat does it do?\n\n\npyseer is a tool for microbial-pangenome wide association studies (mGWAS). It is the reimplementation of \nseer\n. pyseer allows one to analyse a set of genomes for genetic variation associated with bacterial phenotypes (such as antibiotic resistance, virulence, and host specificity). It is strongly suggested that you check out the \npyseer publication\n and \npyseer documentation\n before use to determine which analysis is appropriate for your dataset. If used for publication, dont forget to cite Lees et al., 2018!\n\n\nThis redmine-automator will allow you to conduct a mGWAS using sequence data stored on the OLC-CFIA cluster. There are a few different options available, but if you would like another customisable option added to the automator (see \npyseer documentation\n) please contact an OLC-bioinformatician.\n\n\nHow do I use it?\n\n\nSubject\n\n\nIn the \nSubject\n field, put \npyseer\n. Spelling counts, but case sensitivity doesnt.\n\n\n\n\n\nDescription\n\n\nRequired Components\n\n\nIn the \nDescription\n field, you must include an analysistype as follows:\n\nanalysistype=requested_analysis\n:\n\n\n\n\nkmer\n:\n\n\nWill detect and count k-mers in selected dataset, then use k-mers as a variant to test both short variation and gene presence/absence.\n\n\nThe k-mers will be annotated by the redmine automator using \nprokka\n\n\nIf kmer analysis is selected, it is also suggested that you upload a references.txt file (see description below). \n\n\n\n\n\n\nRoary\n:\n\n\nRoary will use the gene_presence_absence.Rtab file from a previous Roary analysis.\n\n\nTo use this analysis type, you must first run a roary analysis using the OLC Redmine Automator. See the \nroary docs\n for details.\n\n\nYou must then include \nroaryissue=redmine_issue_id\n, where redmine_issue_id is the biorequest number from the roary analysis previously run (this will copy the gene_presence_absence.Rtab file from the previous issue to the current pyseer biorequest). \nPlease note:\n the gene_presence_absence.Rtab files are only retained by the OLC system for requests made after 24-11-2021.\n\n\n\n\n\n\nsnv\n (currently under development):\n\n\nWill test the association of SNPs mapped to a reference.\n\n\n\n\n\n\n\n\nYou \nmust\n attach a traits.tsv file. It must be named \ntraits.tsv\n for the automator to work. This file must contain the SEQ-IDs in the first column, and trait (numerical) in the second column. The automator defaults to \nbinary\n for traits (1,0 - for presence,absence). However, it is possible to use continuous data if you also include \ncontinuous=True\n in the description (default is \ncontinuous=False\n). You may also include \nNA\n if trait was not determined for that sequence.\n\n\nYou must also include a list of SEQIDs one per line.  \n\n\n\n\n\nOptional Components\n\n\nIn order to customise your pyseer analysis, several settings can be modified. These settings will depend on which options were selected.\n\n\nPopulation structure\n\n\nThe first step of pyseer is to estimate the population structure. This can be done a number of ways. \n\n\n\n\nmash\n (default):\n\n\nmash\n is the default distance/phylogeny used by the pyseer automator.\n\n\nuses mash sketch to produce pairwise distance matrix, then calculate distances between all pairs of samples using mash dist.\n\n\na mash tree is also produced, and this phylogeny will be used to create the kinship matrix if the linearmixed association model is chosen\n\n\n\n\n\n\nbcgtree\n: \n\n\nif \nbcgtree\n is selected, you can change a number of parameters. Please see the OLC Redmine Automator documentation for \nbcgtree docs\n for a list of options.\n\n\nbcgtree phylogeny creation will take a while, and required time will increased with larger datasets. It is suggested you run a bcgtree biorequest separately for large datasets.\n\n\na phylogeny is output by bcgtree (RAxML_bestTree.final), which is then used to calculate distances between samples, and/or kinship matrix creation.\n\n\n\n\n\n\ncustom\n:\n\n\nif \ndistance=custom\n is selected, a phylogeny tree file in newick format named \ntree.newick\n must also be attached to the request. \n\n\nThis tree can be created however you'd like, but must be named \ntree.newick\n and the tree tip-labels must be the same as the SEQIDs in the pyseer request\n\n\nthe uploaded phylogeny will then be used for distance calculations between pairs of samples, and/or kinship matrix creation.\n\n\n\n\n\n\n\n\nAssociation models\n\n\nPlease review the \npyseer documentation\n for a description of models. The current association models available for the pyseer automator include:\n\n\n\n\nfixed\n:\n\n\nThe patristic distances between all samples are used\n\n\nA GLM is run on each variant\n\n\n\n\n\n\nlinearmixed\n:\n\n\nA linear mixed model (LMM) of fixed and random effects is fitted to the data\n\n\nThe selected phylogeny will be used to calculate pairwise distances (\nnote\n:mash may be less accurate than other phylogenies).\n\n\nCalculates the similarities between sequences based on the shared branch length between each pair's most recent common ancestor and the root.\n\n\n\n\n\n\n\n\nReferences file for k-mer analysis\n\n\nIf a references file (\nreferences.txt\n) is not uploaded to the redmine request, one will be automatically generated. The benefit of uploading the references file is that you can select a few trusted reference sequences for the annotations. Otherwise, all sequences in the request will be included as \"reference\" quality.\n\n\nThe references are used first, and allow a close match of a k-mer. The drafts are used second, and require an exact match of the k-mer.\n\n\nThis \nreferences.txt\n is a tab-separated file containing the sequence filename, annotation filename, and type of the references to be used (there are no headers required):\n\n\n\n\n\n\n\n\nXXXX-SEQ-0001.fasta\n\n\nXXXX-SEQ-0001.gff\n\n\nref\n\n\n\n\n\n\n\n\n\n\nXXXX-MIN-0001.fasta\n\n\nXXXX-MIN-0001.gff\n\n\nref\n\n\n\n\n\n\nXXXX-SEQ-0002.fasta\n\n\nXXXX-SEQ-0002.gff\n\n\ndraft\n\n\n\n\n\n\nXXXX-SEQ-0340.fasta\n\n\nXXXX-SEQ-0340.gff\n\n\ndraft\n\n\n\n\n\n\n\n\nExample\n\n\nFor an example pyseer issue see \nissue 25083\n. \nNOTE\n: the output files for these issues no longer exist on the ftp server.\n\n\nInterpreting Results\n\n\nThe pyseer automator will upload links to the ftp for files called \npyseer_output.zip\n, and possibly \nprokka_output.zip\n and \nbcgtree_output.zip\n depending on selected options.\n\n\nThe \npyseer_output.zip\n will contain all of the pyseer outputs including the tree files and distance matrices. See \npyseer tutorial\n\n\n\n\nkmer\n analysis will output \npyseer_kmers.txt\n, the significant kmers (\nsignificant_kmers.txt\n), \nannotated_kmers.txt\n, and \ngene_hits.txt\n which is a summary file of the annotated k-mers found by pyseer.\n\n\nthe summarised annotated \ngene_hits.txt\n file can be graphed using R. See the \npyseer tutorial\n\n\n\n\n\n\nroary\n analysis will output a \npyseer_COGs.txt\n (COG = clusters of orthologous groups) file which contains the COGs not filtered out by pyseer. \n\n\nThe first column in this file will contain the gene name (from the roary output gene_presence_absence.Rtab file)\n\n\nIf \nhigh-bse\n or \nbad-chisq\n are listed in the last column, there may be a high effect size/low frequency result (\nhigh-bse\n) or MAF filter may not be stringent enough (\nbad-chisq\n).\n\n\n\n\n\n\n\n\nIf \nanalysistype=kmer\n, and/or \ndistance=bcgtree\n were selected, the automator will upload a link to the ftp \nprokka_output.zip\n. This contains all of the outputs from prokka. Prokka will output a lot of files for each genome you give it - you can find a quick description of\neach file \nhere\n. Of particular interest are the \n.gff\n files, which pyseer uses for annotations.\n\n\nIf \ndistance=bcgtree\n was used for distance/phylogeny, the \nbcgtree_output.zip\n file contains all of the outputs from bcgTree. The alignment files, and gene-id files output by bcgtree can be found in subfolders in the zip file. The most interesting outputs from bcgtree are the RAxML files. These files conaint the phylogenetic trees output by bcgTree: \n\n\nHow long does it take?\n\n\nThis will depend on the number of sequences requested, and the analysis type.\n\n\nK-mer analysis will take hours in order to count the number of k-mers in a large number of sequences.\n\n\nProkka isnt the quickest thing around - expect it to take 2 to 3 minutes for each genome you give it. \n\n\nThe bcgTree pipeline time will depend on the number of sequences and bootstraps requested. If a large number of sequences is being analysed, it is suggested you create a separate issue for phylogeny generation with bcgtree (however this is yet to be tested).\n\n\nWhat can go wrong?\n\n\n\n\nRequested SEQIDs are not available. If we cant find some of the SEQIDs that you request, you will get a warning message informing you of it.\n\n\nA traits.tsv file was not uploaded to redmine. You will get a warning message informing you to re-submit the request.", 
            "title": "Pyseer"
        }, 
        {
            "location": "/analysis/pyseer/#gwas-pyseer", 
            "text": "What does it do?  pyseer is a tool for microbial-pangenome wide association studies (mGWAS). It is the reimplementation of  seer . pyseer allows one to analyse a set of genomes for genetic variation associated with bacterial phenotypes (such as antibiotic resistance, virulence, and host specificity). It is strongly suggested that you check out the  pyseer publication  and  pyseer documentation  before use to determine which analysis is appropriate for your dataset. If used for publication, dont forget to cite Lees et al., 2018!  This redmine-automator will allow you to conduct a mGWAS using sequence data stored on the OLC-CFIA cluster. There are a few different options available, but if you would like another customisable option added to the automator (see  pyseer documentation ) please contact an OLC-bioinformatician.  How do I use it?  Subject  In the  Subject  field, put  pyseer . Spelling counts, but case sensitivity doesnt.   Description  Required Components  In the  Description  field, you must include an analysistype as follows: analysistype=requested_analysis :   kmer :  Will detect and count k-mers in selected dataset, then use k-mers as a variant to test both short variation and gene presence/absence.  The k-mers will be annotated by the redmine automator using  prokka  If kmer analysis is selected, it is also suggested that you upload a references.txt file (see description below).     Roary :  Roary will use the gene_presence_absence.Rtab file from a previous Roary analysis.  To use this analysis type, you must first run a roary analysis using the OLC Redmine Automator. See the  roary docs  for details.  You must then include  roaryissue=redmine_issue_id , where redmine_issue_id is the biorequest number from the roary analysis previously run (this will copy the gene_presence_absence.Rtab file from the previous issue to the current pyseer biorequest).  Please note:  the gene_presence_absence.Rtab files are only retained by the OLC system for requests made after 24-11-2021.    snv  (currently under development):  Will test the association of SNPs mapped to a reference.     You  must  attach a traits.tsv file. It must be named  traits.tsv  for the automator to work. This file must contain the SEQ-IDs in the first column, and trait (numerical) in the second column. The automator defaults to  binary  for traits (1,0 - for presence,absence). However, it is possible to use continuous data if you also include  continuous=True  in the description (default is  continuous=False ). You may also include  NA  if trait was not determined for that sequence.  You must also include a list of SEQIDs one per line.     Optional Components  In order to customise your pyseer analysis, several settings can be modified. These settings will depend on which options were selected.  Population structure  The first step of pyseer is to estimate the population structure. This can be done a number of ways.    mash  (default):  mash  is the default distance/phylogeny used by the pyseer automator.  uses mash sketch to produce pairwise distance matrix, then calculate distances between all pairs of samples using mash dist.  a mash tree is also produced, and this phylogeny will be used to create the kinship matrix if the linearmixed association model is chosen    bcgtree :   if  bcgtree  is selected, you can change a number of parameters. Please see the OLC Redmine Automator documentation for  bcgtree docs  for a list of options.  bcgtree phylogeny creation will take a while, and required time will increased with larger datasets. It is suggested you run a bcgtree biorequest separately for large datasets.  a phylogeny is output by bcgtree (RAxML_bestTree.final), which is then used to calculate distances between samples, and/or kinship matrix creation.    custom :  if  distance=custom  is selected, a phylogeny tree file in newick format named  tree.newick  must also be attached to the request.   This tree can be created however you'd like, but must be named  tree.newick  and the tree tip-labels must be the same as the SEQIDs in the pyseer request  the uploaded phylogeny will then be used for distance calculations between pairs of samples, and/or kinship matrix creation.     Association models  Please review the  pyseer documentation  for a description of models. The current association models available for the pyseer automator include:   fixed :  The patristic distances between all samples are used  A GLM is run on each variant    linearmixed :  A linear mixed model (LMM) of fixed and random effects is fitted to the data  The selected phylogeny will be used to calculate pairwise distances ( note :mash may be less accurate than other phylogenies).  Calculates the similarities between sequences based on the shared branch length between each pair's most recent common ancestor and the root.     References file for k-mer analysis  If a references file ( references.txt ) is not uploaded to the redmine request, one will be automatically generated. The benefit of uploading the references file is that you can select a few trusted reference sequences for the annotations. Otherwise, all sequences in the request will be included as \"reference\" quality.  The references are used first, and allow a close match of a k-mer. The drafts are used second, and require an exact match of the k-mer.  This  references.txt  is a tab-separated file containing the sequence filename, annotation filename, and type of the references to be used (there are no headers required):     XXXX-SEQ-0001.fasta  XXXX-SEQ-0001.gff  ref      XXXX-MIN-0001.fasta  XXXX-MIN-0001.gff  ref    XXXX-SEQ-0002.fasta  XXXX-SEQ-0002.gff  draft    XXXX-SEQ-0340.fasta  XXXX-SEQ-0340.gff  draft     Example  For an example pyseer issue see  issue 25083 .  NOTE : the output files for these issues no longer exist on the ftp server.  Interpreting Results  The pyseer automator will upload links to the ftp for files called  pyseer_output.zip , and possibly  prokka_output.zip  and  bcgtree_output.zip  depending on selected options.  The  pyseer_output.zip  will contain all of the pyseer outputs including the tree files and distance matrices. See  pyseer tutorial   kmer  analysis will output  pyseer_kmers.txt , the significant kmers ( significant_kmers.txt ),  annotated_kmers.txt , and  gene_hits.txt  which is a summary file of the annotated k-mers found by pyseer.  the summarised annotated  gene_hits.txt  file can be graphed using R. See the  pyseer tutorial    roary  analysis will output a  pyseer_COGs.txt  (COG = clusters of orthologous groups) file which contains the COGs not filtered out by pyseer.   The first column in this file will contain the gene name (from the roary output gene_presence_absence.Rtab file)  If  high-bse  or  bad-chisq  are listed in the last column, there may be a high effect size/low frequency result ( high-bse ) or MAF filter may not be stringent enough ( bad-chisq ).     If  analysistype=kmer , and/or  distance=bcgtree  were selected, the automator will upload a link to the ftp  prokka_output.zip . This contains all of the outputs from prokka. Prokka will output a lot of files for each genome you give it - you can find a quick description of\neach file  here . Of particular interest are the  .gff  files, which pyseer uses for annotations.  If  distance=bcgtree  was used for distance/phylogeny, the  bcgtree_output.zip  file contains all of the outputs from bcgTree. The alignment files, and gene-id files output by bcgtree can be found in subfolders in the zip file. The most interesting outputs from bcgtree are the RAxML files. These files conaint the phylogenetic trees output by bcgTree:   How long does it take?  This will depend on the number of sequences requested, and the analysis type.  K-mer analysis will take hours in order to count the number of k-mers in a large number of sequences.  Prokka isnt the quickest thing around - expect it to take 2 to 3 minutes for each genome you give it.   The bcgTree pipeline time will depend on the number of sequences and bootstraps requested. If a large number of sequences is being analysed, it is suggested you create a separate issue for phylogeny generation with bcgtree (however this is yet to be tested).  What can go wrong?   Requested SEQIDs are not available. If we cant find some of the SEQIDs that you request, you will get a warning message informing you of it.  A traits.tsv file was not uploaded to redmine. You will get a warning message informing you to re-submit the request.", 
            "title": "GWAS-pyseer"
        }, 
        {
            "location": "/analysis/resfinder/", 
            "text": "ResFinder\n\n\nWhat does it do?\n\n\nResFinder is a program developed by the Danish Center for Genomic Epidemiology for detection of antibiotic resistance\nin draft genome assemblies. It is very important to note that the Redmine version will only look for acquired antibiotic\nresistance genes (generally plasmid-borne) and not chromosomally encoded AMR genes that are caused by point mutations.\n\n\nIf you're interested in chromosomally encoded AMR genes, use the\n \nPointFinder automator\n, using the \nCARDRGI automator\n, or you can \nExternal Retrieve\n your\nassemblies of interest and submit them to an alternate AMR predictor, such as McMaster's webportal \nCARD\n.\n\n\nHow do I use it?\n\n\nSubject\n\n\nIn the \nSubject\n field, put \nResFinder\n. Spelling counts, but case sensitivity doesn't.\n\n\nDescription\n\n\nAll you need to put in the description is a list of SEQIDs you want to detect AMR in, one per line.\n\n\nExample\n\n\nFor an example ResFinder, see \nissue 12854\n.\n\n\nInterpreting Results\n\n\nResFinder will upload a file called \nresfinder.xlsx\n once it has completed, which shows every AMR gene found in each\nsample. Just because a gene/resistance is listed here does not necessarily mean the strain carries that resistance - it's important\nto look at the \nPercentIdentity\n and \nPercentCovered\n columns. You can be pretty sure that anything with 100 for both\nis actually there, but anything else requires further analysis to be sure.\n\n\nHow long does it take?\n\n\nResFinder is very fast - it should only take a few seconds to analyze each SEQID requested.\n\n\nWhat can go wrong?\n\n\n1) Requested SEQIDs are not available. If we can't find some of the SEQIDs that you request, you will get a warning\nmessage informing you of it.", 
            "title": "Resfinder"
        }, 
        {
            "location": "/analysis/resfinder/#resfinder", 
            "text": "What does it do?  ResFinder is a program developed by the Danish Center for Genomic Epidemiology for detection of antibiotic resistance\nin draft genome assemblies. It is very important to note that the Redmine version will only look for acquired antibiotic\nresistance genes (generally plasmid-borne) and not chromosomally encoded AMR genes that are caused by point mutations.  If you're interested in chromosomally encoded AMR genes, use the\n  PointFinder automator , using the  CARDRGI automator , or you can  External Retrieve  your\nassemblies of interest and submit them to an alternate AMR predictor, such as McMaster's webportal  CARD .  How do I use it?  Subject  In the  Subject  field, put  ResFinder . Spelling counts, but case sensitivity doesn't.  Description  All you need to put in the description is a list of SEQIDs you want to detect AMR in, one per line.  Example  For an example ResFinder, see  issue 12854 .  Interpreting Results  ResFinder will upload a file called  resfinder.xlsx  once it has completed, which shows every AMR gene found in each\nsample. Just because a gene/resistance is listed here does not necessarily mean the strain carries that resistance - it's important\nto look at the  PercentIdentity  and  PercentCovered  columns. You can be pretty sure that anything with 100 for both\nis actually there, but anything else requires further analysis to be sure.  How long does it take?  ResFinder is very fast - it should only take a few seconds to analyze each SEQID requested.  What can go wrong?  1) Requested SEQIDs are not available. If we can't find some of the SEQIDs that you request, you will get a warning\nmessage informing you of it.", 
            "title": "ResFinder"
        }, 
        {
            "location": "/analysis/roary/", 
            "text": "RoaryScoary\n\n\nWhat does it do?\n\n\nRoary\n\n\nRoary is a pipeline for calculating pan genomes. Roary is not intended for metagenomics or for comparing extremely diverse sets of genomes. If you want to \nlearn more about it, check out the \nRoary publication\n.\n\n\nScoary\n\n\nScoary takes the \ngene_presence_absence.csv\n file output from Roary and a traits file created by the user, and calculates the associations between the given traits and all genes in the accessory genome. For more information, check out the \nScoary github\n or \nScoary publication\n.\n\n\nHow do I use it?\n\n\nSubject\n\n\nIn the \nSubject\n field, put \nroary\n. Spelling counts, but case sensitivity doesn't.\n\n\nDescription\n\n\nRequired Components\n\n\nIn the \nDescription\n field, you must provide the requested analysis type as follows:\n\n\nanalysistype=requested_analysis\n\n\nThe Roary automator supports the following analyses which perform operations on the pan genome of isolate sequences (again, spelling counts, but case sensitivity doesn't):\n\n\n\n\nunion - reports the union of genes found in sequences\n\n\nintersection - reports the intersection of genes found in isolate sequences (core genes)\n\n\ncomplement - reports the complement of genes found in isolates (accessory genes)\n\n\ngene_multifasta - extracts the sequence of each gene listed and creates multi-fasta files for each gene listed (outputs protein multi-fastas). \nNOTE\n: you must provide an additional line: \ngenes=gene1,gene2,geneN\n which is a comma-separated list of genes you would like multi-fasta files for (eg. \ngenes=fliC,gyrA\n). \nCase sensitivity counts for gene names\n\n\ndifference - reports the gene differences between sets of isolates. You must differentiate between sequence sets by adding the line \nset_two\n above your second set of sequences in the description (sequences you want compared).\n\n\n\n\nYou must also include a list of SEQIDs one per line.\n\n\nOptional Components - Scoary\n\n\nIf you would like scoary analysis to be completed, calculating the associations between traits and all genes in the accessory genome \nyou must attach a csv file of traits (traits.csv) to the issue\n. Attaching a \ntraits.csv\n file will automatically result in scoary analysis being conducted.\n\n\nThis traits file must be formatted in a specific way\n.\n\n\n\n\nthe rows should correspond to your isolate sequence IDs\n\n\nthe top right cell should be left blank\n\n\nthe trait(s) data must be binary (0 for trait absent, 1 for trait present)\n\n\nall SEQ-IDs and traits should be uniquely named and not contain any weird characters (e.g. %;,/\n[]@? etc) \n\n\n\n\nThe below table is an example from the Scoary github:\n\n\n\n\n\n\n\n\n\n\nTrait 1\n\n\nTrait 2\n\n\n...\n\n\nTrait N\n\n\n\n\n\n\n\n\n\n\nYYYY-SEQ-0001\n\n\n1\n\n\n0\n\n\n...\n\n\n1\n\n\n\n\n\n\nYYYY-SEQ-0002\n\n\n0\n\n\n0\n\n\n...\n\n\n1\n\n\n\n\n\n\nYYYY-SEQ-0003\n\n\n1\n\n\n0\n\n\n...\n\n\n1\n\n\n\n\n\n\n\n\nFor more information, check out the \nScoary github\n\n\nExample\n\n\nFor an example Roary/Scoary issue see \nissue 24968\n, for an example Roary \nanalysistype=gene_multifasta\n issue see \nissue 25013\n. (\nNOTE\n: the output files for these issues no longer exist on the ftp server.)\n\n\nInterpreting Results\n\n\nThe Roary automator will upload links to the ftp for files called \nprokka_output.zip\n and \nroary_output.zip\n once it has completed. \n\n\nThe \nprokka_output.zip\n contains all of the outputs from prokka. Prokka will output a lot of files for each genome you give it - you can find a quick description of\neach file \nhere\n. Of particular interest are the \n.gff\n files, which Roary uses for analysis.\n\n\nThe \nroary_output.zip\n file contains all of the outputs from roary. Some additional files will be present depending on the analysis type chosen:\n\n\n\n\ngene_multifasta - the zip file will include \n.fa\n files that contain the aligned protein sequences for the requested gene(s) (one for file each gene included in the analysis, eg. \ngene_multifasta_fliC.fa\n and \ngene_multifasta_gyrA.fa\n). If you'd like, these sequences can be further analysed using NCBI protein blast.\n\n\nscoary - the zip file will include \n.csv\n file(s) for each of the traits (column headers) provided in the attached \ntraits.csv\n file.\n\n\n\n\nHow long does it take?\n\n\nProkka isn't the quickest thing around - expect it to take 2 to 3 minutes for each genome you give it. After prokka is finished the Roary pipeline time will depend on the analysis type, and the number of genes/traits requested (in the case of gene_multifasta and scoary). \n\n\nWhat can go wrong?\n\n\n\n\nRequested SEQIDs are not available. If we can't find some of the SEQIDs that you request, you will get a warning message informing you of it.\n\n\nThere was an issue with the requested analysistype: either one was not supplied, the was a typo, or you requested a currently-unsupported analysis. An error message detailing the problem will be added to the issue.\n\n\nScoary\n You will not get an error if the traits.csv file is not attached or formatted correctly. Roary will complete, but no \n.csv\n files for each of the traits will be included in the zip file. Unfortunately, you will have to submit the analysis request again with the correct \ntraits.csv\n formatting.", 
            "title": "Roary"
        }, 
        {
            "location": "/analysis/roary/#roaryscoary", 
            "text": "What does it do?  Roary  Roary is a pipeline for calculating pan genomes. Roary is not intended for metagenomics or for comparing extremely diverse sets of genomes. If you want to \nlearn more about it, check out the  Roary publication .  Scoary  Scoary takes the  gene_presence_absence.csv  file output from Roary and a traits file created by the user, and calculates the associations between the given traits and all genes in the accessory genome. For more information, check out the  Scoary github  or  Scoary publication .  How do I use it?  Subject  In the  Subject  field, put  roary . Spelling counts, but case sensitivity doesn't.  Description  Required Components  In the  Description  field, you must provide the requested analysis type as follows:  analysistype=requested_analysis  The Roary automator supports the following analyses which perform operations on the pan genome of isolate sequences (again, spelling counts, but case sensitivity doesn't):   union - reports the union of genes found in sequences  intersection - reports the intersection of genes found in isolate sequences (core genes)  complement - reports the complement of genes found in isolates (accessory genes)  gene_multifasta - extracts the sequence of each gene listed and creates multi-fasta files for each gene listed (outputs protein multi-fastas).  NOTE : you must provide an additional line:  genes=gene1,gene2,geneN  which is a comma-separated list of genes you would like multi-fasta files for (eg.  genes=fliC,gyrA ).  Case sensitivity counts for gene names  difference - reports the gene differences between sets of isolates. You must differentiate between sequence sets by adding the line  set_two  above your second set of sequences in the description (sequences you want compared).   You must also include a list of SEQIDs one per line.  Optional Components - Scoary  If you would like scoary analysis to be completed, calculating the associations between traits and all genes in the accessory genome  you must attach a csv file of traits (traits.csv) to the issue . Attaching a  traits.csv  file will automatically result in scoary analysis being conducted.  This traits file must be formatted in a specific way .   the rows should correspond to your isolate sequence IDs  the top right cell should be left blank  the trait(s) data must be binary (0 for trait absent, 1 for trait present)  all SEQ-IDs and traits should be uniquely named and not contain any weird characters (e.g. %;,/ []@? etc)    The below table is an example from the Scoary github:      Trait 1  Trait 2  ...  Trait N      YYYY-SEQ-0001  1  0  ...  1    YYYY-SEQ-0002  0  0  ...  1    YYYY-SEQ-0003  1  0  ...  1     For more information, check out the  Scoary github  Example  For an example Roary/Scoary issue see  issue 24968 , for an example Roary  analysistype=gene_multifasta  issue see  issue 25013 . ( NOTE : the output files for these issues no longer exist on the ftp server.)  Interpreting Results  The Roary automator will upload links to the ftp for files called  prokka_output.zip  and  roary_output.zip  once it has completed.   The  prokka_output.zip  contains all of the outputs from prokka. Prokka will output a lot of files for each genome you give it - you can find a quick description of\neach file  here . Of particular interest are the  .gff  files, which Roary uses for analysis.  The  roary_output.zip  file contains all of the outputs from roary. Some additional files will be present depending on the analysis type chosen:   gene_multifasta - the zip file will include  .fa  files that contain the aligned protein sequences for the requested gene(s) (one for file each gene included in the analysis, eg.  gene_multifasta_fliC.fa  and  gene_multifasta_gyrA.fa ). If you'd like, these sequences can be further analysed using NCBI protein blast.  scoary - the zip file will include  .csv  file(s) for each of the traits (column headers) provided in the attached  traits.csv  file.   How long does it take?  Prokka isn't the quickest thing around - expect it to take 2 to 3 minutes for each genome you give it. After prokka is finished the Roary pipeline time will depend on the analysis type, and the number of genes/traits requested (in the case of gene_multifasta and scoary).   What can go wrong?   Requested SEQIDs are not available. If we can't find some of the SEQIDs that you request, you will get a warning message informing you of it.  There was an issue with the requested analysistype: either one was not supplied, the was a typo, or you requested a currently-unsupported analysis. An error message detailing the problem will be added to the issue.  Scoary  You will not get an error if the traits.csv file is not attached or formatted correctly. Roary will complete, but no  .csv  files for each of the traits will be included in the zip file. Unfortunately, you will have to submit the analysis request again with the correct  traits.csv  formatting.", 
            "title": "RoaryScoary"
        }, 
        {
            "location": "/analysis/sequence_extractor/", 
            "text": "SequenceExtractor\n\n\nWhat does it do?\n\n\nSequenceExtractor extracts the sequence data from a supplied contig at designated start and stop positions\n\n\nCheck out the source code: \ngithub\n\n\nHow do I use it?\n\n\nSubject\n\n\nIn the \nSubject\n field, put \nsequence_extractor\n. Spelling counts, but case sensitivity does not.\n\n\nDescription\n\n\nThere are two ways to use SequenceExtractor\n\n\nYou must provide a list of (one per line):\n\n\nSEQID;contig name;start coordinates; stop coordinates\n\n\ne.g. \n\n\n2019-SEQ-0848;Contig_1_149.079_Circ;1;50\n2019-SEQ-1019;Contig_1_388.862_Circ;14;77\n2019-SEQ-0848;Contig_2_392.879_Circ;2;39\n2019-SEQ-1019;Contig_3_52.4575;5;22\n\n\n\n\nNotes: \n\n\n\n\nIf you want an entire contig, supply the start and stop positions as 0\n\n\nThe stop base can be lower than the start base. The script will change them, so that the start base is always lower\n\n\n\n\nThe above example performs four extractions:\n\n\n\n\nbases \n1-50\n from \nContig_1_149.079_Circ\n in the assembly for SEQID \n2019-SEQ-0848\n\n\nbases \n14-77\n from \nContig_1_388.862_Circ\n in the assembly for SEQID \n2019-SEQ-1019\n\n\nbases \n2-39\n from \nContig_2_392.879_Circ\n in the assembly for SEQID \n2019-SEQ-0848\n\n\nbases \n5-22\n from \nContig_3_52.4575\n in the assembly for SEQID \n2019-SEQ-1019\n\n\n\n\nThis list can be supplied in two possible ways:\n\n\n\n\nIn the Description\n\n\nIn an attached file (the name of the file doesn't matter, but please try to avoid empty lines)\n\n\n\n\nYou cannot supply the list both ways; if you provide an attachment, any entries in the Description will be ignored.\n\n\nExample\n\n\nFor an example SequenceExtractor analysis with the fasta details provided as an attachment, see \nissue 28104\n.\n\n\nThis example has SEQIDs in the Description, but it's not necessary.\n\n\nFor an example SequenceExtractor analysis with the fasta details provided in the description, see \nissue 28181\n.\n\n\nInterpreting Results\n\n\nSequenceExtractor will output a FASTA-formatted file, \nextracted_sequences.fasta\n ,that should look like the following if you used the example list above:\n\n\n2019-SEQ-0848_Contig_1_149.079_Circ_1_50\nAAAAAAAACAAATATATACTTTGATGATAACTTTCTAAATATCTACAAAA\n\n2019-SEQ-0848_Contig_2_392.879_Circ_2_39\nAAAAAAACAATAAAAAACACCGCAAAAATGGATTGTTA\n\n2019-SEQ-1019_Contig_1_388.862_Circ_14_77\nCAATAGTCTTATTTCCATTCAGGTATTCAATATTAATATTCATACGTTAATCCGATTTAT\nCCTT\n\n2019-SEQ-1019_Contig_3_52.4575_5_22\nATATCATCAGATGGCTGC\n\n\n\n\nHow long does it take?\n\n\nSequenceExtractor is pretty fast - expect it to take a few seconds per entry you give it.\n\n\nWhat can go wrong?\n\n\n\n\nRequested SEQIDs are not available. If we can't find some of the SEQIDs that you request, \nyou will get a warning message informing you of it.\n\n\nThe contig name must be provided exactly as it is written in the assembly.\n\n\nThe start or stop position provided is invalid e.g. if you ask for positions 789-882 in a contig that is only 500bp long, nothing will be returned.", 
            "title": "Sequence extractor"
        }, 
        {
            "location": "/analysis/sequence_extractor/#sequenceextractor", 
            "text": "What does it do?  SequenceExtractor extracts the sequence data from a supplied contig at designated start and stop positions  Check out the source code:  github  How do I use it?  Subject  In the  Subject  field, put  sequence_extractor . Spelling counts, but case sensitivity does not.  Description  There are two ways to use SequenceExtractor  You must provide a list of (one per line):  SEQID;contig name;start coordinates; stop coordinates  e.g.   2019-SEQ-0848;Contig_1_149.079_Circ;1;50\n2019-SEQ-1019;Contig_1_388.862_Circ;14;77\n2019-SEQ-0848;Contig_2_392.879_Circ;2;39\n2019-SEQ-1019;Contig_3_52.4575;5;22  Notes:    If you want an entire contig, supply the start and stop positions as 0  The stop base can be lower than the start base. The script will change them, so that the start base is always lower   The above example performs four extractions:   bases  1-50  from  Contig_1_149.079_Circ  in the assembly for SEQID  2019-SEQ-0848  bases  14-77  from  Contig_1_388.862_Circ  in the assembly for SEQID  2019-SEQ-1019  bases  2-39  from  Contig_2_392.879_Circ  in the assembly for SEQID  2019-SEQ-0848  bases  5-22  from  Contig_3_52.4575  in the assembly for SEQID  2019-SEQ-1019   This list can be supplied in two possible ways:   In the Description  In an attached file (the name of the file doesn't matter, but please try to avoid empty lines)   You cannot supply the list both ways; if you provide an attachment, any entries in the Description will be ignored.  Example  For an example SequenceExtractor analysis with the fasta details provided as an attachment, see  issue 28104 .  This example has SEQIDs in the Description, but it's not necessary.  For an example SequenceExtractor analysis with the fasta details provided in the description, see  issue 28181 .  Interpreting Results  SequenceExtractor will output a FASTA-formatted file,  extracted_sequences.fasta  ,that should look like the following if you used the example list above:  2019-SEQ-0848_Contig_1_149.079_Circ_1_50\nAAAAAAAACAAATATATACTTTGATGATAACTTTCTAAATATCTACAAAA 2019-SEQ-0848_Contig_2_392.879_Circ_2_39\nAAAAAAACAATAAAAAACACCGCAAAAATGGATTGTTA 2019-SEQ-1019_Contig_1_388.862_Circ_14_77\nCAATAGTCTTATTTCCATTCAGGTATTCAATATTAATATTCATACGTTAATCCGATTTAT\nCCTT 2019-SEQ-1019_Contig_3_52.4575_5_22\nATATCATCAGATGGCTGC  How long does it take?  SequenceExtractor is pretty fast - expect it to take a few seconds per entry you give it.  What can go wrong?   Requested SEQIDs are not available. If we can't find some of the SEQIDs that you request, \nyou will get a warning message informing you of it.  The contig name must be provided exactly as it is written in the assembly.  The start or stop position provided is invalid e.g. if you ask for positions 789-882 in a contig that is only 500bp long, nothing will be returned.", 
            "title": "SequenceExtractor"
        }, 
        {
            "location": "/analysis/sipprverse/", 
            "text": "sipprverse\n\n\nWhat does it do?\n\n\nThe sipprverse is a suite of analyses that detect gene targets in raw FASTQ reads.\n\n\nHow do I use it?\n\n\nSubject\n\n\nIn the \nSubject\n field, put \nsipprverse\n. Spelling counts, but case sensitivity doesn't.\n\n\nDescription\n\n\nRequired Components\n\n\nIn the \nDescription\n field, you must provide:\n\n\n\n\n\n\nanalysis=requested_analysis\n\n\nThe sipprverse pipeline supports the following analyses (again, spelling counts, but case sensitivity doesn't):\n\n\n\n\ngdcs - determines the presence of genomically-dispersed conserved sequences in the following genera: \nEscherichia, Listeria, Salmonella, Vibrio\n\n\ngenesippr - custom suite of genes derived from the following genera: \nBacillus, Campylobacter, Escherichia, Listeria, Salmonella, Staphylococcus, Vibrio\n\n\nmash - finds closest matching RefSeq genome\n\n\nmlst - determines multi-locus sequence type for the following genera: \nBacillus, Campylobacter, Escherichia, Listeria, Salmonella, Staphylococcus, Vibrio\n\n\npointfinder - detects chromosomal mutations predictive of drug resistance\n\n\nresfinder - identifies acquired antimicrobial resistance genes\n\n\nrmlst - determines ribosomal multi-locus sequence type\n\n\nserosippr - calculates the serotype for \nEscherichia\n\n\nsixteens - determines closest 16S match\n\n\nvirulence - finds virulence genes\n\n\nfull (all the above analyses)\n\n\ncustom (\nyou must attach a FASTA-formatted file of targets to the issue\n)\n\n\n\n\n\n\n\n\na list of SEQIDs (one per line)\n\n\n\n\n\n\nOptional Components\n\n\nIn order to customise your sipprverse analyses, several settings can be optionally modified\n\n\n\n\nMinimum cutoff for matches to be included in report.\n\n\ndefault is \n0.90\n\n\nmodify as follows:\n\n\ncutoff=0.85\n\n\n\n\n\n\n\n\n\n\nAverage pileup depth cutoff\n\n\ndefault is \n2\n\n\nmodify as follows:\n\n\naveragedepth=3\n\n\n\n\n\n\n\n\n\n\nKmer size to use for baiting. Please don't lower this too much (11 is probably about as low as I would recommend)\n\n\ndefault is \n19\n\n\nmodify as follows:\n\n\nkmersize=11\n\n\n\n\n\n\n\n\n\n\nDo not automatically discard hits if there are internal soft clips present\n\n\ndefault is \nFalse\n\n\nmodify as follows:\n\n\nallowsoftclips=True\n\n\n\n\n\n\n\n\n\n\n\n\nExample\n\n\nFor an example sipprverse issue, see \nissue 15706\n or \n\nissue 15707\n.\n\n\nInterpreting Results\n\n\nThe sipprverse automator will upload a file called \nsipprverse_output.zip\n once it has completed. This file will contain all the reports generated for the requested analysis.\n\n\nHow long does it take?\n\n\nIt depends on the analysis requested. The sipprverse pipeline deals with raw reads, so expect that it should take a few minutes to analyze each SEQID requested.\n\n\nWhat can go wrong?\n\n\n\n\nRequested SEQIDs are not available. If we can't find some of the SEQIDs that you request, you will get a warning\nmessage informing you of it.\n\n\nThere was an issue with the requested analysis: either one was not supplied, the was a typo, or you requested a currently-unsupported analysis. An error message detailing the problem will be added to the issue.\n\n\nThe \ncustom\n analysis requires an attached FASTA-formatted file of gene targets. If the file was not attached, or there was an issue reading the file, an error message detailing the problem will be add to the issue.", 
            "title": "Sipprverse"
        }, 
        {
            "location": "/analysis/sipprverse/#sipprverse", 
            "text": "What does it do?  The sipprverse is a suite of analyses that detect gene targets in raw FASTQ reads.  How do I use it?  Subject  In the  Subject  field, put  sipprverse . Spelling counts, but case sensitivity doesn't.  Description  Required Components  In the  Description  field, you must provide:    analysis=requested_analysis  The sipprverse pipeline supports the following analyses (again, spelling counts, but case sensitivity doesn't):   gdcs - determines the presence of genomically-dispersed conserved sequences in the following genera:  Escherichia, Listeria, Salmonella, Vibrio  genesippr - custom suite of genes derived from the following genera:  Bacillus, Campylobacter, Escherichia, Listeria, Salmonella, Staphylococcus, Vibrio  mash - finds closest matching RefSeq genome  mlst - determines multi-locus sequence type for the following genera:  Bacillus, Campylobacter, Escherichia, Listeria, Salmonella, Staphylococcus, Vibrio  pointfinder - detects chromosomal mutations predictive of drug resistance  resfinder - identifies acquired antimicrobial resistance genes  rmlst - determines ribosomal multi-locus sequence type  serosippr - calculates the serotype for  Escherichia  sixteens - determines closest 16S match  virulence - finds virulence genes  full (all the above analyses)  custom ( you must attach a FASTA-formatted file of targets to the issue )     a list of SEQIDs (one per line)    Optional Components  In order to customise your sipprverse analyses, several settings can be optionally modified   Minimum cutoff for matches to be included in report.  default is  0.90  modify as follows:  cutoff=0.85      Average pileup depth cutoff  default is  2  modify as follows:  averagedepth=3      Kmer size to use for baiting. Please don't lower this too much (11 is probably about as low as I would recommend)  default is  19  modify as follows:  kmersize=11      Do not automatically discard hits if there are internal soft clips present  default is  False  modify as follows:  allowsoftclips=True       Example  For an example sipprverse issue, see  issue 15706  or  issue 15707 .  Interpreting Results  The sipprverse automator will upload a file called  sipprverse_output.zip  once it has completed. This file will contain all the reports generated for the requested analysis.  How long does it take?  It depends on the analysis requested. The sipprverse pipeline deals with raw reads, so expect that it should take a few minutes to analyze each SEQID requested.  What can go wrong?   Requested SEQIDs are not available. If we can't find some of the SEQIDs that you request, you will get a warning\nmessage informing you of it.  There was an issue with the requested analysis: either one was not supplied, the was a typo, or you requested a currently-unsupported analysis. An error message detailing the problem will be added to the issue.  The  custom  analysis requires an attached FASTA-formatted file of gene targets. If the file was not attached, or there was an issue reading the file, an error message detailing the problem will be add to the issue.", 
            "title": "sipprverse"
        }, 
        {
            "location": "/analysis/snippy/", 
            "text": "Snippy\n\n\nWhat does it do?\n\n\nSnippy is a tool for rapid haploid variant calling and core genome alignment of closely related genomes. This automator can also be used to build a phylogenetic tree to attempt to show the\nrelatedness of these strains. Lots more info can be found at the \nSnippy github site\n.\n\n\nHow do I use it?\n\n\nSubject\n\n\nIn the \nSubject\n field, put \nsnippy\n. Spelling counts, but case sensitivity doesn't.\n\n\nDescription\n\n\nRequired Components\n\n\nThe first line of your description needs to be \nreference=\n, the SEQID of the strain you want to act\nas your reference strain. Ideally, you'll want to pick a high-quality assembly for your reference.\n\n\neg. \nreference=YYYY-MIN-NNNN\n\n\nIf you wish to attach a reference file instead of providing a SEQID, the line must be \nreference=attached\n\n\nYou must also include a list of SEQIDs one per line.\n\n\nOptional Components\n\n\nWe have also included the ability to 'cleanup' a multiple sequence alignment, and generate a tree using \nGubbins\n and \nIQ-tree\n. If you call SNPs for multiple isolates from the same reference, you are able to produce an alignment of \"core SNPs\" to build a phylogeny. To use this function, add the following line in the description:\n\n\n\n\ncleanup_\n_tree=True\n\n\n\n\nThis automator currently uses IQtree and default settings for gubbins, but other options are available. If you would like additional functions, please contact a bioinformatician and we will do our best to add them.\n\n\nExample\n\n\nFor an example snippy, see \nissue 30388\n.\n\n\nInterpreting Results\n\n\nThe zip file uploaded on snippy completion will contain folders for each of the comparator sequences, as well as core alignment files. Some of the files will also be uploaded/attached directly to the redmine request. Important files are:\n\n\n\n\ncore.txt\n: A summary file. Tab-separated columnar list of alignment/core-size statistics of the number of: aligned, unaligned, variants, and low coverage bases between every strain submitted and the reference.\n\n\ncore.tab\n: Tab-separated columnar list of core SNP sites with alleles but NO annotations\n\n\ncore.vcf\n: Multi-sample VCF file with genotype GT tags for all discovered alleles\n\n\nWithin each sequence folder there will also be files, including a tab separated summary for that particular sequence in comparison to the reference.\n\n\n\n\nIf cleanup_\n_tree was included, then tree files will also be included in the output:\n\n\n\n\n{issue.id}.snippy.gubbins.iqtree.tree\n: An intermediate phylogenetic tree created by gubbins + iqtree. \n\n\n{issue.id}.snippy_final.clean.core.snp.aln.tree\n: The \nfinal\n phylogeny created from the core snp alignment (created using IQtree and the GTR substitution method).\n\n\n\n\nIf you want to view these tree files, you can use a program such as\n\nFigTree\n or a web-based viewer like \nphylo.io\n.\n\n\nOther files can also be important - see the \ndocs on Snippy Output files\n\nfor more information.\n\n\nVariant types\n\n\nFor more information, see the \ndocs on Snippy Output files\n:\n\n\n\n\n\n\n\n\nType\n\n\nName\n\n\nExample\n\n\n\n\n\n\n\n\n\n\nsnp\n\n\nSingle Nucleotide Polymorphism\n\n\nA =\n T\n\n\n\n\n\n\nmnp\n\n\nMultiple Nuclotide Polymorphism\n\n\nGC =\n AT\n\n\n\n\n\n\nins\n\n\nInsertion\n\n\nATT =\n AGTT\n\n\n\n\n\n\ndel\n\n\nDeletion\n\n\nACGG =\n ACG\n\n\n\n\n\n\ncomplex\n\n\nCombination of snp/mnp\n\n\nATTC =\n GTTA\n\n\n\n\n\n\n\n\nHow long does it take?\n\n\nIt depends on the number of sequences and coverage/size of sequence files. Small snippy requests take ~15 minutes to complete (see the example request). If you submit a request for a larger snippy (\n30 strains), or include larger long-read sequences, it may take substantially longer.\n\n\nWhat can go wrong?\n\n\nA few things can go wrong with this process:\n\n\n1) Requested SEQIDs are not available. If we can't find some of the SEQIDs that you request, you will get a warning\nmessage informing you of it.\n\n\n2) Strains too far apart. Snippy requires that the strains you want to compare to the reference be closely related to\nthe reference. If you ask for a snippy-analysis with things that are not very related, the analysis will fail. In this case, look at the \ncore.txt\n file that is uploaded to the redmine request. If there are sequences with 0 under \"Aligned\", remove those sequences from the request and re-submit.\n\n\n3) Why is the cleaned snp tree not showing my single-end sequences? - I'm not sure... the cleaning step(s) using gubbins appears to remove the minion (single-end) sequence data from the cleaned alignment when a multi-analysis is performed using both illumina and minion sequences. The \n{}.snippy_core_alignment.iqtree.treefile\n, which is generated before the cleaning steps, will contain all SEQIDS.\n\n\nShould I use Snippy or SNVPhyl?\n\n\n...This depends on your goal...\n\n\nSnippy appears to be faster than SNVPhyl. It also allows use of both paired-end and single-end raw data files in the same analysis (whereas SNVPhyl \ncurrently does not\n).\n\n\nA comparison of snippy vs SNVPhyl has not been conducted by our lab. The \nSNVPhyl publication\n does briefly discuss snippy.", 
            "title": "Snippy"
        }, 
        {
            "location": "/analysis/snippy/#snippy", 
            "text": "What does it do?  Snippy is a tool for rapid haploid variant calling and core genome alignment of closely related genomes. This automator can also be used to build a phylogenetic tree to attempt to show the\nrelatedness of these strains. Lots more info can be found at the  Snippy github site .  How do I use it?  Subject  In the  Subject  field, put  snippy . Spelling counts, but case sensitivity doesn't.  Description  Required Components  The first line of your description needs to be  reference= , the SEQID of the strain you want to act\nas your reference strain. Ideally, you'll want to pick a high-quality assembly for your reference.  eg.  reference=YYYY-MIN-NNNN  If you wish to attach a reference file instead of providing a SEQID, the line must be  reference=attached  You must also include a list of SEQIDs one per line.  Optional Components  We have also included the ability to 'cleanup' a multiple sequence alignment, and generate a tree using  Gubbins  and  IQ-tree . If you call SNPs for multiple isolates from the same reference, you are able to produce an alignment of \"core SNPs\" to build a phylogeny. To use this function, add the following line in the description:   cleanup_ _tree=True   This automator currently uses IQtree and default settings for gubbins, but other options are available. If you would like additional functions, please contact a bioinformatician and we will do our best to add them.  Example  For an example snippy, see  issue 30388 .  Interpreting Results  The zip file uploaded on snippy completion will contain folders for each of the comparator sequences, as well as core alignment files. Some of the files will also be uploaded/attached directly to the redmine request. Important files are:   core.txt : A summary file. Tab-separated columnar list of alignment/core-size statistics of the number of: aligned, unaligned, variants, and low coverage bases between every strain submitted and the reference.  core.tab : Tab-separated columnar list of core SNP sites with alleles but NO annotations  core.vcf : Multi-sample VCF file with genotype GT tags for all discovered alleles  Within each sequence folder there will also be files, including a tab separated summary for that particular sequence in comparison to the reference.   If cleanup_ _tree was included, then tree files will also be included in the output:   {issue.id}.snippy.gubbins.iqtree.tree : An intermediate phylogenetic tree created by gubbins + iqtree.   {issue.id}.snippy_final.clean.core.snp.aln.tree : The  final  phylogeny created from the core snp alignment (created using IQtree and the GTR substitution method).   If you want to view these tree files, you can use a program such as FigTree  or a web-based viewer like  phylo.io .  Other files can also be important - see the  docs on Snippy Output files \nfor more information.  Variant types  For more information, see the  docs on Snippy Output files :     Type  Name  Example      snp  Single Nucleotide Polymorphism  A =  T    mnp  Multiple Nuclotide Polymorphism  GC =  AT    ins  Insertion  ATT =  AGTT    del  Deletion  ACGG =  ACG    complex  Combination of snp/mnp  ATTC =  GTTA     How long does it take?  It depends on the number of sequences and coverage/size of sequence files. Small snippy requests take ~15 minutes to complete (see the example request). If you submit a request for a larger snippy ( 30 strains), or include larger long-read sequences, it may take substantially longer.  What can go wrong?  A few things can go wrong with this process:  1) Requested SEQIDs are not available. If we can't find some of the SEQIDs that you request, you will get a warning\nmessage informing you of it.  2) Strains too far apart. Snippy requires that the strains you want to compare to the reference be closely related to\nthe reference. If you ask for a snippy-analysis with things that are not very related, the analysis will fail. In this case, look at the  core.txt  file that is uploaded to the redmine request. If there are sequences with 0 under \"Aligned\", remove those sequences from the request and re-submit.  3) Why is the cleaned snp tree not showing my single-end sequences? - I'm not sure... the cleaning step(s) using gubbins appears to remove the minion (single-end) sequence data from the cleaned alignment when a multi-analysis is performed using both illumina and minion sequences. The  {}.snippy_core_alignment.iqtree.treefile , which is generated before the cleaning steps, will contain all SEQIDS.  Should I use Snippy or SNVPhyl?  ...This depends on your goal...  Snippy appears to be faster than SNVPhyl. It also allows use of both paired-end and single-end raw data files in the same analysis (whereas SNVPhyl  currently does not ).  A comparison of snippy vs SNVPhyl has not been conducted by our lab. The  SNVPhyl publication  does briefly discuss snippy.", 
            "title": "Snippy"
        }, 
        {
            "location": "/analysis/snvphyl/", 
            "text": "SNVPhyl\n\n\nWhat does it do?\n\n\nSNVPhyl is a pipeline developed by the Public Health Agency of Canada for evaluating the number of SNPs between a\nreference strain and other closely related strains. It also builds a phylogenetic tree to attempt to show the\nrelatedness of these strains. Lots more info can be found at the \nSNVPhyl readthedocs site\n.\n\n\nHow do I use it?\n\n\nSubject\n\n\nIn the \nSubject\n field, put \nSNVPhyl\n. Spelling counts, but case sensitivity doesn't.\n\n\nDescription\n\n\nThe first line of your description needs to be \nreference\n, and the second line the SEQID of the strain you want to act\nas your reference strain. Ideally, you'll want to pick a high-quality assembly for your reference.\n\n\nIf you wish to attach a reference file instead of providing a SEQID, the second line must be \nattached\n\n\nThe third line of your description should be \ncompare\n, and lines after that the SEQIDs for strains you want to compare\nyour reference to.\n\n\nExample\n\n\nFor an example SNVPhyl, see \nissue 12494\n.\n\n\nInterpreting Results\n\n\nThe zip file uploaded on SNVPhyl completion should contain 10 files. Important files are:\n\n\n\n\nsnvMatrix.tsv: Shows the number of SNVs between every strain submitted.\n\n\nvcf2core.tsv: Shows how much of the genome was covered by the analysis (look at the \nPercentage of all positions that are valid, included, and part of the core genome\n\ncolumn in the \nall\n row). This should be at least 90 percent, or the strains you were comparing were probably too far apart\nto get good results.\n\n\nphylogeneticTree.nwk: The phylogenetic tree created by SNVPhyl. If you want to view this tree, you can use a program such as\n\nFigTree\n or a web-based viewer like \nphylo.io\n.\n\n\n\n\nOther files can also be important - see the \ndocs on SNVPhyl Output files\n\nfor more information.\n\n\nHow long does it take?\n\n\nMost SNVPhyl requests take ~1 hour to complete. If you submit a request for a larger SNVPhyl (\n30 strains), it may take\nsubstantially longer.\n\n\nWhat can go wrong?\n\n\nA few things can go wrong with this process:\n\n\n1) Requested SEQIDs are not available. If we can't find some of the SEQIDs that you request, you will get a warning\nmessage informing you of it.\n\n\n2) Strains too far apart. SNVPhyl requires that the strains you want to compare to the reference be closely related to\nthe reference. If you ask for a SNVPhyl with things that are not very related, you will get a warning telling you so.\n\n\n3) No output files. Sometimes, SNVPhyl will say it has completed, but the typical output files will not be present. This\nis either because \na)\n there are no SNVs between the two strains, and so SNVPhyl crashes or \nb)\n SNVPhyl crashed for an\nunknown reason, which does happen occasionally. If this happens, your best bet is to try running the SNVPhyl again. If\nSNVPhyl keeps crashing even after subsequent attempts, let us know and we'll do our best to fix things.", 
            "title": "Snvphyl"
        }, 
        {
            "location": "/analysis/snvphyl/#snvphyl", 
            "text": "What does it do?  SNVPhyl is a pipeline developed by the Public Health Agency of Canada for evaluating the number of SNPs between a\nreference strain and other closely related strains. It also builds a phylogenetic tree to attempt to show the\nrelatedness of these strains. Lots more info can be found at the  SNVPhyl readthedocs site .  How do I use it?  Subject  In the  Subject  field, put  SNVPhyl . Spelling counts, but case sensitivity doesn't.  Description  The first line of your description needs to be  reference , and the second line the SEQID of the strain you want to act\nas your reference strain. Ideally, you'll want to pick a high-quality assembly for your reference.  If you wish to attach a reference file instead of providing a SEQID, the second line must be  attached  The third line of your description should be  compare , and lines after that the SEQIDs for strains you want to compare\nyour reference to.  Example  For an example SNVPhyl, see  issue 12494 .  Interpreting Results  The zip file uploaded on SNVPhyl completion should contain 10 files. Important files are:   snvMatrix.tsv: Shows the number of SNVs between every strain submitted.  vcf2core.tsv: Shows how much of the genome was covered by the analysis (look at the  Percentage of all positions that are valid, included, and part of the core genome \ncolumn in the  all  row). This should be at least 90 percent, or the strains you were comparing were probably too far apart\nto get good results.  phylogeneticTree.nwk: The phylogenetic tree created by SNVPhyl. If you want to view this tree, you can use a program such as FigTree  or a web-based viewer like  phylo.io .   Other files can also be important - see the  docs on SNVPhyl Output files \nfor more information.  How long does it take?  Most SNVPhyl requests take ~1 hour to complete. If you submit a request for a larger SNVPhyl ( 30 strains), it may take\nsubstantially longer.  What can go wrong?  A few things can go wrong with this process:  1) Requested SEQIDs are not available. If we can't find some of the SEQIDs that you request, you will get a warning\nmessage informing you of it.  2) Strains too far apart. SNVPhyl requires that the strains you want to compare to the reference be closely related to\nthe reference. If you ask for a SNVPhyl with things that are not very related, you will get a warning telling you so.  3) No output files. Sometimes, SNVPhyl will say it has completed, but the typical output files will not be present. This\nis either because  a)  there are no SNVs between the two strains, and so SNVPhyl crashes or  b)  SNVPhyl crashed for an\nunknown reason, which does happen occasionally. If this happens, your best bet is to try running the SNVPhyl again. If\nSNVPhyl keeps crashing even after subsequent attempts, let us know and we'll do our best to fix things.", 
            "title": "SNVPhyl"
        }, 
        {
            "location": "/analysis/staramr/", 
            "text": "StarAMR\n\n\nWhat does it do?\n\n\nStarAMR is a program from Canada's National Microbiology Laboratory that combines the ResFinder\nand PointFinder programs for detecting antibiotic resistance from the \nDanish Center for Genomic Epidemiology\n.\n\n\nHow do I use it?\n\n\nSubject\n\n\nIn the \nSubject\n field, put \nstaramr\n. Spelling counts, but case sensitivity doesn't.\n\n\nDescription\n\n\nAll you need to put in the description is a list of SEQIDs you want to detect AMR in, one per line.\nNote that StarAMR is limited to detecting mutations in a few genera:\n\n\n\n\nCampylobacter\n\n\nSalmonella\n\n\n\n\nOur StarAMR automator will automatically determine the genus of your requested SEQIDs, and will not attempt to\nanalyze any SEQIDs that are not from one of these genera.\n\n\nExample\n\n\nFor an example StarAMR, see \nissue 15625\n.\n\n\nInterpreting Results\n\n\nStarAMR will upload a zip file called \nstaramr_output.zip\n. Within this folder, you will find a few files for each genus:\n\n\nNote: Any SEQIDs from genera that are not Campylobacter or Salmonella not have any files uploaded\n\n\nThe most important file for each genus is \nresults.xlsx\n - this shows what AMR genes were found in each\nSeqID, and also lets you see if the resistance is conferred by a gene or a point mutation.\n\n\nHow long does it take?\n\n\nStarAMR should take 30 seconds to 1 minutes for analysis of each sample.\n\n\nWhat can go wrong?\n\n\n1) Requested SEQIDs are not available: If we can't find some of the SEQIDs that you request, you will get a warning\nmessage informing you of it.\n\n\n2) Can't run on requested genera: If the SEQIDs you request are not one of the genera that PointFinder works on,\nyou will get a message saying so. PointFinder will still run on any SEQIDs specified that are from the correct genera.", 
            "title": "Staramr"
        }, 
        {
            "location": "/analysis/staramr/#staramr", 
            "text": "What does it do?  StarAMR is a program from Canada's National Microbiology Laboratory that combines the ResFinder\nand PointFinder programs for detecting antibiotic resistance from the  Danish Center for Genomic Epidemiology .  How do I use it?  Subject  In the  Subject  field, put  staramr . Spelling counts, but case sensitivity doesn't.  Description  All you need to put in the description is a list of SEQIDs you want to detect AMR in, one per line.\nNote that StarAMR is limited to detecting mutations in a few genera:   Campylobacter  Salmonella   Our StarAMR automator will automatically determine the genus of your requested SEQIDs, and will not attempt to\nanalyze any SEQIDs that are not from one of these genera.  Example  For an example StarAMR, see  issue 15625 .  Interpreting Results  StarAMR will upload a zip file called  staramr_output.zip . Within this folder, you will find a few files for each genus:  Note: Any SEQIDs from genera that are not Campylobacter or Salmonella not have any files uploaded  The most important file for each genus is  results.xlsx  - this shows what AMR genes were found in each\nSeqID, and also lets you see if the resistance is conferred by a gene or a point mutation.  How long does it take?  StarAMR should take 30 seconds to 1 minutes for analysis of each sample.  What can go wrong?  1) Requested SEQIDs are not available: If we can't find some of the SEQIDs that you request, you will get a warning\nmessage informing you of it.  2) Can't run on requested genera: If the SEQIDs you request are not one of the genera that PointFinder works on,\nyou will get a message saying so. PointFinder will still run on any SEQIDs specified that are from the correct genera.", 
            "title": "StarAMR"
        }, 
        {
            "location": "/analysis/strainmash/", 
            "text": "StrainMash\n\n\nWhat does it do?\n\n\nStrainMash uses the MinHash algorithm (as implemented by \nmash\n) in order to very quickly\nfind which RefSeq type strain an assembly is closest to. This can be very useful if you aren't entirely sure what species\nit is that you've actually sequnced.\n\n\nHow do I use it?\n\n\nSubject\n\n\nIn the \nSubject\n field, put \nStrainMash\n. Spelling counts, but case sensitivity doesn't.\n\n\nDescription\n\n\nAll you need to put in the description is a list of SEQIDs you want to analyze, one per line.\n\n\nExample\n\n\nFor an example StrainMash, see \nissue 12860\n.\n\n\nInterpreting Results\n\n\nStrainMash will upload a zip file once it finishes. This contains a folder called output, which will have a\ntext file for each SEQID entered showing results.\n\n\nThese text files have 6 columns:\n\n\n\n\nMashDistance: Represents roughly how close the query sequence is the the reference strain. 1 is a perfect match, 0 is no\nsimilarity. To say that something very closely matches a reference strain, this number should be \nat least\n 0.98\n\n\nNumMatchingHashes: Another measure of how close the query sequence is to the reference strain. 1000/1000 is a perfect match,\n0 is no similarity. Number needs to be fairly high (\n850) for close matches to reference.\n\n\nMedianMultiplicity: Can mostly be ignored. Should always be 1.\n\n\nPvalue: An attempt to assign significance to the hit. Should be zero for anything that very closely matches a reference\nstrain.\n\n\nReferenceStrain: The NCBI Accession for the reference strain.\n\n\nOrganism: The name of the organism that is the reference strain.\n\n\n\n\nHow long does it take?\n\n\nStrainMash should take about 30 seconds to 1 minute to analyze each sample you send to it.\n\n\nWhat can go wrong?\n\n\n1) Requested SEQIDs are not available. If we can't find some of the SEQIDs that you request, you will get a warning\nmessage informing you of it.", 
            "title": "Strainmash"
        }, 
        {
            "location": "/analysis/strainmash/#strainmash", 
            "text": "What does it do?  StrainMash uses the MinHash algorithm (as implemented by  mash ) in order to very quickly\nfind which RefSeq type strain an assembly is closest to. This can be very useful if you aren't entirely sure what species\nit is that you've actually sequnced.  How do I use it?  Subject  In the  Subject  field, put  StrainMash . Spelling counts, but case sensitivity doesn't.  Description  All you need to put in the description is a list of SEQIDs you want to analyze, one per line.  Example  For an example StrainMash, see  issue 12860 .  Interpreting Results  StrainMash will upload a zip file once it finishes. This contains a folder called output, which will have a\ntext file for each SEQID entered showing results.  These text files have 6 columns:   MashDistance: Represents roughly how close the query sequence is the the reference strain. 1 is a perfect match, 0 is no\nsimilarity. To say that something very closely matches a reference strain, this number should be  at least  0.98  NumMatchingHashes: Another measure of how close the query sequence is to the reference strain. 1000/1000 is a perfect match,\n0 is no similarity. Number needs to be fairly high ( 850) for close matches to reference.  MedianMultiplicity: Can mostly be ignored. Should always be 1.  Pvalue: An attempt to assign significance to the hit. Should be zero for anything that very closely matches a reference\nstrain.  ReferenceStrain: The NCBI Accession for the reference strain.  Organism: The name of the organism that is the reference strain.   How long does it take?  StrainMash should take about 30 seconds to 1 minute to analyze each sample you send to it.  What can go wrong?  1) Requested SEQIDs are not available. If we can't find some of the SEQIDs that you request, you will get a warning\nmessage informing you of it.", 
            "title": "StrainMash"
        }, 
        {
            "location": "/analysis/wgsassembly/", 
            "text": "WGS Assembly\n\n\nWhat does it do?\n\n\nWGS Assembly will take an Illumina MiSeq run and put it through the CFIA OLC Workflow for Bacterial Assembly and Typing (COWBAT).\n\n\nHow do I use it?\n\n\nBefore Redmine\n\n\nBefore submitting your request to Redmine, you need to upload your sequence data. Your sequence data should be in a folder\nnamed YYMMDD_LAB, where YYMMDD is the date sequencing was done, and LAB is a 3-letter code for your lab. For example, a\nsequencing run from Calgary done on July 16, 2018 would be 180716_CAL.\n\n\nThis folder needs to have the following files:\n\n\n\n\nSampleSheet.csv (see RDIMS 8040830 for an example SampleSheet)\n\n\nCompletedJobInfo.xml\n\n\nconfig.xml\n\n\nGenerateFASTQRunStatistics.xml\n\n\nRunInfo.xml\n\n\nrunParameters.xml\n\n\nthe InterOp folder\n\n\nA forward and reverse set of reads for each SEQID specified in your SampleSheet.csv\n\n\n\n\nTo upload this folder, navigate to \nftp://ftp.agr.gc.ca/incoming/cfia-ak\n in a file browser and drag and drop the folder\nto upload. Upload speed will vary depending on your connection. Once your upload is complete, you can head to Redmine\nto submit your issue.\n\n\nSubject\n\n\nIn the \nSubject\n field, put \nWGS Assembly\n. Spelling counts, but case sensitivity doesn't.\n\n\nDescription\n\n\nThe only thing to put in your description is the name of the folder you created and uploaded.\n\n\nExample\n\n\nFor an example WGS Assembly, see \nissue 12782\n.\n\n\nHow long does it take?\n\n\nWGS Assembly will likely take 5-6 hours to complete, although it can be as fast as 2 hours or as slow as 8.\n\n\nWhat can go wrong?\n\n\nA few things can go wrong with this process:\n\n\n1) FTP upload fails: Your upload to the FTP may time out or otherwise fail. If this happens, you will need to send us an\nemail so we can clear out the previous upload attempt before attempting to upload again.\n\n\n2) Validation fail: We validate a number of things about the files that are submitted before starting assembly, including\nmaking sure that all SEQIDs specified in the SampleSheet are uploaded, that the FASTQ files are appropriately sized, and\nthat all files required are present. If any of these validation checks fail, send us an email and we'll get things sorted\nout.", 
            "title": "Wgsassembly"
        }, 
        {
            "location": "/analysis/wgsassembly/#wgs-assembly", 
            "text": "What does it do?  WGS Assembly will take an Illumina MiSeq run and put it through the CFIA OLC Workflow for Bacterial Assembly and Typing (COWBAT).  How do I use it?  Before Redmine  Before submitting your request to Redmine, you need to upload your sequence data. Your sequence data should be in a folder\nnamed YYMMDD_LAB, where YYMMDD is the date sequencing was done, and LAB is a 3-letter code for your lab. For example, a\nsequencing run from Calgary done on July 16, 2018 would be 180716_CAL.  This folder needs to have the following files:   SampleSheet.csv (see RDIMS 8040830 for an example SampleSheet)  CompletedJobInfo.xml  config.xml  GenerateFASTQRunStatistics.xml  RunInfo.xml  runParameters.xml  the InterOp folder  A forward and reverse set of reads for each SEQID specified in your SampleSheet.csv   To upload this folder, navigate to  ftp://ftp.agr.gc.ca/incoming/cfia-ak  in a file browser and drag and drop the folder\nto upload. Upload speed will vary depending on your connection. Once your upload is complete, you can head to Redmine\nto submit your issue.  Subject  In the  Subject  field, put  WGS Assembly . Spelling counts, but case sensitivity doesn't.  Description  The only thing to put in your description is the name of the folder you created and uploaded.  Example  For an example WGS Assembly, see  issue 12782 .  How long does it take?  WGS Assembly will likely take 5-6 hours to complete, although it can be as fast as 2 hours or as slow as 8.  What can go wrong?  A few things can go wrong with this process:  1) FTP upload fails: Your upload to the FTP may time out or otherwise fail. If this happens, you will need to send us an\nemail so we can clear out the previous upload attempt before attempting to upload again.  2) Validation fail: We validate a number of things about the files that are submitted before starting assembly, including\nmaking sure that all SEQIDs specified in the SampleSheet are uploaded, that the FASTQ files are appropriately sized, and\nthat all files required are present. If any of these validation checks fail, send us an email and we'll get things sorted\nout.", 
            "title": "WGS Assembly"
        }, 
        {
            "location": "/data/external_retrieve/", 
            "text": "External Retrieve\n\n\nWhat does it do?\n\n\nExternal retrieve is a process that will upload data you request (either raw reads or draft assemblies) to an FTP site\nso that you can download it in the event that you need to have your files locally available.\n\n\nHow do I use it?\n\n\nSubject\n\n\nIn the \nSubject\n field, put \nExternal Retrieve\n. Spelling counts, but case sensitivity doesn't.\n\n\nDescription\n\n\nThe first line of your description tells the process whether you want to rename the retrieved files for upload to\nthe SRA (e.g. 2014-SEQ-0349_S11_L001_R1_001.fastq.gz renamed to 2014-SEQ-0349_R1.fastq.gz). Note that this option requires \nFASTQ files to be retrieved (see below)\n\n\nThe next line specifies whether you want raw reads or draft assemblies. For reads,\nthe first line should be \nfastq\n, and for assemblies the first line should be \nfasta\n. \n\n\nEvery line after that should be a SEQID that you want the data for.\n\n\nExample\n\n\nFor an example of an External Retrieve, see \nissue 12822\n or\nSRA formatting \nissue 18760\n.\n\n\nHow long does it take?\n\n\nIf your request is for a small number of files, it will generally be done within a few minutes. The more files requested,\nthe longer the request will take.\n\n\nWhat can go wrong?\n\n\nA few things can go wrong with this process:\n\n\n1) Requested SEQIDs are not available. If we can't find some of the SEQIDs that you request, you will get a warning\nmessage informing you of it.\n\n\n2) FTP timeout. Sometimes, particularly for larger requests, the upload to the FTP will run into problems and time out,\nin which case you will likely get an error message similar to this: \n[Errno 104] Connection reset by peer\n. If this occurs,\nyou can either try again later, or, if you had a large request, try splitting it into a few smaller requests. If the\nproblem persists, send us an email and we'll try to get it figured out.", 
            "title": "External retrieve"
        }, 
        {
            "location": "/data/external_retrieve/#external-retrieve", 
            "text": "What does it do?  External retrieve is a process that will upload data you request (either raw reads or draft assemblies) to an FTP site\nso that you can download it in the event that you need to have your files locally available.  How do I use it?  Subject  In the  Subject  field, put  External Retrieve . Spelling counts, but case sensitivity doesn't.  Description  The first line of your description tells the process whether you want to rename the retrieved files for upload to\nthe SRA (e.g. 2014-SEQ-0349_S11_L001_R1_001.fastq.gz renamed to 2014-SEQ-0349_R1.fastq.gz). Note that this option requires \nFASTQ files to be retrieved (see below)  The next line specifies whether you want raw reads or draft assemblies. For reads,\nthe first line should be  fastq , and for assemblies the first line should be  fasta .   Every line after that should be a SEQID that you want the data for.  Example  For an example of an External Retrieve, see  issue 12822  or\nSRA formatting  issue 18760 .  How long does it take?  If your request is for a small number of files, it will generally be done within a few minutes. The more files requested,\nthe longer the request will take.  What can go wrong?  A few things can go wrong with this process:  1) Requested SEQIDs are not available. If we can't find some of the SEQIDs that you request, you will get a warning\nmessage informing you of it.  2) FTP timeout. Sometimes, particularly for larger requests, the upload to the FTP will run into problems and time out,\nin which case you will likely get an error message similar to this:  [Errno 104] Connection reset by peer . If this occurs,\nyou can either try again later, or, if you had a large request, try splitting it into a few smaller requests. If the\nproblem persists, send us an email and we'll try to get it figured out.", 
            "title": "External Retrieve"
        }, 
        {
            "location": "/data/report_retrieve/", 
            "text": "Report Retrieve\n\n\nWhat does it do?\n\n\nReport retrieve will grab assembly reports for you and upload them to the FTP.\n\n\nHow do I use it?\n\n\nSubject\n\n\nIn the \nSubject\n field, put \nReport Retrieve\n. Spelling counts, but case sensitivity doesn't.\n\n\nDescription\n\n\nPut the SEQIDs you want reports for in the description, one per line. \n\n\nExample\n\n\nFor an example of an External Retrieve, see \nissue 13931\n.\n\n\nHow long does it take?\n\n\nThis should be almost instant - your request should be processed within a few minutes.\n\n\nWhat can go wrong?\n\n\nA few things can go wrong with this process:\n\n\n1) Requested SEQIDs are not available. If we can't find some of the SEQIDs that you request, you will get a warning\nmessage informing you of it.\n\n\n2) FTP timeout. Sometimes, particularly for larger requests, the upload to the FTP will run into problems and time out,\nin which case you will likely get an error message similar to this: \nUpload of result files was unsucessful due to\nFTP connectivity issues\n. If this occurs, your best bet is to try again later. If problems persist, send us an email\nand we'll look into it.", 
            "title": "Report retrieve"
        }, 
        {
            "location": "/data/report_retrieve/#report-retrieve", 
            "text": "What does it do?  Report retrieve will grab assembly reports for you and upload them to the FTP.  How do I use it?  Subject  In the  Subject  field, put  Report Retrieve . Spelling counts, but case sensitivity doesn't.  Description  Put the SEQIDs you want reports for in the description, one per line.   Example  For an example of an External Retrieve, see  issue 13931 .  How long does it take?  This should be almost instant - your request should be processed within a few minutes.  What can go wrong?  A few things can go wrong with this process:  1) Requested SEQIDs are not available. If we can't find some of the SEQIDs that you request, you will get a warning\nmessage informing you of it.  2) FTP timeout. Sometimes, particularly for larger requests, the upload to the FTP will run into problems and time out,\nin which case you will likely get an error message similar to this:  Upload of result files was unsucessful due to\nFTP connectivity issues . If this occurs, your best bet is to try again later. If problems persist, send us an email\nand we'll look into it.", 
            "title": "Report Retrieve"
        }, 
        {
            "location": "/data/sra_upload/", 
            "text": "SRA Upload\n\n\nWhat does it do?\n\n\nSRA Upload allows you to preload your sequence data for submission to the NCBI SRA using an FTP connection.\n\n\nHow do I use it?\n\n\nSubject\n\n\nIn the \nSubject\n field, put \nSRA Upload\n. Spelling counts, but case sensitivity doesn't.\n\n\nDescription\n\n\nBefore submitting, you'll need to get your FTP username, FTP password, and FTP folder name from the SRA.\nTo do this, log in to the SRA submission portal. Click on the \nMy Submissions\n tab towards the top right of the page,\nand then in the \nStart a new submission\n box, click \nSequence Read Archive\n. Under \nOptions to preload data\n, click \n\nFTP upload\n, and take note of the \nUsername\n, \nPassword\n, and the text under \nNavigate to your account folder.\n\n\nOnce you have those three things, you're ready to go. Put the username in the first line of the description, password \nin the second line, and the folder specified in the third (it should be something like \nuploads/youremail_a1d3a1\n).\nIn subsequent lines, put the SeqIDs you want to upload files for. Once the request finishes running, you should be \nable to find a folder named with your Redmine issue ID when you select a preload folder during submission.\n\n\nExample\n\n\nFor an example of an SRA Upload, see \nissue 14963\n.\n\n\nHow long does it take?\n\n\nIf your request is for a small number of files, it will generally be done within a few minutes. The more files requested,\nthe longer the request will take.\n\n\nWhat can go wrong?\n\n\nA few things can go wrong with this process:\n\n\n1) Requested SEQIDs are not available. If we can't find some of the SEQIDs that you request, you will get a warning\nmessage informing you of it.\n\n\n2) FTP timeout. Sometimes, particularly for larger requests, the upload to the FTP will run into problems and time out,\nin which case you will likely get an error message similar to this: \n[Errno 104] Connection reset by peer\n. If this occurs,\nyou can either try again later, or, if you had a large request, try splitting it into a few smaller requests. If the\nproblem persists, send us an email and we'll try to get it figured out.\n\n\n3) Bad FTP credentials. If the username and password for the NCBI FTP site didn't work you'll get a message telling you so.\nMake sure your username is on the first line of the request and password is second.\n\n\n4) FTP folder does not exist. If the FTP folder specified on the third line of the description isn't correct,\nyou'll get a message saying so.", 
            "title": "Sra upload"
        }, 
        {
            "location": "/data/sra_upload/#sra-upload", 
            "text": "What does it do?  SRA Upload allows you to preload your sequence data for submission to the NCBI SRA using an FTP connection.  How do I use it?  Subject  In the  Subject  field, put  SRA Upload . Spelling counts, but case sensitivity doesn't.  Description  Before submitting, you'll need to get your FTP username, FTP password, and FTP folder name from the SRA.\nTo do this, log in to the SRA submission portal. Click on the  My Submissions  tab towards the top right of the page,\nand then in the  Start a new submission  box, click  Sequence Read Archive . Under  Options to preload data , click  FTP upload , and take note of the  Username ,  Password , and the text under  Navigate to your account folder.  Once you have those three things, you're ready to go. Put the username in the first line of the description, password \nin the second line, and the folder specified in the third (it should be something like  uploads/youremail_a1d3a1 ).\nIn subsequent lines, put the SeqIDs you want to upload files for. Once the request finishes running, you should be \nable to find a folder named with your Redmine issue ID when you select a preload folder during submission.  Example  For an example of an SRA Upload, see  issue 14963 .  How long does it take?  If your request is for a small number of files, it will generally be done within a few minutes. The more files requested,\nthe longer the request will take.  What can go wrong?  A few things can go wrong with this process:  1) Requested SEQIDs are not available. If we can't find some of the SEQIDs that you request, you will get a warning\nmessage informing you of it.  2) FTP timeout. Sometimes, particularly for larger requests, the upload to the FTP will run into problems and time out,\nin which case you will likely get an error message similar to this:  [Errno 104] Connection reset by peer . If this occurs,\nyou can either try again later, or, if you had a large request, try splitting it into a few smaller requests. If the\nproblem persists, send us an email and we'll try to get it figured out.  3) Bad FTP credentials. If the username and password for the NCBI FTP site didn't work you'll get a message telling you so.\nMake sure your username is on the first line of the request and password is second.  4) FTP folder does not exist. If the FTP folder specified on the third line of the description isn't correct,\nyou'll get a message saying so.", 
            "title": "SRA Upload"
        }
    ]
}